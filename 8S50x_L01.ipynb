{"cells": [{"cell_type": "markdown", "metadata": {"tags": ["learner", "learner_chopped"]}, "source": ["<!--start-block-->\n", "<hr style=\"height: 1px;\">\n", "<i>This notebook was authored by the 8.S50x Course Team, Copyright 2022 MIT All Rights Reserved.</i>\n", "<hr style=\"height: 1px;\">\n", "<br>\n", "\n", "<h1>Lesson 1: Probability Distributions, Simple Plots, and Expectation Values</h1>\n", "\n", "<br>"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "learner_chopped"]}, "source": ["<!--start-block-->\n", "<a name='section_1_0'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L1.0 Overview</h2>"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "learner_chopped"]}, "source": ["<h3>Navigation</h3>\n", "          \n", "<table style=\"width:100%\">\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_1_1\">L1.1 Arrays, Functions, and Simple Plots</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_1_1\">L1.1 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_1_2\">L1.2 Simulated Data and Histograms</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_1_2\">L1.2 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_1_3\">L1.3 Sampling Events</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_1_3\">L1.3 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_1_4\">L1.4 Expectation and Variance</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_1_4\">L1.4 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_1_5\">L1.5 Sum of Two Distributions Continued</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_1_5\">L1.5 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_1_6\">L1.6 Generalizing to Many Measurements</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_1_6\">L1.6 Exercises</a></td>\n", "    </tr>\n", "</table>\n", "\n", "<!--end-block-->"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "catsoop_00"]}, "source": ["<h3>Welcome!</h3>\n", "\n", "Welcome to Datascience in physics! This course will cover the core topics of how to analyze modern physics data. We assume basic familiarity with Python and the Jupyter notebook platform, but otherwise most of the background you'll need will be here."]}, {"cell_type": "markdown", "metadata": {"tags": ["catsoop_00", "learner", "md"]}, "source": ["<h3>Learning Objectives</h3>\n", "\n", "In this Lesson, we will do the following:\n", "\n", "- create simple arrays and functions\n", "- introduce probability distributions\n", "- make simple plots\n", "- simulate data by randomly sampling from probability distributions\n", "- create histograms from randomly sampled data\n", "- investigate the sum of randomly sampled data\n", "- introduce the cumulative distribution function\n", "- define the expectation and variance of a distribution\n", "- consider sampling from the same distribution many times\n"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner"]}, "source": ["<h3>Importing Libraries</h3>\n", "\n", "<b>If starting a new session somewhere other than at the beginning of this notebook, don't forget to run the code cell that imports libraries!</b>\n", "\n", "As discussed in the introductory material, the programs you will run in this course use a variety of code libraries. In order to access these libraries and define the corresponding names, you will see a code section similar to the one below at the start of every course notebook. You will need to run this code only once per session. \n", "\n", "When running in Colab, you can check if you need to run it again by hovering your cursor over the run button. The popup window will tell you if that code has not been run during your current session."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L1.0-runcell01\n", "\n", "\"\"\"\n", "This code needs to be run once per session. If you get an error message of the form:\n", "\n", "--NameError: name 'np' is not defined--\n", "\n", "when running a later code segment, that means that this initialization code needs to be run.\n", "\"\"\"\n", "\n", "#import sys\n", "#we will install the core packages here\n", "#!{sys.executable} -m pip install numpy\n", "#!{sys.executable} -m pip install matplotlib\n", "#!{sys.executable} -m pip install scipy\n", "\n", "#to load python packages, simply import them (with optional nicknames)\n", "import numpy as np                 #https://numpy.org/doc/stable/\n", "import matplotlib.pyplot as plt    #https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.html\n", "import scipy.stats as stats        #https://docs.scipy.org/doc/scipy/reference/stats.html\n", "import csv                         #https://docs.python.org/3/library/csv.html "]}, {"cell_type": "markdown", "metadata": {"tags": ["learner"]}, "source": ["<h3>Setting Default Figure Parameters</h3>\n", "\n", "As will be discussed in the first section, you should set appropriate sizes for titles, labels, and axes markers in your plots. The following code cell sets default values for figure parameters."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L1.0-runcell02\n", "\n", "#set plot resolution\n", "%config InlineBackend.figure_format = 'retina'\n", "\n", "#set default figure parameters\n", "plt.rcParams['figure.figsize'] = (9,6)\n", "\n", "medium_size = 12\n", "large_size = 15\n", "\n", "plt.rc('font', size=medium_size)          # default text sizes\n", "plt.rc('xtick', labelsize=medium_size)    # xtick labels\n", "plt.rc('ytick', labelsize=medium_size)    # ytick labels\n", "plt.rc('legend', fontsize=medium_size)    # legend\n", "plt.rc('axes', titlesize=large_size)      # axes title\n", "plt.rc('axes', labelsize=large_size)      # x and y labels\n", "plt.rc('figure', titlesize=large_size)    # figure title"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "learner_chopped"]}, "source": ["<!--start-block-->\n", "<a name='section_1_1'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L1.1 Arrays, Functions, and Simple Plots</h2>    \n", "    \n", "| [Top](#section_1_0) | [Previous Section](#section_1_0) | [Exercises](#exercises_1_1) | [Next Section](#section_1_2) |"]}, {"cell_type": "markdown", "metadata": {"tags": ["8S50x", "learner"]}, "source": ["*The material in this section is discussed in the video **<a href=\"https://courses.mitxonline.mit.edu/learn/course/course-v1:MITxT+8.S50.1x+3T2022/block-v1:MITxT+8.S50.1x+3T2022+type@sequential+block@seq_LS1/block-v1:MITxT+8.S50.1x+3T2022+type@vertical+block@vert_LS1_vid1\" target=\"_blank\">HERE</a>.** You are encouraged to watch that video and use this notebook concurrently.*"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "lect_01"]}, "source": ["<h3>Making Plots</h3>\n", "\n", "Before we do anything substantial, let's walk through how to make a plot. Plots are the bread and butter of data science; it's helpful to see a plot when we first acquire data, and often we present processed data as plots.\n", "\n", "There are many libraries for plotting, but for this course, we will use Python with the popular `numpy`,  <a href=\"https://matplotlib.org/stable/users/index.html\" target=\"_blank\">`matplotlib`</a>, and <a href=\"https://docs.scipy.org/doc/scipy/reference/stats.html\" target=\"_blank\">`scipy.stats`</a> libraries.\n", "\n", "So for starters, we need something to plot. Since we don't have data yet, we'll make some up. Here's a good chance for `numpy` practice!\n", "\n", "As you saw in previous practice sections, `numpy` implements functions that can be run on arrays of objects or that have arrays as their output. Let's see an example, where we make an array of numbers and evaluate it with the `sin()` function (i.e., make a new array that is the sine of those numbers):"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["learner", "learner_chopped", "lect_01"]}, "outputs": [], "source": ["#>>>RUN: L1.1-runcell01\n", "\n", "x = np.linspace(start=-4, stop=4, num=5) # make an array of 5 numbers, evenly spaced from -4 to 4\n", "y = np.sin(x) # take the sine of each element of x, to get a new array, y\n", "\n", "print(\"x: \", x)\n", "print(\"y: \", y)\n", "\n", "#Try changing the array to include the range [-10,10]"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "lect_01"]}, "source": ["Hopefully that worked for you! As is usual in scientific computation, the `np.sin` function assumes radians as its input. \n", "\n", "To see a case where the answers will be more familiar to you, try using  `np.pi` or `math.pi` to generate the value $\\pi$ for the start and stop values. Note that, because of the precision of floating point numbers in Python, the sin of $\\pi$ generated in this way is not exactly zero."]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "lect_01"]}, "source": ["Now we can try plotting these two arrays `x` and `y` as if they were data. To do this quickly, we can use the `.plot()` function from `matplotlib.pyplot` (which we imported as `plt`). Note that the default plot size was already set in the last line of the code segment above that imported libraries.\n", "\n", "You will see that that none of the code that you ran to generate the arrays `x` and `y` appears in the following code segment. This is one of the advantages of Juypter notebooks. As you saw for importing libraries, everything that is run in a single notebook session functions as if you were executing these code segments sequentially within a single Python session."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["learner", "learner_chopped", "lect_01"]}, "outputs": [], "source": ["#>>>RUN: L1.1-runcell02\n", "\n", "plt.plot(x, y, label='sin') # initialize the plot\n", "plt.show() # put on screen"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "lect_01"]}, "source": ["Ok, now let's plot a few distributions, a sine, a cosine, and a normal distribution generated using the `scipy` stats function. Note that we did not import the entire `scipy` library, just the `scipy.stats` functions. \n", "\n", "To get smoother looking plots, we now generate an array with 100 points instead of just 5. Importantly, we also label everything to ensure that the plot is more readable. As you can see above, a plot generated with just the `pt.plot()` and `pt.show()` commands has numerical labels on the axes but nothing else."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["learner", "learner_chopped", "lect_01"]}, "outputs": [], "source": ["#>>>RUN: L1.1-runcell03\n", "\n", "#First we define an array for our x data \n", "x = np.linspace(start=-4, stop=4, num=100)\n", "\n", "#evaluate the data using a normal distribution from scipy\n", "mu = 0\n", "std = 1\n", "y = stats.norm.pdf(x, mu, std) \n", "\n", "\n", "#plotting-------------------\n", "#plot size\n", "#fig, ax = plt.subplots(figsize=(9,6)) #optionally set the figure size here\n", "\n", "#plot data\n", "plt.plot(x, np.sin(x), label='sin')\n", "plt.plot(x, np.cos(x), label='cos')\n", "plt.plot(x, y,label='normal distribution')\n", "\n", "#plot labels and style\n", "plt.title('Simple Plots of Common Functions', fontsize=15)\n", "plt.legend(loc='lower right', fontsize = 12)\n", "plt.xlabel('x', fontsize=15) #Label x\n", "plt.ylabel('f(x)', fontsize=15)#Label y\n", "\n", "# changing the fontsize of ticks\n", "plt.xticks(fontsize=12)\n", "plt.yticks(fontsize=12)\n", "\n", "# a grid\n", "plt.grid()\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "lect_01"]}, "source": ["While it's not the focus of this course, it is important to follow *good plotting etiquette* when you generate a final plot.\n", "\n", "In particular, you should:\n", "\n", "- Label all axes\n", "- Label all lines with a legend (if more than one)\n", "- Make sure the plot is readable:\n", " - The axis ranges are the right size so the plot is not cut off and also does not have excess empty space around the edges\n", " - A grid aligned with the tick marks makes it easy to read off values from the plot, but it optional\n", "\n", "\n", "This makes it much easier for other people to understand what you're showing! \n"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "learner_chopped"]}, "source": ["<a name='exercises_1_1'></a>\n", "\n", "| [Top](#section_1_0) | [Restart Section](#section_1_1) | [Next Section](#section_1_2) |"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "learner_chopped"]}, "source": ["<!--start-block-->\n", "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-1.1.1: Exponential Function</span>\n", "\n", "Define a function that returns the exponential of an array, using numpy.\n", "\n", "To check your answer, see if the output of your function `exp_func(x)` is equal to `e` for `x=1`. The \"starting\" code cell below includes a line at the end which does this check for you. This \"check\" is not graded.\n", "\n", "**Note:** Checks like this will **not** be included in the \"starting\" code for many of the problems in this course. While drafting your answers, you will need to think of the best way to do these checks yourself. Consider how to determine whether your code is correct."]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "learner_chopped", "8S50x"]}, "source": ["**Reminder:** You can edit or create and then run code cells in this notebook in order to help you find a solution to all of the problems in this course. However, your final answers **must** always be submitted on MITx."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true, "tags": ["draft"]}, "outputs": [], "source": ["#>>>EXERCISE: L1.1.1\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "def exp_func(x):\n", "    return 0\n", "\n", "\n", "if exp_func(1) == 2.718281828459045:\n", "    print('correct')\n", "else:\n", "    print('incorrect')"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-1.1.2: Plotting Etiquette</span>\n", "\n", "Which of the following functions will generate a plot that satisfies all criteria of good plotting etiquette? Try running each function in your Jupyter notebook.\n", "\n", "**Note:** This code uses your previously defined exponential function. If you are starting a new session with this exercise, you **must** rerun that code to redefine it."]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "learner_chopped", "8S50x"]}, "source": ["**Reminder:** Your final answers **must** always be submitted on MITx."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true, "tags": ["draft"]}, "outputs": [], "source": ["#>>>EXERCISE: L1.1.2\n", "\n", "def plot1(x):\n", "    #plotting-------------------\n", "    #plot data\n", "    plt.plot(x, exp_func(x))\n", "\n", "    #plot labels and style\n", "    plt.xlabel('x', fontsize=15) #Label x\n", "    plt.ylabel('exp(x)', fontsize=15)#Label y\n", "\n", "    # changing the fontsize of ticks\n", "    plt.xticks(fontsize=12)\n", "    plt.yticks(fontsize=12)\n", "    \n", "    plt.show()\n", "    \n", "\n", "def plot2(x):\n", "    #plotting-------------------\n", "    #plot data\n", "    plt.plot(x, exp_func(x), label='exp(x)')\n", "\n", "    #plot labels and style\n", "    plt.title('Exponential Function', fontsize=15)\n", "    plt.legend(loc='lower right', fontsize = 12)\n", "    plt.xlabel('x', fontsize=15) #Label x\n", "    plt.ylabel('exp(x)', fontsize=15)#Label y\n", "\n", "    # changing the fontsize of ticks\n", "    plt.xticks(fontsize=12)\n", "    plt.yticks(fontsize=12)\n", "\n", "    # a grid\n", "    plt.grid()\n", "    plt.show()\n", "    \n", "    \n", "def plot3(x):\n", "    #plotting-------------------\n", "    #plot data\n", "    plt.plot(x, exp_func(x), label='exp(x)')\n", "\n", "    #plot labels and style\n", "    plt.title('Exponential Function', fontsize = 8)\n", "    plt.legend(loc='lower right', fontsize = 8)\n", "    plt.xlabel('x', fontsize=8) #Label x\n", "    plt.ylabel('exp(x)', fontsize=8)#Label y\n", "\n", "    # changing the fontsize of ticks\n", "    plt.xticks(fontsize=8)\n", "    plt.yticks(fontsize=8)\n", "\n", "    # a grid\n", "    plt.grid()\n", "    plt.show()\n", "\n", "\n", "x = np.linspace(start=0, stop=10, num=100)\n", "plot1(x)\n", "plot2(x)\n", "plot3(x)"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "learner_chopped"]}, "source": [">#### Follow-up 1.1.1a (ungraded)\n", ">   \n", ">Change the range of the plot and/or try plotting with a different number of data points."]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "learner_chopped"]}, "source": ["<!--start-block-->\n", "<a name='section_1_2'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L1.2 Simulated Data and Histograms</h2>\n", "    \n", "| [Top](#section_1_0) | [Previous Section](#section_1_1) | [Exercises](#exercises_1_2) | [Next Section](#section_1_3) |\n", "\n", "</br>"]}, {"cell_type": "markdown", "metadata": {"tags": ["8S50x", "learner"]}, "source": ["*The material in this section is discussed in the video **<a href=\"https://courses.mitxonline.mit.edu/learn/course/course-v1:MITxT+8.S50.1x+3T2022/block-v1:MITxT+8.S50.1x+3T2022+type@sequential+block@seq_LS1/block-v1:MITxT+8.S50.1x+3T2022+type@vertical+block@vert_LS1_vid2\" target=\"_blank\">HERE</a>.** You are encouraged to watch that video and use this notebook concurrently.*"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "lect_02"]}, "source": ["<h3>Overview</h3>\n", "\n", "The next concept that we need to understand is a histogram. A histogram is just a sum of the number of data points that fall within a specific range of x, called a \"bin.\" We can compute it using the ```np.histogram``` function. This outputs an array with the number of data points per bin along with the edges of the bin. \n", "\n", "To fill this histogram, we will generate a set of random values (or events). We will use the `np.random.uniform` function, which generates random numbers from a uniform distribution. (Alternatively, you can comment out the `np.random.uniform` line and uncomment the line using `np.random.normal` for a normal distribution.) Then we will fill a 20-bin histogram with this information. "]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "lect_02"]}, "source": ["<h3>Generating Random Numbers</h3>\n", "\n", "It's impossible for any computer program to generate truly random numbers. Describing how such generators work in beyond the scope of this course but most programs use a number called the \"seed\". Using the same starting value for the seed always produces the same set of \"random\" numbers. \n", "\n", "This seems counterintuitive to the very concept of \"random\" numbers. However, it is often desirable to have a way to recreate a specific set of random numbers so that a program using sampling can give reproducible results. This is done by setting the starting value of the random seed. You will often see `np.random.seed(0)` used in code segments in this course. That way, the instructors can ensure that students will see exactly the same results every time.\n", "\n", "The point is that, given **only** the set of generated random numbers, it is not possible to find a pattern that can be used to predict any of the entries given the previous values. The need to generate a reproducible sequence of numbers which, nonetheless, display no discernible pattern is why random number generators are not trivial to write."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["learner", "learner_chopped", "lect_02"]}, "outputs": [], "source": ["#>>>RUN: L1.2-runcell01\n", "\n", "#Randomly choose 1000 events between 0 and 10\n", "bkg = np.random.uniform(0,10, 1000) \n", "\n", "#ALTERNATIVELY\n", "#Randomly choose 1000 events from a normal distribution with mean 0 and standard deviation 1\n", "#bkg = np.random.normal(0, 1, 1000) # uncomment to run\n", "\n", "#If you want to see the output, uncomment the line below. It's a good idea to\n", "# change the number of events to something less than 1000 first. Don't forget to\n", "# change it back to 1000 and rerun the code before going on to the next step.\n", "#print(bkg)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true, "tags": ["learner", "learner_chopped", "lect_02"]}, "outputs": [], "source": ["#>>>RUN: L1.2-runcell02\n", "\n", "#Now let's make a histogram\n", "histy, bin_edges = np.histogram(bkg, bins=20)\n", "bin_centers = 0.5*(bin_edges[1:] + bin_edges[:-1])\n", "\n", "                            \n", "#plotting-------------------\n", "#plot size\n", "#fig, ax = plt.subplots(figsize=(9,6)) #optionally set the figure size here\n", "\n", "#plot data and axes limits\n", "plt.plot(bin_centers,histy,drawstyle = 'steps-mid')\n", "plt.ylim(0,100) #You will need to change this for a normal distribution\n", "#ax.set_ylim([0,100]) #set the y-range of ax to be 0 to 100, if using ax\n", "\n", "#plot labels and style\n", "plt.xlabel('x', fontsize=15) #Label x\n", "plt.ylabel('N samples', fontsize=15) #Label y\n", "plt.xticks(fontsize=12)\n", "plt.yticks(fontsize=12)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "learner_chopped"]}, "source": ["<a name='exercises_1_2'></a>\n", "\n", "| [Top](#section_1_0) | [Restart Section](#section_1_2) | [Next Section](#section_1_3) |"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "learner_chopped"]}, "source": ["<!--start-block-->\n", "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-1.2.1: Integral of a Histogram</span>\n", "\n", "What is the integral of the histogram in the previous example, a uniform distribution sampled 1000 times? You can add to the code below to calculate your answer, or you may determine the result without computation.\n", "\n", "Enter a number for your answer."]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "learner_chopped", "8S50x"]}, "source": ["**Reminder:** Your final answers **must** always be submitted on MITx."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["draft", "learner_chooped"]}, "outputs": [], "source": ["#>>>EXERCISE: L1.2.1\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "#Randomly choose 1000 events between 0 and 10\n", "bkg = np.random.uniform(0,10, 1000) \n", "histy, bin_edges = np.histogram(bkg, bins=20)\n", "\n", "integral = 0 #complete the code\n", "\n", "print(\"Integral:\",integral)"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-1.2.2: Number of Bins</span>\n", "\n", "The number of bins you choose for a histogram can have an outsized impact on its visual quality and information content. Poor quality can result from having both too many and too few bins. Below, we provide code to sample from a uniform distribution. Add code to plot a histogram of the samples, and try it with 3 bins, 10 bins, and 100 bins. You may find it easiest to copy and then edit lines from previous code cells. You might also want to try `matplotlib.pyplot.hist`.\n", "\n", "Which number of bins produces the most sensible histogram: 3, 10, or 1000?"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "learner_chopped", "8S50x"]}, "source": ["**Reminder:** Your final answers **must** always be submitted on MITx."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L1.2.2\n", "#Randomly choose 1000 events between 0 and 10, with set RNG seed\n", "np.random.seed(0) # makes the random numbers stay the same between runs\n", "samples = np.random.uniform(0, 10, 1000) \n", "\n", "# Below, write code to make a histogram, and try with 3, 10, and 1000 bins"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "learner_chopped"]}, "source": [">#### Follow-up 1.2.2a (ungraded)\n", ">   \n", ">Sample a uniform distribution from 0 to 5 and plot it with 11 bins. Use the starting code below."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>FOLLOW-UP: L1.2.2a\n", "# Use this cell for drafting your solution (if desired)\n", "\n", "bkg = 0 #your code here\n", "histy, bin_edges = 0 #your code here\n", "#make sure to plot it with bin centers, not bin edges!\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "learner_chopped"]}, "source": [">#### Follow-up 1.2.2b (ungraded)\n", ">   \n", ">Change the code in `L1.2-runcell01`, so that you draw 10000 samples from a normal distribution. How is the histogram different? You may have to change some parameters of your plot to fit the data appropriately. Try other values."]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "learner_chopped"]}, "source": ["<!--start-block-->\n", "<a name='section_1_3'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L1.3 Sampling events</h2>\n", "    \n", "| [Top](#section_1_0) | [Previous Section](#section_1_2) | [Exercises](#exercises_1_3) | [Next Section](#section_1_4) |"]}, {"cell_type": "markdown", "metadata": {"tags": ["8S50x", "learner"]}, "source": ["*The material in this section is discussed in the video **<a href=\"https://courses.mitxonline.mit.edu/learn/course/course-v1:MITxT+8.S50.1x+3T2022/block-v1:MITxT+8.S50.1x+3T2022+type@sequential+block@seq_LS1/block-v1:MITxT+8.S50.1x+3T2022+type@vertical+block@vert_LS1_vid3\" target=\"_blank\">HERE</a>.** You are encouraged to watch that video and use this notebook concurrently.*"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner"]}, "source": ["<h3>Slides</h3>\n", "\n", "Run the code below to view the slides for this section, which are discussed in the related video. You can also open the slides in a separate window <a href=\"https://mitx-8s50.github.io/slides/L01/slides1.html\" target=\"_blank\">HERE</a>."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["learner"]}, "outputs": [], "source": ["#>>>RUN: L1.2-slides\n", "\n", "from IPython.display import IFrame\n", "\n", "IFrame(src='https://mitx-8s50.github.io/slides/L01/slides1.html', width=975, height=550)"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "lect_03"]}, "source": ["<h3>Overview</h3>\n", "\n", "Let's try something a bit more complicated. In the following code, we are going to sample TWO random variables described by uniform (flat) distributions. Then, we'll define a new random variable that's the SUM of the two sampled values. The \"observed\" value of a random number (i.e., what you get when you sample a distribution) is also called a \"realization\"."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["learner", "learner_chopped", "lect_03"]}, "outputs": [], "source": ["#>>>RUN: L1.3-runcell01\n", "\n", "#Let's sample a uniform distribution 10k times each\n", "bkg1 = np.random.uniform(0,10, 10000)\n", "bkg2 = np.random.uniform(0,10, 10000) #this outputs an array of 10,000\n", "\n", "#Now we sum them\n", "data = bkg1 + bkg2 #since bkg1 and 2 are numpy arrays, doing this adds element-wise (called \"broadcasting\")\n", "\n", "\n", "def getHist(data):\n", "    \"\"\"Get hist y values, bin edges, and bin centers as np arrays\"\"\"\n", "    histy, bin_edges = np.histogram(data, bins=100)\n", "    bin_centers = 0.5*(bin_edges[1:] + bin_edges[:-1])\n", "    return (histy, bin_edges, bin_centers)\n", "\n", "def plotData(data):\n", "    #plotting-------------------\n", "    #plot size\n", "    #fig, ax = plt.subplots(figsize=(9,6)) #optionally set the figure size here\n", "    \n", "    #plot data\n", "    histy, bin_edges, bin_centers = getHist(data)\n", "    plt.plot(bin_centers,histy,drawstyle = 'steps-mid')\n", "    \n", "    #plot labels and style\n", "    plt.xlabel('x', fontsize=15) #Label x\n", "    plt.ylabel('N samples', fontsize=15) #Label y\n", "    plt.xticks(fontsize=12)\n", "    plt.yticks(fontsize=12)\n", "    plt.show()\n", "\n", "def plotDataNormalized(data):\n", "    histy, bin_edges, bin_centers = getHist(data)\n", "    # normalize the hist y values to the total number of samples (integral)\n", "    integral = len(data)\n", "    norm_histy = histy / integral # again, division is broadcast to elements of histy\n", "    plt.plot(bin_centers,norm_histy,drawstyle = 'steps-mid')\n", "    plt.xlabel('x', fontsize=15) #Label x\n", "    plt.ylabel('Relative probability', fontsize=15) #Label y\n", "    plt.xticks(fontsize=12)\n", "    plt.yticks(fontsize=12)\n", "    plt.show()\n", "\n", "plotData(data)\n", "#plotDataNormalized(data)"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "lect_03"]}, "source": ["So, what distribution are we sampling when we generate this new random variable? \n", "\n", "Let's derive it analytically. However, before we do that, let's first define a few statistical quantities. When these quantities are calculated for a specific sample of events, they are called \"observables\". \n", "\n", "To understand this, we need to define a probability distribution function, or \"PDF\". By definition, the integral of a PDF is always equal to 1. \n", "\n", "When we sample a uniform distribution from 0 to 10, we are sampling random numbers in that range. We can characterize the process of taking a random sample of a PDF $p(x)$ by defining the probability $P_{ab}(X)$ that a number is sampled between $a$ and $b$ as: \n", "\n", "$$P_{ab}(X)=\\int_{a}^{b}p(x)dx$$\n", "\n", "or, in other words, the probability is given by the integral of $p(x)$ over that range. As expected, the probability of observing a number within the entire range of the PDF will always equal 1. \n", "\n", "$$1=\\int_{-\\infty}^{\\infty}p(x)dx$$\n", "\n", "For a flat distribution from a to b, $p(x)$ is given by:\n", "\n", "$$p_{flat}(x)=\\frac{1}{b-a}$$  \n", "\n", "To check this, let's just count events in our range. If we restrict our range to $x_{min} < x < x_{max}$ (where $x_{min}\\gt a$ and $x_{max} \\lt b$), the probability will then be \n", "\n", "$$\\int_{x_{min}}^{x_{max}}\\frac{1}{b-a}dx = \\frac{x_{max}-x_{min}}{b-a}$$"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "lect_03"]}, "source": ["Let's check this \"ideal\" probability by doing an \"observation\" of the probability."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["learner", "learner_chopped", "lect_03"]}, "outputs": [], "source": ["#>>>RUN: L1.3-runcell02\n", "\n", "#define a=xmin and b=xmax\n", "xmin=2\n", "xmax=5\n", "\n", "#sample\n", "bkg1 = np.random.uniform(0,10, 10000)\n", "\n", "#now count\n", "prob=0\n", "total=0\n", "for x in bkg1:\n", "    total+=1\n", "    if x > xmin and x < xmax :\n", "        prob+=1\n", "        \n", "print(\"Probability that we are between a and b is: \",prob/total, \"true probability is:\",(xmax-xmin)/10)"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "lect_03"]}, "source": ["So, we see that we get a number very close to the expected value. It is not exact, because now we are dealing with sampled events. We will get back to the lack of exactness later on. For now, try varying the number of samples to see how the difference from the true value changes.  \n", "\n", "Now, in addition to having a PDF, we can define something called the cumulative distribution function (CDF). This function is similar to the probability, except we integrate one end of the PDF from negative infinity. \n", "\n", "$$\\mathrm{CDF}(x)=\\int_{-\\infty}^{x} p(u)du$$\n", "\n", "This is now a function of $x$ that involves an integral over the PDF. Defined this way, the CDF for a given $x$ is the total probability that lies in values below that $x$. It can also be defined the opposite way, accounting for total probability of values above the $x$."]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "lect_03"]}, "source": ["Let's display PDFs and their associated CDFs using the `scipy.stats` module, for both the uniform and normal distributions. The normal distribution will be studied in detail later on. "]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["learner", "learner_chopped", "lect_03"]}, "outputs": [], "source": ["#>>>RUN: L1.3-runcell03\n", "\n", "def plot_pdf_cdf_uniform(x):\n", "    #plotting-------------------\n", "    #plot size\n", "    fig, ax = plt.subplots(figsize=(9,6))\n", "\n", "    #plot data\n", "    ax.plot(x, stats.uniform.pdf(x), 'k-', lw=2, label='PDF')  # PDF of a standard uniform distribution\n", "    ax.plot(x, stats.uniform.cdf(x), 'k--', lw=2, label='CDF')  # CDF of a standard uniform distribution\n", "\n", "    #plot labels and style\n", "    plt.title(\"PDF and CDF of a standard uniform distribution\", fontsize=15)\n", "    plt.legend(fontsize=12)\n", "    plt.xlabel('x', fontsize=15) #Label x\n", "    plt.xticks(fontsize=12)\n", "    plt.yticks(fontsize=12)\n", "    plt.show()\n", "\n", "x = np.linspace(-2,2,100)\n", "plot_pdf_cdf_uniform(x)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["learner", "learner_chopped", "lect_03"]}, "outputs": [], "source": ["#>>>RUN: L1.3-runcell04\n", "\n", "def plot_pdf_cdf_normal(x):\n", "    #plotting-------------------\n", "    #plot size\n", "    fig, ax = plt.subplots(figsize=(9,6))\n", "\n", "    #plot data\n", "    ax.plot(x, stats.norm.pdf(x), 'k-', lw=2, label='PDF')  # PDF of a standard normal distribution\n", "    ax.plot(x, stats.norm.cdf(x), 'k--', lw=2, label='CDF')  # CDF of a standard normal distribution\n", "\n", "    #plot labels and style\n", "    plt.title(\"PDF and CDF of a standard normal distribution\", fontsize=15)\n", "    plt.legend(fontsize=12)\n", "    plt.xlabel('x', fontsize=15) #Label x\n", "    plt.xticks(fontsize=12)\n", "    plt.yticks(fontsize=12)\n", "    plt.show()\n", "    \n", "x = np.linspace(-5,5,100)\n", "plot_pdf_cdf_normal(x)"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "learner_chopped"]}, "source": ["<a name='exercises_1_3'></a>\n", "\n", "| [Top](#section_1_0) | [Restart Section](#section_1_3) | [Next Section](#section_1_4) |"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "learner_chopped"]}, "source": ["<!--start-block-->\n", "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-1.3.1: PDF and CDF</span>\n", "\n", "For any valid (i.e. corresponding to some possible probability distribution) PDF, what is the maximum value of its corresponding CDF? Enter a number."]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "learner_chopped", "8S50x"]}, "source": ["**Reminder:** Your final answers **must** always be submitted on MITx."]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-1.3.2: Sum of Two Distributions</span>\n", "\n", "Consider two arrays of uniformly distributed data, each with 10,000 points (as shown in the code below). What is the integral of the array which is the sum of these two arrays?  Enter a number."]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "learner_chopped", "8S50x"]}, "source": ["**Reminder:** Your final answers **must** always be submitted on MITx."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true, "tags": ["draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L1.3.2\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "#Let's sample a uniform distribution 10k times each\n", "bkg1 = np.random.uniform(0,10, 10000)\n", "bkg2 = np.random.uniform(0,10, 10000) #this outputs an array of 10,000\n", "\n", "#Now we sum them\n", "data = bkg1 + bkg2 #since bkg1 and 2 are numpy arrays, doing this adds element-wise (called \"broadcasting\")\n", "\n", "#YOUR CODE HERE"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "learner_chopped"]}, "source": ["<!--start-block-->\n", "<a name='section_1_4'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L1.4 Expectation and Variance</h2>\n", "\n", "| [Top](#section_1_0) | [Previous Section](#section_1_3) | [Exercises](#exercises_1_4) | [Next Section](#section_1_5) |"]}, {"cell_type": "markdown", "metadata": {"tags": ["8S50x", "learner"]}, "source": ["*The material in this section is discussed in the video **<a href=\"https://courses.mitxonline.mit.edu/learn/course/course-v1:MITxT+8.S50.1x+3T2022/block-v1:MITxT+8.S50.1x+3T2022+type@sequential+block@seq_LS1/block-v1:MITxT+8.S50.1x+3T2022+type@vertical+block@vert_LS1_vid4\" target=\"_blank\">HERE</a>.** You are encouraged to watch that video and use this notebook concurrently.*"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "lect_04"]}, "source": ["<h3>Definitions</h3>\n", "\n", "We can use PDFs to define the expectation $E[x]$ for a continuous variable,\n", "\n", "$$E[x]=\\int_{-\\infty}^{\\infty}xp(x)dx$$\n", "\n", "or, in other words, the value of $x$ weighted by its PDF. This is also commonly referred to as the mean or average of the distribution. \n", "\n", "Furthermore, we can also define the variance of this distribution, as: \n", "\n", "$$V[x]=\\int_{-\\infty}^{\\infty}\\left(x-E[x]\\right)^{2}p(x)dx$$\n", "\n", "or, in other words, the spread of the numbers about the mean of the distribution. The variance holds an important interpretation. It is a measure of the width of our distribution, and we often use this as a way to describe the uncertainty of our measurement. Uncertainty is simply defined to be the square root of the above, $\\sqrt{V(x)}$, which we refer to as the standard deviation $\\sigma$. We will clarify this interpretation more in a later section. \n", "\n", "$$\\sigma=\\sqrt{V(x)}$$\n", "\n", "You will often see the standard deviation called the root mean squared, or RMS.\n", "\n", "<br>"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "lect_04"]}, "source": ["<h3>Example of Computing Mean and Variance</h3>\n", "\n", "Let's estimate the mean and variance of a flat (i.e., uniform) distribution by using a sample of data points. \n", "\n", "The formulas given above apply to finding exact statistical properties of a known distribution. However, they can also be applied to finding these properties for a data sample. Suppose we have ${N_\\mathrm{samples}}$ data points and we pick out one arbitrary data point. All the data points have an equal probability of being selected, so there is a probability $p(x)=\\frac{1}{N_\\mathrm{samples}}$ that we pick a specific one.\n", "\n", "Note that this probability is independent of what distribution the points were sampled from. We can use this PDF with the formulas above to calculate the mean and variance. Of course, for a set of discrete values of $x$, we need to do a sum, not an integral.\n", "\n", "You can see that using this $p(x)$ and a sum for the expectation value, you are just doing the usual procedure for calculating an average of any set of numbers."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["learner", "learner_chopped", "lect_04"]}, "outputs": [], "source": ["#>>>RUN: L1.4-runcell01\n", "\n", "#Again another exercise\n", "\n", "#sample\n", "nsamples=10000\n", "bkg1 = np.random.uniform(0,10, nsamples)\n", "\n", "#mean\n", "mean=0\n", "prob=1./nsamples\n", "for x in bkg1:\n", "    mean+=x*prob\n", "print(\"Mean: \",mean)\n", "\n", "#Now we can do the variance\n", "var=0\n", "for x in bkg1:\n", "    var+=(x-mean)*(x-mean)*prob\n", "print(\"Var: \",var)\n", "\n", "#Now we can do it the fast way, using intrinsic numpy functions\n", "print(\"Mean:\",bkg1.mean(),\"Variance:\",bkg1.var())"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner"]}, "source": ["<a name='exercises_1_4'></a>\n", "\n", "| [Top](#section_1_0) | [Restart Section](#section_1_4) | [Next Section](#section_1_5) |"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "learner_chopped"]}, "source": ["<!--start-block-->\n", "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-1.4.1: Mean of Uniform Distribution</span>\n", "\n", "Compute the \"ideal\" value of the mean (i.e., the average) of a uniform distribution from 0 to 5. You may do this analytically or by augmenting the code above."]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "learner_chopped", "8S50x"]}, "source": ["**Reminder:** Your final answers **must** always be submitted on MITx."]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "learner_chopped"]}, "source": [">#### Follow-up 1.4.1a (ungraded)\n", ">   \n", ">Compute the mean and variance of a uniform distribution from 0 to 5 by taking 1000 random samples. Use the starting code below."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true, "tags": ["draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>FOLLOW-UP: L1.4.1a\n", "# Use this cell for drafting your solution (if desired)\n", "\n", "def mean(start, end, num_points):\n", "    mean_val = 0 # your code here\n", "    return mean_val\n", "\n", "def variance(start, end, num_points):\n", "    var_val = 0 # your code here\n", "    return var_val"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "learner_chopped"]}, "source": ["<!--start-block-->\n", "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-1.4.2: Mean and Variance of a Uniform Distribution</span>\n", "\n", "Calculate analytically the mean and variance for a uniform distribution in the following ranges:\n", "\n", "(a) 0 to 2<br>\n", "(b) 0 to 5<br>\n", "(c) 0 to 10<br>\n", "(d) 0 to 20\n", "\n", "What is the trend in mean (expectation) and variance, from (a) to (d)? Choose from the options below:\n", "\n", "- mean decreasing, variance decreasing\n", "- mean decreasing, variance increasing\n", "- mean increasing, variance decreasing\n", "- mean increasing, variance increasing\n", "\n", "You may want to get a general formula. Alternatively, use large samples (>1000 events) from these distributions to computationally estimate the mean and variances (starting code below).\n", "    \n", "Whichever method you chose, you are encouraged to look at the solution after you submit your answer to make sure you understand how this works analytically. "]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "learner_chopped", "8S50x"]}, "source": ["**Reminder:** Your final answers **must** always be submitted on MITx."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true, "tags": ["draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L1.4.2\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "import numpy as np\n", "\n", "# Sample from uniform distributions in [0,2], [0,5], [0,10], [0,20]\n", "samples_list = [np.random.uniform(0, upper, 1000) for upper in [2, 5, 10, 20]] # Python list compr. syntax\n", "\n", "# Get a list of tuples of (mean, variance)\n", "means_vars = 0 #YOUR CODE HERE\n", "\n", "# Print results\n", "for mean, variance in means_vars:\n", "    print(f\"Mean: {mean}, Variance: {variance}\")"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "learner_chopped"]}, "source": ["<!--start-block-->\n", "<a name='section_1_5'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L1.5 Sum of Two Distributions Continued</h2>\n", "\n", "| [Top](#section_1_0) | [Previous Section](#section_1_4) | [Exercises](#exercises_1_5) | [Next Section](#section_1_6) |"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "lect_05"]}, "source": ["<h3>Back to the sum distribution!</h3>\n", "\n", "Finally, we're ready to see what distribution results from summing realizations of two uniform distributions. Let's first turn a uniform distribution from 0 to 10 into a PDF. For this we know that the function is flat between 0 and 10, and zero otherwise. Consequently $f(x)=a$ when $x\\in[0,10]$, and \n", "\n", "$$\n", "\\begin{equation}\n", "1=\\int_{0}^{10}adx=ax|_{0}^{10}=10a\\\\\n", "a=\\frac{1}{10}\n", "\\end{equation}\n", "$$\n", "\n", "As a quick check, we find the expectation of this distribution is \n", "\n", "$$\n", "\\begin{equation}\n", "E[x]=\\int_{0}^{10}axdx=ax^2|_{0}^{10}=50a\\\\\n", "E[x]=5\n", "\\end{equation}\n", "$$\n", "\n", "Now, let's consider sampling this distribution twice. If we get a result $x^\\prime=x_{1}+x_{2}$, there are a broad range of possible values for $x_{1}$ and $x_{2}$. Let's say $x^{\\prime}=10$ then it could be that one sample $x_{1}=5$ and the other sample $x_{2}=5$ or it could be that $x_{1}=10$ and $x_{2}=0$. To get all the possible values for $x^{\\prime}=10$ we need to compute the expectation over all possibilities. This is equivalent imposing a constraint that $x^{\\prime}=x_{1}+x_{2}\\rightarrow x_{2}=x^{\\prime}-x_{1}$. \n", "\n", "The best way to think about this is as a 2D distribution. Let's make a plot of this. "]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["learner", "learner_chopped", "lect_05"]}, "outputs": [], "source": ["#>>>RUN: L1.5-runcell01\n", "\n", "bkg1 = np.random.uniform(0,10, 100)\n", "bkg2 = np.random.uniform(0,10, 100)\n", "\n", "#Now we sum them\n", "data = bkg1+bkg2\n", "\n", "#now let's fix x' to be 10, this means only bkg1 is an independent variable\n", "val=10-bkg1\n", "\n", "#now let's plot them\n", "#plotting-------------------\n", "#plot data\n", "plt.scatter(bkg1,bkg2, label=\"x1, x2 independently sampled\")\n", "plt.scatter(bkg1,val, label=\"x' = x1 + x2 = 10\")\n", "\n", "#plot labels and style\n", "plt.legend(fontsize=15)\n", "plt.xlabel('x1', fontsize=15) #Label x\n", "plt.ylabel('x2', fontsize=15) #Label y\n", "plt.xticks(fontsize=12)\n", "plt.yticks(fontsize=12)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "lect_05"]}, "source": ["So when we fix $x^{\\prime}$ and sample events, that is equivalent to just drawing a line on the 2D plot. Now, if we think of this distribution as a 2D probability distribution function, we can write. \n", "\n", "$$\n", "\\begin{eqnarray}\n", "P(x_{1},x_{2})&=&\\int_{x_1^\\mathrm{min}}^{x_1^\\mathrm{max}} \\int_{x_2^\\mathrm{min}}^{x_2^\\mathrm{max}}p(x_{1})p(x_{2})dx_{1}dx_{2}\n", "\\end{eqnarray}\n", "$$\n", "\n", "with the probability $P$ now defined as a 2D integral. In this case, we treated it as 2 independent probability distributions $p(x_{1})$ and $p(x_{2})$. In reality this function can be a function of both variables $p(x_{1},x_{2})$. We can now simplify this distribution into a 1D distribution by integrating over the line where $x^{\\prime}=x_1+x_2$\n", "\n", "\n", "$$\n", "\\begin{eqnarray}\n", "p(x^\\prime=x_{1}+x_{2})&=&\\int_{-\\infty}^{\\infty}p(x_{1})p(x^\\prime-x_{1})dx_{1}\n", "\\end{eqnarray}\n", "$$\n", "\n", "For this, we have then \n", "\n", "$$\n", "\\begin{eqnarray}\n", "p(x^\\prime=x_{1}+x_{2})&=& \\int_{0}^{10}\\frac{1}{a}p(x^\\prime-x_{1})dx_{1}\\\\\n", "\\end{eqnarray}\n", "$$\n", "\n", "We have to deal with two cases separately. One is where $x^{\\prime} \\geq 10$, and so the smaller number cannot go down to zero, but only to a minimum of $x^{\\prime}-10$ (the max number would be 10 in this case). The other case is where $x^{\\prime} \\lt 10$ and so the larger number cannot exceed $x^{\\prime}$ (the min number would be 0 in this case). Expanding this out gives us:\n", "\n", "$$\n", "\\begin{eqnarray}\n", "p(x^\\prime=x_{1}+x_{2}) &=&\\int_{x^\\prime-10}^{10}\\frac{1}{a^2}dx_{1}~\\forall x^\\prime \\geq 10\\\\\n", "&=&\\frac{20-x^\\prime}{a^2}~\\forall x^\\prime \\geq 10\\\\\n", "\\end{eqnarray}\n", "$$\n", "\n", "$$\n", "\\begin{eqnarray}\n", "p(x^\\prime=x_{1}+x_{2}) &=&\\int_0^{x^{\\prime}}\\frac{1}{a^2}dx_{1}~\\forall x^\\prime < 10\\\\\n", "&=&\\frac{x^\\prime}{a^2}~\\forall x^\\prime < 10\\\\\n", "\\end{eqnarray}\n", "$$"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "lect_05"]}, "source": ["Or, in other words, the probability of finding a particular value of $x^\\prime$ is a line sloping up from 0 when we are below 10, and then sloping back down to 0 when we are above 10. To verify that this is a full PDF we can check the normalization:\n", "\n", "$$\n", "\\begin{eqnarray}\n", "\\int_{-\\infty}^{\\infty}p(x^\\prime)dx^{\\prime}&=&\\frac{x^2}{2a^2}|^{10}_{0}+\\frac{20x-x^2/2}{a^2}|^{20}_{10}\\\\\n", "&=&\\frac{100}{200}+\\frac{400-200}{100}-\\frac{200-50}{100}\\\\\n", "&=&\\frac{1}{2}+\\frac{200-150}{100}\\\\\n", "&=&1\n", "\\end{eqnarray}\n", "$$\n", "\n", "The nice thing about computers is we don't need to do all these integrals to get these lines. Finally, let's actually plot all of these on the same plot! We now have a histogram and a function. \n", "\n", "The one tricky component in the above formula is that we want to compare a distribution with a histogram, so we need to ensure that the integrals are the same over each region.  \n", "\n", "To make sure they are the same, let pick a specific bin with minimum $x_{min}$ and maximum $x_{max}$.  Ensuring the integrals per bin are the same means that for each bin the values need to be the same or in other words\n", "\n", "$$\n", "\\begin{equation}\n", "N^{\\rm bin}_\\mathrm{samples} = \\int_{x_\\mathrm{min}}^{x_\\mathrm{max}} C p(x) dx\\approx C p(x)\\left(x_\\mathrm{max}-x_\\mathrm{min}\\right) = C p(x)\\Delta x\n", "\\end{equation}\n", "$$\n", "\n", "Now, for a distribution, we can write $\\Delta x=\\frac{x_\\mathrm{max}-x_\\mathrm{min}}{N_\\mathrm{bins}}$. Additionally, if we sum all bins, we have \n", "\n", "$$\n", "\\begin{eqnarray}\n", "N_{\\rm samples} & = & \\sum_{i=1}^{N} C p(x_{i}) \\Delta x \\\\\n", "\\end{eqnarray}\n", "$$\n", "\n", "Then, we can write our normalization term per bin as $N_{samples}\\Delta x$. Thus, per bin we write our function as\n", "\n", "$$\n", "\\begin{equation}\n", "f(x)= p(x) N_{\\rm samples} \\Delta x \n", "\\end{equation}\n", "$$"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true, "tags": ["learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L1.5-runcell02\n", "\n", "#Let's first add our numbers\n", "nsamples=1000\n", "bkg1 = np.random.uniform(0,10, nsamples)\n", "bkg2 = np.random.uniform(0,10, nsamples)\n", "data = bkg1+bkg2\n", "nbins=100\n", "\n", "#now we make a histogram\n", "histy, bin_edges = np.histogram(data, bins=nbins)\n", "bin_centers = 0.5*(bin_edges[1:] + bin_edges[:-1])\n", "\n", "#Now let's define our function. \n", "def function(ix,ntot=nsamples,inbins=nbins):#note the norm is for n bins over 0-20\n", "    if ix < 10:\n", "        return ntot*(20/inbins)*(ix/100)\n", "    else: \n", "        return ntot*(20/inbins)*(20-ix)/100\n", "\n", "def functionnp(ix,ntot=nsamples,inbins=nbins):#note the norm is for n bins over 0-20\n", "    return np.where(ix < 10,ntot*(20/inbins)*(ix/100),ntot*(20/inbins)*(20-ix)/100 )\n", "    \n", "#We need to evaluate the function, so we do it like this\n", "x = np.linspace(start=0, stop=20, num=100)\n", "#this list(map) is just a trick to run this function on all elements in the array\n", "#y = np.array(list(map(function, x)))\n", "y = functionnp(x) #this just uses numpy\n", "\n", "\n", "#plotting-------------------\n", "#plot size\n", "fig, ax = plt.subplots(figsize=(9,6))\n", "\n", "#plot data\n", "plt.plot(x, y,label='analytic PDF')\n", "plt.plot(bin_centers,histy,drawstyle = 'steps-mid')\n", "\n", "#plot labels and style\n", "plt.xlabel('x1+x2', fontsize=15) #Label x\n", "plt.ylabel('$N_\\mathrm{samples}$/bin', fontsize=15) #Label y\n", "plt.xticks(fontsize=12)\n", "plt.yticks(fontsize=12)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "lect_05"]}, "source": ["Now, to understand the power of sampling, let's make a much more complicated function based on sampling, and let's see what this more complicated function looks like. "]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["learner", "learner_chopped", "lect_05"]}, "outputs": [], "source": ["#>>>RUN: L1.5-runcell03\n", "\n", "#Sample something crazy\n", "bkg1 = np.random.uniform(0,10, 10000) # a random like before\n", "bkg2 = np.random.normal (5,2 , 10000) # a gaussian distribution centered about 2 with width 5\n", "data = bkg1+bkg2\n", "\n", "\n", "#plotting-------------------\n", "#plot size\n", "fig, ax = plt.subplots(figsize=(9,6))\n", "\n", "#plot data and axes limits\n", "histy, bin_edges = np.histogram(data, bins=20)\n", "bin_centers = 0.5*(bin_edges[1:] + bin_edges[:-1])\n", "#ax.set_ylim([0,150])\n", "\n", "#plot labels and style\n", "plt.plot(bin_centers,histy,drawstyle = 'steps-mid')\n", "plt.xlabel('x', fontsize=15) #Label x\n", "plt.ylabel('f(x)', fontsize=15) #Label y\n", "plt.xticks(fontsize=12)\n", "plt.yticks(fontsize=12)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "lect_05"]}, "source": ["The point of this is that we can put sample events from any distribution we want, and make very complicated distributions that have all sorts of features. Instead of going through the analytical calculations to figure out what these distributions look like, we can simply sample!"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner"]}, "source": ["<a name='exercises_1_5'></a>\n", "\n", "| [Top](#section_1_0) | [Restart Section](#section_1_5) | [Next Section](#section_1_6) |"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "learner_chopped"]}, "source": ["<!--start-block-->\n", "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-1.5.1: Generalizing the Sum Distribution</span>\n", "\n", "Let's generalize the sum distribution. Compute the sum of 3 random variables that are distributed uniformly between 0 and 1 (draw 10000 samples, as was done abobe). Plot the histogram of this sum, as was done above. Try the sum of 4 random variables.\n", "\n", "How does the sum distribution behave as we scale to N uniform random variables? Choose from the options below:\n", "\n", "- it looks like a uniform distribtion\n", "- it looks like a sharper triangle shape\n", "- it looks like a normal distribution"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "learner_chopped"]}, "source": ["<!--start-block-->\n", "<a name='section_1_6'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L1.6 Generalizing to Many Measurements</h2>\n", "    \n", "| [Top](#section_1_0) | [Previous Section](#section_1_5) | [Exercises](#exercises_1_6) |\n"]}, {"cell_type": "markdown", "metadata": {"tags": ["8S50x", "learner"]}, "source": ["*The material in this section is discussed in the video **<a href=\"https://courses.mitxonline.mit.edu/learn/course/course-v1:MITxT+8.S50.1x+3T2022/block-v1:MITxT+8.S50.1x+3T2022+type@sequential+block@seq_LS1/block-v1:MITxT+8.S50.1x+3T2022+type@vertical+block@vert_LS1_vid5\" target=\"_blank\">HERE</a>.** You are encouraged to watch that video and use this notebook concurrently.*"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "lect_06"]}, "source": ["<h3>Overview</h3>\n", "\n", "Let's consider a set of measurements. Like we had with the two variables, if we take $N$ measurements, we can treat them as $N$ separate variables. Often the measurements can be sampled from the same distribution (like we had for the above case). \n", "\n", "Typically, we treat these measurements as independent variables. This means that the result of any one of the measurement doesn't affect the results of any of the other measurements. The probability distributions of these is similar to the case above where we had two measurements $x_{1}$ and $x_{2}$.  Like the 2D probability distribution we had before, we now have $N$ variables, yielding an $N$ dimensional distribution. Yes, this is complicated! But, it won't get too scary. \n", "\n", "To deal with this very high dimensional space, we can define the joint PDF distribution of these as the multiplication of the individual PDFs. For two independent measurements it's:\n", "\n", "$$\n", "\\begin{equation}\n", "p(x_{1},x_{2})=p(x_{1})p(x_{2}) \\\\\n", "\\end{equation}\n", "$$\n", "\n", "For $N$ independent measurements it is, \n", "\n", "$$\n", "\\begin{equation}\n", "p(x_{1},...,x_{N})=\\prod_{i=1}^{i=N}p(x_{i})\n", "\\end{equation}\n", "$$\n", "\n", "Let's visualize some measurements sampled from the same distribution. We will take two measurements, $x_{1}$ and $x_{2}$, and, because we can, we will run this experiment 1000 times. To perform this experiment, we will use a normal distribution, which is defined as \n", "\n", "$$\n", "\\begin{equation}\n", "\\mathcal{N}(x; \\mu,\\sigma) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\n", "\\end{equation}\n", "$$\n", "\n", "where $\\mu$ and $\\sigma$ are the mean and standard deviation, respectively, of the distribution and the fraction before the exponential is required for the integral of the distribution to equal 1.\n", "\n", "This is a distribution that we will use quite extensively in this course.     "]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["learner", "learner_chopped", "lect_06"]}, "outputs": [], "source": ["#>>>RUN: L1.6-runcell01\n", "\n", "#Let's first add our numbers\n", "nsamples=1000\n", "mu=0\n", "sigma=1\n", "x1 = np.random.normal(mu,sigma, nsamples)\n", "x2 = np.random.normal(mu,sigma, nsamples)\n", "\n", "#plotting-------------------\n", "#plot size\n", "fig, ax = plt.subplots(figsize=(6,6)) #a square plot size is more useful for this data\n", "\n", "#plot data and axes limits\n", "plt.scatter(x1,x2,)\n", "plt.xlim(-4,4)\n", "plt.ylim(-4,4)\n", "\n", "#plot labels and style\n", "plt.title(\"Joint PDF of two normal distributions\", fontsize=15)\n", "plt.xlabel('x1', fontsize=15) #Label x\n", "plt.ylabel('x2', fontsize=15) #Label y\n", "plt.xticks(fontsize=12)\n", "plt.yticks(fontsize=12)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "lect_06"]}, "source": ["Now, from this setup, we can define a bunch of variables that help to understand the data. We call the variables that we define \"observables\" or data summaries. Let's list the definition of these variables, and then we will go ahead and see what we can do with them. First, we define the mean $\\bar{x}$ of our *sample* (not necessarily of the distribution). \n", "\n", "$$\n", "\\begin{equation}\n", "\\bar{x}=\\frac{1}{N}\\sum_{i=1}^{N} x_{i}\n", "\\end{equation}\n", "$$\n", "\n", "To be clear, this is an observable, (i.e., a calculation), that we perform on the data that we have at hand. \n", "\n", "We can then compute the expectation of $\\bar{x}$ for our sampled distribution. This expectation gives us: \n", "\n", "$$\n", "\\begin{eqnarray}\n", "E[\\bar{x}]&=&\\int \\left(\\frac{1}{N}\\sum_{i=1}^{N} x_{i}\\right)\\prod_{i=0}^{i=N}p(x_{i}) dx_{i}\\\\\n", "          &=&\\frac{1}{N}\\sum_{i=1}^{N}\\left(\\int x_{j}\\prod_{i=0}^{i=N}p(x_{i}) dx_{i}\\right)\\\\\n", "          &=&\\frac{1}{N}\\times N \\int x_{i} p(x_{i}) dx_{i}\\\\\n", "E[\\bar{x}]&=&E[x]\\\\\n", "\\end{eqnarray}\n", "$$\n", "\n", "Or, on average, our sample mean $\\bar{x}$ will be the mean of the distribution. \n", "\n", "Now, we can define the variance of the data in a similar way\n", "\n", "$$\n", "\\begin{equation}\n", "V(x)=\\frac{1}{N}\\sum_{i=1}^{N} (x_{i}-\\bar{x})^{2}\n", "\\end{equation}\n", "$$\n", "\n", "Note that the form above is very similar to the variance of a distribution, defined by\n", "\n", "$$\n", "\\begin{eqnarray}\n", "E\\left[V(x)\\right]&=&\\frac{1}{N}\\int_{-\\infty}^{\\infty}\n", "\\left(\\sum_{i=1}^{N}\\left(x_{i}-\\bar{x}\\right)^{2}\\right)\\prod_{i=0}^{i=N}p(x_{i}) dx_{i}\\\\\n", "E\\left[V(x)\\right]&=&\\frac{1}{N}\\sum_{i=1}^{N}\\int_{-\\infty}^{\\infty}\\left(x_{i}-\\bar{x}\\right)^{2} p(x_{i}) dx_{i}\\\\\n", "E\\left[V(x)\\right]&=&\\frac{N}{N}E[(x-\\bar{x})^2]\\\\\n", "E\\left[V(x)\\right]&=&V(x)\\\\\n", "\\end{eqnarray}\n", "$$\n", "\n", "And now we can consider the variance of these distributions. Let's do the variance of our defined $\\bar{x}$. First let's derive it for just one variable. \n", "\n", "$$\n", "\\begin{eqnarray}\n", "V\\left[\\bar{x}\\right]&=&\\int (x_i-\\bar{x})^2 p(x_i)dx_i\\\\\n", "                     &=&\\int (x^2_i-2x_{i}\\bar{x}+\\bar{x}^2) p(x_i)dx_i\\\\\n", "                     &=&\\int x^2_i p(x_i)dx_i - 2\\bar{x}^2+\\bar{x}^2\\\\\n", "                     &=&\\int x^2_i p(x_i)dx_i -  \\bar{x}^2\\\\\n", "                     &=&\\int (x^2_i-\\bar{x}^2) p(x_i)dx_i  \n", "\\end{eqnarray}\n", "$$"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "lect_06"]}, "source": ["Now, let's generalize this whole thing to $N$ measurements. I would like to warn you that this is a complicated calculation; it's not the focus of this course, but it's here for completeness.\n", "\n", "$$\n", "\\begin{eqnarray}\n", "V\\left[\\bar{x}\\right]&=&\\int \\left(\\frac{1}{N}\\sum_{i=1}^{N} x_{i}-\\bar{x}\\right)^{2} \\Pi_{i=0}^{i=N}p(x_{i}) dx_{i} \\\\\n", "V\\left[\\bar{x}\\right]&=&\\int \\left(\\frac{1}{N}\\right)^2 \\left( \\left(\\sum_{i=1}^{N} x_{i}\\right)^2-2N\\left(\\sum_{i=1}^{N} x_{i}\\right)\\bar{x}+ N^2\\bar{x}^2\\right)\\Pi_{i=0}^{i=N}p(x_{i}) dx_{i}\\\\\n", "V\\left[\\bar{x}\\right]&=&\\int \\left(\\frac{1}{N}\\right)^2 \\left( \\left(\\sum_{i=1}^{N} x_{i}\\right)^2\\right) \\Pi_{i=0}^{i=N}p(x_{i}) dx_{i}-\\frac{2}{N}\\bar{x}N\\bar{x}+\\bar{x}^2 \\\\\n", "V\\left[\\bar{x}\\right]&=&\\int \\left(\\frac{1}{N}\\right)^2 \\left( \\left(\\sum_{i=1}^{N} x_{i}\\right)\\left(\\sum_{i=1}^{N} x_{i}\\right) \\right) \\Pi_{i=0}^{i=N}p(x_{i}) dx_{i}-\\bar{x}^2\\\\\n", "V\\left[\\bar{x}\\right]&=&\\int \\left(\\frac{1}{N}\\right)^2 \\left(\\sum_{i} x_{i}^2 + 2\\sum_{i}\\sum_{j\\neq i}x_{i}x_{j} \\right) \\Pi_{i=0}^{i=N}p(x_{i}) c-\\bar{x}^2\\\\\n", "V\\left[\\bar{x}\\right]&=&\\int \\left(\\frac{1}{N}\\right)^2 \\left(\\sum_{i} x_{i}^2\\right)\\Pi_{i=0}^{i=N}p(x_{i})dx_{i} + \\frac{(N-1)}{N}\\bar{x}^2-\\bar{x}^2\\\\\n", "V\\left[\\bar{x}\\right]&=&\\int \\left(\\frac{1}{N}\\right)^2 \\left(\\sum_{i} x_{i}^2 -N\\bar{x}^2\\right)\\Pi_{i=0}^{i=N}p(x_{i})dx_{i} + \\frac{1}{N}\\bar{x}^2 + \\frac{(N-1)}{N}\\bar{x}^2-\\bar{x}^2\\\\\n", "V\\left[\\bar{x}\\right]&=&\\left(\\frac{1}{N}\\right) \\int \\left(\\frac{1}{N}\\right) \\left(\\sum_{i} x_{i}^2 -N\\bar{x}^2\\right)\\Pi_{i=0}^{i=N}p(x_{i})dx_{i} \\\\\n", "V\\left[\\bar{x}\\right]&=&\\left(\\frac{1}{N}\\right) \\left(\\frac{1}{N}\\right)N V(x) \\\\\n", "V\\left[\\bar{x}\\right]&=&\\left(\\frac{1}{N}\\right) V(x) \\\\\n", "\\end{eqnarray}\n", "$$\n", "\n", "where $V(x)$ is the variance of any distribution. This is very important. What this means is that if we sample many times a distribution with a variance $\\sigma^2$, we have that the variance of the average over this distribution scales as $\\frac{1}{N}$ times the variance of the sampled distribution. This means that if you are measuring the mean, the uncertainty on the mean scales as the $\\sqrt{V[\\bar{x}]}=\\sqrt{\\frac{1}{N}V[x]}$. \n", "\n", "We will state without proof that the variance scales in a similar way. \n", "\n", "\n", "$$\n", "\\begin{eqnarray}\n", "V\\left[V(\\bar{x})\\right]&=&\\left(\\frac{1}{2N}\\right) V(x) \\\\\n", "\\end{eqnarray}\n", "$$\n", "\n", "To understand how this works, let's run some toy calculations. \n", "\n", "<br>\n", "<!--end-block-->"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "lect_06"]}, "source": ["In the following code, we first generate one sample and measure its mean and rms (remember, rms is the squareroot of the variance). Then, we estimate the rms in those quantities by generating 100 samples and calculating the rms of those two observables. In other words, we will calculate the rms of the mean and the rms of the rms from simulated data.\n", "\n", "Since, as mentioned above, the variances of both observables are similar, we add 1 to the rms of the rms in order to more clearly separate the two on the plot."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["learner", "learner_chopped", "lect_06"]}, "outputs": [], "source": ["#>>>RUN: L1.6-runcell02\n", "\n", "import math\n", "\n", "#define a function that samples a normal distribution N times and then returns mean and root mean-square rms \n", "#(also known as standard deviation, the square root of variance)\n", "def sample(iN,imean,istdev):\n", "    sample = np.random.normal(imean,istdev,iN)\n", "    return sample.mean(),sample.std()\n", "\n", "#This function runs 100 tests where we sample N times, we call these toys\n", "def meansample(iN,imean,istdev):\n", "    ntoys=100\n", "    allmeans=np.array([])\n", "    allrmses=np.array([])\n", "    for i0 in range(ntoys):\n", "        pMean,pRMS=sample(iN,imean,istdev)\n", "        allmeans=np.append(allmeans,pMean)\n", "        allrmses=np.append(allrmses,pRMS)\n", "    return allmeans.std(),allrmses.std()\n", "\n", "\n", "def get_sim_mean_rms(isamples,imean,istdev):\n", "  nvar=np.array([])\n", "  mean=np.array([])\n", "  rms=np.array([])\n", "\n", "  distmean=np.array([])\n", "  distrms=np.array([])\n", "\n", "\n", "  #Now we iterate from 1 to 250 in sampling and compute mean and RMS\n", "  for i0 in range(isamples):\n", "      nvar = np.append(nvar,i0)\n", "\n", "      #Sample just once \n", "      pMean,pRMS=sample(i0,imean,istdev)\n", "      distmean = np.append(distmean,pMean)\n", "      distrms  = np.append(distrms,pRMS)\n", "\n", "      #sample many times\n", "      pMean,pRMS=meansample(i0,imean,istdev)\n", "      mean = np.append(mean,pMean)\n", "      rms  = np.append(rms,pRMS)\n", "    \n", "  return nvar, distmean, mean, rms\n", "\n", "\n", "isamples,imean,istdev = [250,0,1]\n", "nvar, distmean, mean, rms = get_sim_mean_rms(isamples,imean,istdev)\n", "\n", "\n", "# plt.plot(nvar,funcmean,'--',label='func rms of mean')\n", "# plt.plot(nvar,funcrms,'--',label='func rms of rms')\n", "plt.plot(nvar,distmean,label='mean')\n", "plt.plot(nvar,distrms,label='rms')\n", "plt.plot(nvar,mean,label='rms of mean')\n", "plt.plot(nvar,rms + np.ones(len(rms)),label='rms of rms') # Add 1 to the rms to separate these two quantities in the plot\n", "plt.legend(loc='lower right')\n", "plt.xlabel(\"Number of samples\")\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "lect_06"]}, "source": ["As you can see from the plot, the mean and rms of a single sample fluctuate a lot for small sample sizes, a fact that is quantified by the relatively large standard deviations (rms) of those two observables. As we increase the size of the samples, the rms of the mean and the rms of the rms decrease asymptotically  (don't forget that the rms of the rms is increased by 1 on the plot for clarity). This same effect is seen in the reduced fluctuations in the values of the mean and rms for single samples.\n", "\n", "This means that with larger samples, we can be more confident in our measurement of the distribution's mean and rms. Note that the shape of the decrease of the two variances matches quite well the prediction of $1/\\sqrt{N}$ and $1/ \\sqrt{2N}$ scaling for the rms of the mean and rms, respectively (recall that the rms or standard deviation is the square root of the variance)."]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "learner_chopped"]}, "source": ["<a name='exercises_1_6'></a>\n", "\n", "| [Top](#section_1_0) | [Restart Section](#section_1_6) |"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-1.6.1: Variance of the Mean and Variance of the Variance</span>\n", "\n", "We know that the variance and mean for a normal distribution are \n", "\n", "$$\n", "\\begin{eqnarray}\n", "E(\\mathcal N(x; \\mu,\\sigma)) & = & \\mu \\\\\n", "V(\\mathcal N(x; \\mu,\\sigma)) & = & \\sigma^2 \\\\\n", "\\end{eqnarray}\n", "$$\n", "\n", "Now we wish to derive a functional form for $\\sqrt{V[\\bar{x}]}$ (the rms of the mean) and $\\sqrt{V\\left[(x-\\bar{x})^2\\right]}$ (the rms of the rms), and compare with simulated data.\n", "\n", "Write a function that accepts an array and returns the rms of the mean and the rms of the rms."]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "learner_chopped", "8S50x"]}, "source": ["**Reminder:** Your final answers **must** always be submitted on MITx."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L1.6.1\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "\n", "def func_rms_mean(isample_array,imean,istdev):\n", "    rms_mean = 0. #complete the function\n", "    return rms_mean\n", "    \n", "\n", "def func_rms_rms(isample_array,imean,istdev):\n", "    #this is a piecewise function with rms=0 for isample[i]=1\n", "    rms_rms = 0. #complete the function\n", "    return np.where(isample_array <=1, 0, rms_rms)\n"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "learner_chopped"]}, "source": [">#### Follow-up 1.6.1a (ungraded)\n", ">\n", ">Plot the functions that correspond to the rms of the mean and the rms of the rms, and compare these predictions with the results from simulated data."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true, "tags": ["learner"]}, "outputs": [], "source": ["#>>>FOLLOW-UP: L1.6.1a\n", "# Run this cell as follow-up to the previous exercise.\n", "\n", "#make plots\n", "#####################\n", "def get_new_func_mean_rms(isamples,imean,istdev):\n", "    sample_array = np.arange(1,isamples+1,1)\n", "    \n", "    funcrmsmean = func_rms_mean(sample_array,imean,istdev)\n", "    funcrmsrms = func_rms_rms(sample_array,imean,istdev)\n", "    return funcrmsmean, funcrmsrms\n", "\n", "\n", "isamples,imean,istdev = [250,0,1]\n", "nvar, mean_mean, rms_mean, rms_rms = get_sim_mean_rms(isamples,imean,istdev)\n", "funcrmsmean, funcrmsrms = get_new_func_mean_rms(isamples,imean,istdev)\n", "\n", "\n", "\n", "def plot_mean_and_rms_mean_vals():\n", "    plt.errorbar(nvar,mean_mean,yerr=rms_mean, ecolor='red', label='mean and rms of mean')\n", "    plt.legend(loc=1)\n", "    plt.xlabel(\"Number of samples\")\n", "    plt.show()\n", "    return\n", "\n", "\n", "def plot_rms_mean_vals():\n", "    plt.plot(nvar,rms_mean,label='rms of mean')\n", "    plt.plot(nvar,funcrmsmean,'--',label='func rms of mean')\n", "    plt.legend(loc=1)\n", "    plt.xlabel(\"Number of samples\")\n", "    plt.show()\n", "    return\n", "\n", "def plot_rms_rms_vals():\n", "    plt.plot(nvar,rms_rms,label='rms of rms')\n", "    plt.plot(nvar,funcrmsrms,'--',label='func rms of rms')\n", "    plt.legend(loc=1)\n", "    plt.xlabel(\"Number of samples\")\n", "    plt.show()\n", "    return\n", "\n", "def plot_residuals():\n", "    plt.plot(nvar,funcrmsmean - rms_mean,'--',label='func rms of mean residuals')\n", "    plt.plot(nvar,funcrmsrms - rms_rms,'--',label='func rms of rms residuals')\n", "    plt.legend(loc=1)\n", "    plt.xlabel(\"Number of samples\")\n", "    plt.show()\n", "    return\n", "\n", "\n", "plot_mean_and_rms_mean_vals()\n", "plot_rms_mean_vals()\n", "plot_rms_rms_vals()\n", "plot_residuals()"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "learner_chopped"]}, "source": [">#### Follow-up 1.6.1b (ungraded)\n", ">   \n", ">Sample a normal distribution of mean 1 and variance $\\sigma$ with an increasing number of events, N. What do you observe as the trend of this distribution as a function of N?\n", "\n"]}], "metadata": {"celltoolbar": "Tags", "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}