{"cells": [{"cell_type": "markdown", "id": "d6d3c5b9", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<hr style=\"height: 1px;\">\n", "<i>This notebook was authored by the 8.S50x Course Team, Copyright 2022 MIT All Rights Reserved.</i>\n", "<hr style=\"height: 1px;\">\n", "<br>\n", "\n", "<h1>Lesson 2: Binomial, Poisson, and Gaussian Distributions</h1>\n"]}, {"cell_type": "markdown", "id": "8f15f03f", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_2_0'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L2.0 Overview</h2>\n"]}, {"cell_type": "markdown", "id": "63e300db", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<h3>Navigation</h3>\n", "\n", "<table style=\"width:100%\">\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_2_1\">L2.1 Introduction to Binomial Distribution</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_2_1\">L2.1 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_2_2\">L2.2 Applications Using the Binomial Distribution</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_2_2\">L2.2 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_2_3\">L2.3 The Poisson Distribution</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_2_3\">L2.3 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_2_4\">L2.4 Poisson Distribution Continued</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_2_4\">L2.4 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_2_5\">L2.5 The Gaussian Distribution</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_2_5\">L2.5 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_2_6\">L2.6 Uncertainties in Measurement</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_2_6\">L2.6 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_2_7\">L2.7 Propagating Uncertainties</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_2_7\">L2.7 Exercises</a></td>\n", "    </tr>\n", "</table>\n", "\n"]}, {"cell_type": "markdown", "id": "d39fe23b", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<h3>Importing Data (Colab Only)</h3>\n", "\n", "If you are in a Google Colab environment, run the cell below to import the data for this notebook. Otherwise, if you have downloaded the course repository, you do not have to run the cell below.\n", "\n", "See the source and attribution information below:\n", "\n", ">data: data/L02/tmpdata.txt, data/L02/tmpmc.txt<br>\n", ">source:  https://arxiv.org/pdf/1104.0699.pdf<br>\n", ">attribution: CDF Collaboration, arXiv:1104.0699v2<br>\n", ">license type: https://arxiv.org/licenses/nonexclusive-distrib/1.0/license.html"]}, {"cell_type": "code", "execution_count": null, "id": "2ea4c4c1", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN L2.0-runcell00\n", "\n", "#Importing data:\n", "\n", "!git init\n", "!git remote add -f origin https://github.com/mitx-8s50/nb_LEARNER/\n", "!git config core.sparseCheckout true\n", "!echo 'data/L02' >> .git/info/sparse-checkout\n", "!git pull origin main"]}, {"cell_type": "code", "execution_count": null, "id": "fec93314", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L2.0-runcell01\n", "\n", "# The documentation to these packages is linked beside them if you have questions\n", "\n", "import numpy as np                 #https://numpy.org/doc/stable/ \n", "from scipy.special import comb     #https://docs.scipy.org/doc/scipy/reference/special.html\n", "import scipy.stats as stats        #https://docs.scipy.org/doc/scipy/reference/stats.html\n", "import matplotlib.pyplot as plt    #https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.html"]}, {"cell_type": "code", "execution_count": null, "id": "109098ea", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L2.0-runcell02\n", "\n", "#set plot resolution\n", "%config InlineBackend.figure_format = 'retina'\n", "\n", "#set default figure parameters\n", "plt.rcParams['figure.figsize'] = (9,6)\n", "\n", "medium_size = 12\n", "large_size = 15\n", "\n", "plt.rc('font', size=medium_size)          # default text sizes\n", "plt.rc('xtick', labelsize=medium_size)    # xtick labels\n", "plt.rc('ytick', labelsize=medium_size)    # ytick labels\n", "plt.rc('legend', fontsize=medium_size)    # legend\n", "plt.rc('axes', titlesize=large_size)      # axes title\n", "plt.rc('axes', labelsize=large_size)      # x and y labels\n", "plt.rc('figure', titlesize=large_size)    # figure title"]}, {"cell_type": "markdown", "id": "cbea03c9", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_2_1'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L2.1 Introduction to Binomial Distribution</h2>  \n", "\n", "| [Top](#section_2_0) | [Previous Section](#section_2_0) | [Exercises](#exercises_2_1) | [Next Section](#section_2_2) |\n"]}, {"cell_type": "code", "execution_count": null, "id": "149413af", "metadata": {"tags": ["learner", "py", "lect_01", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L2.1-runcell01\n", "\n", "import numpy as np\n", "from scipy.special import comb\n", "print(\"Test comb:\",comb(2,1),\"True: 2\",comb(3,2),\"True: 3\",comb(10,3),\"True: 120\")\n", "\n", "#for p=0.5, what is the probability of 3 heads out of 10 draws?\n", "def prob(p=0.5,nheads=3,ntotal=10):\n", "    pheads=np.power(p,nheads)\n", "    ptails=np.power(1-p,ntotal-nheads)\n", "    combos=comb(ntotal,nheads)\n", "    return combos*ptails*pheads\n", "\n", "print(\"Probability of 3 heads in 10 draws is:\",prob(nheads=3,ntotal=10))"]}, {"cell_type": "code", "execution_count": null, "id": "9fbc58b5", "metadata": {"tags": ["learner", "py", "lect_01", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L2.1-runcell02\n", "\n", "#We are going to use scipy stats package\n", "import numpy as np\n", "import scipy.stats as stats\n", "import matplotlib.pyplot as plt\n", "n=30\n", "p=0.25\n", "\n", "#Scipy has a binomial, but since this is a discrete distribution we use pmf (probability mass function) rather than pdf\n", "k=np.arange(0,n)\n", "binomial=stats.binom.pmf(k,n,p)\n", "\n", "#let's get the integral of this guy\n", "norm=0\n", "exp=0\n", "var=0\n", "for i0 in range(n):\n", "    norm+=stats.binom.pmf(i0,n,p)\n", "    exp+=i0*stats.binom.pmf(i0,n,p)\n", "for i0 in range(n):\n", "    pVal=stats.binom.pmf(i0,n,p)\n", "    var+=(i0-exp/norm)*(i0-exp/norm)*pVal\n", "\n", "#Print it out\n", "print(\"norm:\",norm,\"expectation:\",exp/norm,\"Var:\",var/norm)\n", "\n", "#Now let's check with the expectation\n", "print(\"norm: 1.000000, expectation:\",n*p,\"Var:\",n*p*(1-p))\n", "\n", "plt.plot(k,binomial,'o')\n", "plt.vlines(k,0, binomial)\n", "plt.ylim(bottom=0)\n", "\n", "plt.xlabel(\"Number of successes\")\n", "plt.ylabel(\"Probability\")\n", "plt.show()"]}, {"cell_type": "markdown", "id": "267e36b8", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='exercises_2_1'></a>     \n", "\n", "| [Top](#section_2_0) | [Restart Section](#section_2_1) | [Next Section](#section_2_2) |\n"]}, {"cell_type": "markdown", "id": "f2695caa", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-2.1.1: Probability as a Function of Coin Fairness</span>\n", "\n", "In order to answer this question, plot the probability of flipping a coin 10 times and observing 3 heads, for varying \"coin fairness.\" In other words, as a function of probability $p$ (i.e., the probability $p$ of getting a heads is varying).\n", "\n", "\n", "<u>Hint:</u> Use the previously defined function `prob(p=0.5,nheads=3,ntotal=10)` and vary `p`, or use the built-in function `stats.binom.pmf(k,n,p)`, defined <a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.binom.html\" target=\"_blank\">here</a>.\n", "\n", "\n", "As the probability $p$ varies from 0 to 1, which of the following correctly describes the behavior? The probability of observing 3 head out of 10 flips...\n", "\n", "- keeps increasing to a value of 1 when p=1\n", "- keeps decreasing to a value of 0 when p=1\n", "- increases from 0 at p=0 to a maximum value, then decreases to 0 at p=1\n", "- maintains a constant value for all p"]}, {"cell_type": "code", "execution_count": null, "id": "8decfd1b", "metadata": {"tags": ["py", "draft"]}, "outputs": [], "source": ["#>>>EXERCISE: L2.1.1\n", "# Use this cell for drafting your solution (if desired)\n", "\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "from scipy.special import comb\n", "\n", "#for p=0.5, what is the probability of 3 heads out of 10 draws?\n", "def prob(p=0.5,nheads=3,ntotal=10):\n", "    #YOUR CODE HERE\n", "    return\n", "\n", "\n", "def plot_prob(x):\n", "    #plotting-------------------\n", "    #plot data\n", "    ydata = prob(p=x,nheads=3,ntotal=10)\n", "    plt.plot(x, ydata, 'o')\n", "    plt.vlines(x,0, ydata)\n", "    plt.ylim(bottom=0)\n", "\n", "    #plot labels and style\n", "    plt.title('Probability of 3 Heads in 10 Draws for Varying Coin Fairness', fontsize=15)\n", "    #plt.legend(loc='lower right', fontsize = 12)\n", "    plt.xlabel('Coin Fairness (Probability of Landing Heads)', fontsize=15) #Label x\n", "\n", "    # changing the fontsize of ticks\n", "    plt.xticks(fontsize=12)\n", "    plt.yticks(fontsize=12)\n", "\n", "    # a grid\n", "    plt.grid()\n", "    plt.show()\n", "    \n", "    \n", "prob_vals = np.linspace(0,1,11)\n", "plot_prob(prob_vals)"]}, {"cell_type": "markdown", "id": "188d58b6", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-2.1.2: Rolling a Die</span>\n", "\n", "Now, instead of flipping a coin, consider rolling a die 10 times. If the die lands on 6, we consider the trial a success. If the die lands on anything other than 6, we consider the trial a failure. Using the formulae for expectation and variance that we previously defined, calculate the expectation and variance of the binomial distribution related to these criteria.\n", "\n", "Enter your answer as a list of numbers with precision 1e-2: `[expectation, variance]`"]}, {"cell_type": "markdown", "id": "d5f9a1e7", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": [">#### Follow-up 2.1.2a (ungraded)\n", ">    \n", ">Plot the binomial distribution of these trials, and calculate the norm (which should be 1), expectation, and variance. Use the starting code below."]}, {"cell_type": "code", "execution_count": null, "id": "6a003d42", "metadata": {"tags": ["draft", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>FOLLOW-UP: L2.1.2a\n", "# Use this cell for drafting your solution (if desired)\n", "\n", "#Follow example given in L2.1\n", "import scipy.stats as stats\n", "import matplotlib.pyplot as plt\n", "\n", "n=10\n", "p=1/6\n", "\n", "#use pmf rather than pdf\n", "k=np.arange(0,n)\n", "binomial=stats.binom.pmf(k,n,p)\n", "\n", "\n", "def get_binom_integral(n,p):\n", "    #get the integral\n", "    ##########\n", "    #YOUR CODE HERE\n", "    ##########\n", "    return norm, exp, pVal, var\n", "\n", "norm, exp, pVal, var = get_binom_integral(n,p)\n", "\n", "#print\n", "print(\"norm:\",norm,\"expectation:\",exp/norm,\", Var:\",var/norm)\n", "\n", "#check\n", "print(\"norm: 1.000000, expectation:\",n*p,\", Var:\",n*p*(1-p))\n", "\n", "    \n", "plt.plot(k,binomial,'o')\n", "plt.vlines(k,0, binomial)\n", "plt.ylim(bottom=0)\n", "\n", "plt.xlabel(\"Number of successes\")\n", "plt.ylabel(\"Probability\")\n", "plt.show()"]}, {"cell_type": "markdown", "id": "3ab245b0", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_2_2'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L2.2 Applications Using the Binomial Distribution</h2>  \n", "\n", "| [Top](#section_2_0) | [Previous Section](#section_2_1) | [Exercises](#exercises_2_2) | [Next Section](#section_2_3) |\n"]}, {"cell_type": "code", "execution_count": null, "id": "99c8c63b", "metadata": {"tags": ["learner", "py", "lect_02", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L2.2-runcell01\n", "\n", "def prob(ndays=2,nobs=2,p=19/365):\n", "    return stats.binom.pmf(nobs,ndays,p)\n", "\n", "print(\"2 observations in 2 days:\",prob())\n", "print(\"2 observations in 7 days:\",prob(7))\n", "print(\"19 observations in 365 days:\",prob(365,19))\n"]}, {"cell_type": "code", "execution_count": null, "id": "78aa681e", "metadata": {"tags": ["learner", "py", "lect_02", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L2.2-runcell02\n", "\n", "p=19/365\n", "n=365\n", "k=np.arange(0,50)\n", "binomial=stats.binom.pmf(k,n,p)\n", "\n", "def plotBinomial(iX,iBinomial,label='Binomial',color='black'):\n", "    plt.plot(iX,iBinomial,'o')\n", "    plt.vlines(iX,0, iBinomial,label=label,color=color)\n", "    plt.ylim(bottom=0)\n", "    plt.xlabel(\"Number of observations per year\")\n", "    plt.ylabel(\"Probability\")\n", "\n", "plotBinomial(k,binomial)\n"]}, {"cell_type": "code", "execution_count": null, "id": "8d21604c", "metadata": {"tags": ["learner", "py", "lect_02", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L2.2-runcell03\n", "\n", "p=19/365\n", "n=365\n", "k=np.arange(0,50)\n", "binomial=stats.binom.pmf(k,n,p)\n", "binomialcdf=stats.binom.cdf(k,n,p)\n", "print(\"cdf at 19:\",stats.binom.cdf(19,n,p))\n", "\n", "plt.plot(k,binomialcdf,'o', label=\"Binomial CDF\")\n", "plt.vlines(k,0, binomialcdf, color=plt.gca().lines[-1].get_color())\n", "plt.ylim(bottom=0)\n", "\n", "plt.plot(k,binomial,'o', label=\"Binomial PMF\")\n", "plt.vlines(k,0, binomial, color=plt.gca().lines[-1].get_color())\n", "plt.ylim(bottom=0)\n", "\n", "plt.xlabel(\"Number of observations per year\")\n", "plt.ylabel(\"Probability\")\n", "plt.legend()\n", "plt.show()\n", "\n", "\n", "mean = np.average(k, weights=binomial)\n", "variance = np.average((k-mean)**2, weights=binomial)\n", "print(\"mean:\",mean,\"stddev:\",np.sqrt(variance))\n", "\n"]}, {"cell_type": "markdown", "id": "e2af4818", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='exercises_2_2'></a>     \n", "\n", "| [Top](#section_2_0) | [Restart Section](#section_2_2) | [Next Section](#section_2_3) |\n"]}, {"cell_type": "markdown", "id": "5febd043", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-2.2.1: Rate of GW Detections</span>\n", "\n", "Let's do another related problem. With the current rate of gravitational wave (GW) detections, we observe a GW once per week. What is the probability that on 3 or more days gravitational waves are detected in one week? Use the starting code below to compute your answer."]}, {"cell_type": "code", "execution_count": null, "id": "ab40146a", "metadata": {"tags": ["solution", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L2.2.1\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "import numpy as np\n", "import scipy.stats as stats\n", "\n", "def plotBinomial(iX,iBinomial,label='Binomial',color='black'):\n", "    plt.plot(iX,iBinomial,'o')\n", "    plt.vlines(iX,0, iBinomial,label=label,color=color)\n", "    plt.ylim(bottom=0)\n", "    plt.xlabel(\"Number of observations per week\")\n", "    plt.ylabel(\"Probability\")\n", "\n", "n = #YOUR CODE HERE\n", "p = #YOUR CODE HERE\n", "k = #YOUR CODE HERE\n", "\n", "binomial=stats.binom.pmf(k,n,p)\n", "total1=0\n", "for i0 in range(len(k)):\n", "    if k[i0] > 2:\n", "        total1+= binomial[i0]\n", "\n", "print(\"binomial:\",total1)\n", "\n", "plotBinomial(k,binomial)\n", "plt.show()"]}, {"cell_type": "markdown", "id": "0417592e", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": [">#### Follow-up 2.2.1a (ungraded)\n", ">  \n", ">Try plotting this distribution! Additionally, what is the probability distribution for the number of GW events observed over a whole year, and what is the mean and variance of this distribution? Use the starting code below."]}, {"cell_type": "code", "execution_count": null, "id": "3ad465dc", "metadata": {"tags": ["py", "draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>FOLLOW-UP: L2.2.1a\n", "# Use this cell for drafting your solution (if desired)\n", "\n", "import scipy.stats as stats\n", "\n", "def plotBinomial(iX,iBinomial,label='Binomial',color='black'):\n", "    plt.plot(iX,iBinomial,'o')\n", "    plt.vlines(iX,0, iBinomial,label=label,color=color)\n", "    plt.ylim(bottom=0)\n", "    plt.xlabel(\"Number of observations per year\")\n", "    plt.ylabel(\"Probability\")\n", "\n", "\n", "\n", "#now what about for GWs in a year\n", "n = #YOUR CODE HERE\n", "p = #YOUR CODE HERE\n", "k = #YOUR CODE HERE\n", "\n", "binomial=stats.binom.pmf(k,n,p)\n", "\n", "plotBinomial(k,binomial)\n", "plt.show()\n", "\n", "average  = np.average(k, weights=binomial)\n", "variance = np.average((k-average)**2, weights=binomial)\n", "print(\"mean:\",average,\"stddev:\",np.sqrt(variance))\n", "\n"]}, {"cell_type": "markdown", "id": "d98afb62", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-2.2.2: Probability of Coin Flips</span>\n", "\n", "What is the probability of 2 heads in 10 coin flips, given a 50% probability for heads? What about if there is a 10% probability for heads?\n", "\n", "Enter your answer as a list of two numbers, where the numbers correspond to probabilities: `[prob with p=50%, prob with p=10%]`\n", "\n", "Use the starting code below to aid your calculation."]}, {"cell_type": "code", "execution_count": null, "id": "b1378c33", "metadata": {"tags": ["draft", "py"]}, "outputs": [], "source": ["#>>>EXERCISE: L2.2.2\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "def prob(nheads=2,nflips=10,p=0.5):\n", "    return #your code here\n", "\n", "print(\"2 heads in 10 flips:\",prob())\n", "print(\"2 heads in 10 flips:\",prob(p=1/10))"]}, {"cell_type": "markdown", "id": "d55932f2", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_2_3'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L2.3 The Poisson Distribution</h2>  \n", "\n", "| [Top](#section_2_0) | [Previous Section](#section_2_2) | [Exercises](#exercises_2_3) | [Next Section](#section_2_4) |\n"]}, {"cell_type": "code", "execution_count": null, "id": "0f0862a0", "metadata": {"tags": ["learner", "py", "lect_03", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L2.3-runcell01\n", "\n", "#Let's make a function for plotting\n", "def plotWeekYear(p, title=''):\n", "    #Week comparison\n", "    n=7\n", "    k=np.arange(0,n+1)\n", "    binomial_week=stats.binom.pmf(k,n,p)\n", "    poisson_week=stats.poisson.pmf(k,n*p)#note we give lambda=n*p\n", "    plt.title(title)\n", "    plotBinomial(k,binomial_week,label='Binomial',color='blue')\n", "    plotBinomial(k,poisson_week,label='Poisson',color='orange')\n", "    plt.legend(loc='upper right')\n", "    plt.xlabel('number of observations per week')\n", "    plt.show()\n", "\n", "    n=365\n", "    k=np.arange(0,2*p*n)\n", "    binomial_year=stats.binom.pmf(k,n,p)\n", "    poisson_year=stats.poisson.pmf(k,n*p)#note we give lambda=n*p\n", "    plt.title(title)\n", "    plotBinomial(k,binomial_year,label='Binomial',color='blue')\n", "    plotBinomial(k,poisson_year,label='Poisson',color='orange')\n", "    plt.legend(loc='upper right')\n", "    plt.show()\n", "\n", "    average  = np.average(k, weights=binomial_year)\n", "    variance = np.average((k-average)**2, weights=binomial_year)\n", "    print(\"Yearly Binomial mean:\",average,\"stddev:\",np.sqrt(variance))\n", "    \n", "    average  = np.average(k, weights=poisson_year)\n", "    variance = np.average((k-average)**2, weights=poisson_year)\n", "    print(\"Yearly Poisson mean:\",average,\"stddev:\",np.sqrt(variance))\n", "    print()\n", "\n", "    \n", "#First FRBs\n", "p=19/365\n", "plotWeekYear(p, title='Probability of Observing FRBs')\n", "\n", "#Now let's do sunny days\n", "p=200/365\n", "plotWeekYear(p, title='Probability of Sunny Days in Boston')\n"]}, {"cell_type": "markdown", "id": "54e627c0", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='exercises_2_3'></a>     \n", "\n", "| [Top](#section_2_0) | [Restart Section](#section_2_3) | [Next Section](#section_2_4) |\n"]}, {"cell_type": "markdown", "id": "4e87813d", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-2.3.1: GW Detection Timescale Comparison</span>\n", "\n", "With the current rate of Gravitational wave detections, we observe a GW once per week (one way to phrase this is that the probability of a GW on a given day is 1/7). Compare the Poisson and binomial distributions for gravitational wave observations over the period of a week vs. a year. **Hint: the previously defined function `plotWeekYear` may be useful.**\n", "\n", "Can GW detections be reasonably approximated by a Poisson process?"]}, {"cell_type": "code", "execution_count": null, "id": "dc870c7a", "metadata": {"tags": ["draft", "py"]}, "outputs": [], "source": ["#>>>EXERCISE: L2.3.1\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "pass"]}, {"cell_type": "markdown", "id": "6694499b", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-2.3.2: Fraction of GWs per Week</span>\n", "\n", "If more GWs are detected per week, on average, will a Poisson distribution be a BETTER fit for the distribution of GW observations or a WORSE fit?"]}, {"cell_type": "markdown", "id": "7801d58d", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_2_4'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L2.4 Poisson Distribution Continued</h2>  \n", "\n", "| [Top](#section_2_0) | [Previous Section](#section_2_3) | [Exercises](#exercises_2_4) | [Next Section](#section_2_5) |\n"]}, {"cell_type": "code", "execution_count": null, "id": "12d02cbd", "metadata": {"tags": ["learner", "py", "lect_04", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L2.4-runcell01\n", "\n", "fig, ax = plt.subplots(figsize=(9,6))\n", "N=10000\n", "nbins=100\n", "sample  = np.random.uniform (0,1,N)\n", "\n", "def plotHist(iSample,iNBins):\n", "    histy, bin_edges = np.histogram(iSample, bins=iNBins)\n", "    bin_centers = 0.5*(bin_edges[1:] + bin_edges[:-1])\n", "    ax.set_ylim([0,2*N/nbins])\n", "    plt.plot(bin_centers,histy,drawstyle = 'steps-mid')\n", "    plt.xlabel(\"x\")\n", "    plt.ylabel(\"Events/bin\")\n", "    plt.show()\n", "    return bin_centers, histy\n", "\n", "_,_ = plotHist(sample,nbins)\n"]}, {"cell_type": "code", "execution_count": null, "id": "e0337645", "metadata": {"tags": ["learner", "py", "lect_04", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L2.4-runcell02\n", "\n", "#copy and past above distribution\n", "fig, ax = plt.subplots(figsize=(9,6))\n", "N=10000 \n", "#N=1000000 #Try larger N value\n", "nbins=100\n", "sample  = np.random.uniform (0,1,N)\n", "histx, histy = plotHist(sample,nbins)\n", "\n", "\n", "def normhist(iVars,iNbins=30,iNormalize=True):\n", "    y0, bin_edges = np.histogram(iVars, bins=iNbins)\n", "    bin_centers = 0.5*(bin_edges[1:] + bin_edges[:-1])\n", "    norm0 = 1 \n", "    if iNormalize:\n", "        norm0=len(iVars)*(bin_edges[-1]-bin_edges[0])/iNbins\n", "    plt.errorbar(bin_centers,y0/norm0,yerr=y0**0.5/norm0,drawstyle = 'steps-mid',c='red')\n", "    return bin_centers,y0,bin_edges\n", "\n", "residx,residy,_=normhist(histy)\n", "haverage  = np.average(residx, weights=residy)\n", "hvariance = np.average((residx-haverage)**2, weights=residy)\n", "print(\"Actual mean:\",haverage,\"Variance:\",hvariance) \n", "\n", "#Now since we have 100 bins with p=1/100 and we sample 10000 times we have lamb=np= N (1/nbins)\n", "lamb=N/nbins # Number events/bin = 100\n", "k=np.arange(0.55*N/nbins,1.45*N/nbins) \n", "#k=np.arange(0.85*N/nbins,1.15*N/nbins) #adjust range if using larger N \n", "poisson=stats.poisson.pmf(k,lamb)#lambda = n * p = 10000 * (1/100)\n", "paverage  = np.average(k, weights=poisson)\n", "pvariance = np.average((k-paverage)**2, weights=poisson)\n", "print(\"Poisson mean:\",paverage,\"Variance:\",pvariance)\n", "\n", "plt.plot(k,poisson,'o')\n", "# plt.vlines(k,0, poisson)\n", "plt.ylim(bottom=0)\n", "\n", "plt.xlabel(\"Mean per bin\")\n", "plt.ylabel(\"probability\")\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "id": "342d96ea", "metadata": {"tags": ["learner", "py", "lect_04", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L2.4-runcell03\n", "\n", "#And so the bins are Poisson fluctuated. This is why when we plot data in a histogram we put error bars \n", "#Corresponding the Poisson uncertainty in a bin\n", "N=10000\n", "nbins=100\n", "sample  = np.random.uniform (0,1,N)\n", "histy, bin_edges = np.histogram(sample, bins=nbins)\n", "yerr=np.sqrt(histy)\n", "bin_centers = 0.5*(bin_edges[1:] + bin_edges[:-1])\n", "ax.set_ylim([0,2*N/nbins])\n", "\n", "#Here is the command\n", "plt.errorbar(bin_centers,histy,yerr=yerr,marker='.',c='black',linestyle = 'None',label='Data')\n", "print(np.mean(yerr))\n", "\n", "k=np.arange(0,1,0.01)\n", "vals=np.full((100),N/nbins)\n", "plt.plot(k,vals,'o--',label=\"Expected value\")\n", "plt.ylim(0,150)\n", "plt.xlabel(\"x\")\n", "plt.ylabel(\"Events/bin\")\n", "plt.legend(loc='lower right')\n", "plt.show()"]}, {"cell_type": "markdown", "id": "ca231f1b", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='exercises_2_4'></a>     \n", "\n", "| [Top](#section_2_0) | [Restart Section](#section_2_4) | [Next Section](#section_2_5) |\n"]}, {"cell_type": "markdown", "id": "a58d32cc", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-2.4.1: Calculating Error for a Poisson Distribution</span>\n", "\n", "For 100 bins, what is the Poisson error (standard deviation) averaged over all bins for an experiment run 100, 1000, and 10000 times?\n", "\n", "Hint: You can use the code below to help calculate the yerr for all bins and then average them yourself.\n", "\n", "Enter your answer as a list of numbers rounded to the nearest integer: `[avg(100), avg(1000), avg(10000)]`."]}, {"cell_type": "code", "execution_count": null, "id": "b4541317", "metadata": {"tags": ["draft", "py"]}, "outputs": [], "source": ["#>>>EXERCISE: L2.4.1\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "N=10000 #YOUR CODE HERE [VARY 100, 1000, 10000]\n", "nbins= 100 \n", "\n", "sample  = np.random.uniform (0,1,N)\n", "histy, bin_edges = np.histogram(sample, bins=nbins)\n", "yerr=np.sqrt(histy)\n", "\n", "#YOUR CODE HERE"]}, {"cell_type": "markdown", "id": "f0d13378", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_2_5'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L2.5 The Gaussian Distribution</h2>  \n", "\n", "| [Top](#section_2_0) | [Previous Section](#section_2_4) | [Exercises](#exercises_2_5) | [Next Section](#section_2_6) |\n"]}, {"cell_type": "code", "execution_count": null, "id": "d737ee3d", "metadata": {"scrolled": false, "tags": ["learner", "py", "lect_05", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L2.5-runcell01\n", "\n", "import math\n", "\n", "def plotSum(iN):\n", "    ntoys=10000\n", "    sums=np.array([])\n", "    for i0 in range(ntoys):\n", "        pToy = np.random.uniform(0,10,iN)\n", "        sums = np.append(sums,pToy.sum())\n", "    _,_,binrange=normhist(sums) #plots a Gaussian hist\n", "    k=np.linspace(binrange[0],binrange[-1], 50)\n", "    normal=stats.norm.pdf(k,sums.mean(),sums.std())\n", "    plt.plot(k,normal,'o-')\n", "    plt.xlabel(\"Number of successes\")\n", "    plt.ylabel(\"Probability\")\n", "    print(\"Summing:\",iN,\" numbers with mean:\",sums.mean(),\" and std-deviation\",sums.std(),sums.mean()/math.sqrt(3*iN))\n", "    plt.show()\n", "\n", "plotSum(1)\n", "plotSum(2)\n", "plotSum(3)\n", "plotSum(4)\n", "plotSum(50)\n", "plotSum(5000)\n"]}, {"cell_type": "code", "execution_count": null, "id": "5d436079", "metadata": {"tags": ["learner", "py", "lect_05", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L2.5-runcell02\n", "\n", "N = 5000\n", "unif_range = 10\n", "print(\"stddev:\", np.sqrt(N * unif_range ** 2 / 12))\n"]}, {"cell_type": "code", "execution_count": null, "id": "51383fde", "metadata": {"tags": ["learner", "py", "lect_05", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L2.5-runcell03\n", "\n", "#solution 1\n", "##### Let's plot a Gaussian and Poisson with same mean and RMS\n", "def poisGausPlot(n):\n", "    lamb=n\n", "    k=np.arange(-2,3.0*n)\n", "    poisson=stats.poisson.pmf(k,lamb)\n", "    normal=stats.norm.pdf(k,n,math.sqrt(n))\n", "    plt.plot(k,poisson,'o',label='Poisson')\n", "    plt.vlines(k,0, poisson, color=plt.gca().lines[-1].get_color())\n", "    plt.ylim(bottom=0)\n", "    plt.plot(k,normal,'-',label='Gaussian')\n", "    plt.xlabel(\"Number of successes\")\n", "    plt.ylabel(\"Probability\")\n", "    plt.legend(loc='lower right')\n", "    plt.show()\n", "\n", "poisGausPlot(3)\n", "poisGausPlot(15)\n", "poisGausPlot(100)\n"]}, {"cell_type": "markdown", "id": "6c444db1", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='exercises_2_5'></a>     \n", "\n", "| [Top](#section_2_0) | [Restart Section](#section_2_5) | [Next Section](#section_2_6) |\n"]}, {"cell_type": "markdown", "id": "f3c3a1c7", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-2.5.1: Sum of Two Gaussians</span>\n", "\n", "Show that the sum of two Gaussian distributions is also Gaussian. To do this, plot the normalized histogram of the sum of two numbers drawn from identical Gaussian distributions. In the same figure, plot a Gaussian distribution with mean and standard deviation equal to the mean and standard deviation of the summed distribution. Write your own code, or run the code below.\n", "\n", "\n", "Based on the output of your code, how is the standard deviation of the summed distribution, $\\sigma_{\\mathrm{sum}}$, related to the standard deviation of the Gaussian distributions from which the samples are drawn (call this $\\sigma_0$)? Choose from the options below.\n", "\n", "- $\\sigma_{\\mathrm{sum}} = 2\\sigma_0$\n", "- $\\sigma_{\\mathrm{sum}} = \\sqrt{2}\\sigma_0$\n", "- $\\sigma_{\\mathrm{sum}} = \\sigma_0$\n", "- $\\sigma_{\\mathrm{sum}} = \\sigma_0/\\sqrt{2}$\n", "- $\\sigma_{\\mathrm{sum}} = \\sigma_0/2$\n", "\n", "\n", "How would this relation change if you summed more samples (here we just did 2, 100000 times). Try varying $\\sigma$ and the number of samples chosen (where are these defined in the code)?"]}, {"cell_type": "code", "execution_count": null, "id": "07e31baf", "metadata": {"tags": ["draft", "py"]}, "outputs": [], "source": ["#>>>EXERCISE: L2.5.1\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "#Generate 2 Gaussian and sum \n", "ntoys=100000\n", "istdev=1\n", "sums=np.array([])\n", "for i0 in range(ntoys):\n", "    pToy = np.random.normal(0,istdev,2)\n", "    sums = np.append(sums,pToy.sum())\n", "_,_,binrange=normhist(sums)\n", "\n", "k=np.arange(binrange[0],binrange[-1])\n", "normal=stats.norm.pdf(k,sums.mean(),sums.std())\n", "\n", "plt.plot(k,normal,'o-')\n", "plt.xlabel(\"Number of successes\")\n", "plt.ylabel(\"Probability\")\n", "print(\"Summing: 2, numbers with mean:\",sums.mean(),\" and std-deviation\",sums.std())\n", "plt.show()"]}, {"cell_type": "markdown", "id": "4b6815a7", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": [">#### Follow-up 2.5.1a (ungraded)\n", ">  \n", ">We've compared the Poisson and binomial distributions, and Poisson and Gaussian distribution. Now try comparing the binomial and Gaussian distributions. What similarities and differences do they have?"]}, {"cell_type": "markdown", "id": "9dffc6f2", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_2_6'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L2.6 Uncertainties in Measurement</h2>  \n", "\n", "| [Top](#section_2_0) | [Previous Section](#section_2_5) | [Exercises](#exercises_2_6) | [Next Section](#section_2_7) |\n"]}, {"cell_type": "code", "execution_count": null, "id": "a893e204", "metadata": {"tags": ["learner", "py", "lect_06", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L2.6-runcell01\n", "\n", "#Now let's say we do a measurement, and the measurement takes an input variable that is varying, \n", "#and applies a function to it. What is the spread of the function\n", "ntries=1000\n", "meas = np.full(ntries,100) #The value 100, 1k times\n", "unc  = np.random.normal (0,1, ntries) #a randomly sampled value from a Gaussian with width 1 1k times\n", "meas = meas+unc # the value 100 now smeared with sigma=1\n", "\n", "def function(ix):#our function\n", "    return ix**2\n", "outmeas = function(meas)\n", "_,_,_=normhist(outmeas)\n", "\n", "print(\"Mean:\",outmeas.mean(),\"Stddeviation:\",outmeas.std())\n", "print(\"Predicted Mean:\",function(100),\"Stddeviation:\",2*100) #expect it to be 2*100*1\n"]}, {"cell_type": "code", "execution_count": null, "id": "03d9f016", "metadata": {"tags": ["learner", "py", "lect_06", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L2.6-runcell02\n", "\n", "ntoys=10000\n", "err1=np.array([])\n", "err2=np.array([])\n", "for i0 in range(ntoys):\n", "    pToy = np.random.normal(0,1,2)\n", "    err1 = np.append(pToy[0],err1)\n", "    err2 = np.append(pToy[1],err2)\n", "angle = np.linspace( 0 , 2 * np.pi , 150 ) \n", "#correct circle\n", "radius = 1*np.sqrt(2)\n", "x = radius * np.cos( angle ) \n", "y = radius * np.sin( angle ) \n", "#too large circle\n", "radius = 1*2.0\n", "x2 = radius * np.cos( angle ) \n", "y2 = radius * np.sin( angle ) \n", "\n", "plt.rcParams['figure.figsize'] = (6,6)\n", "plt.plot(err1,err2,\"p\")\n", "plt.plot(x,y,c='r')\n", "plt.plot(x2,y2,c='r')\n", "plt.xlabel(\"$\\sigma_{1}$\")\n", "plt.ylabel(\"$\\sigma_{2}$\")\n", "plt.show()\n", "plt.rcParams['figure.figsize'] = (9,6)"]}, {"cell_type": "markdown", "id": "627f6f67", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='exercises_2_6'></a>     \n", "\n", "| [Top](#section_2_0) | [Restart Section](#section_2_6) | [Next Section](#section_2_7) |\n"]}, {"cell_type": "markdown", "id": "d0477604", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-2.6.1: Uncertainty in $f(x)$</span>\n", "\n", "If $f(x) = \\log(x)$, what is $\\sigma_{f(x)}$ in terms of $x$ and $\\sigma_{x}$? Express your answer in terms of `x` and `sigma_x` for $\\sigma$.\n"]}, {"cell_type": "code", "execution_count": null, "id": "895aea72", "metadata": {"tags": ["draft", "py"]}, "outputs": [], "source": ["#>>>EXERCISE: L2.6.1a\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "ntries=100000\n", "mean=100\n", "sigma=5\n", "meas = np.full(ntries,mean) #The value 100, 1k times\n", "unc  = np.random.normal (0,sigma, ntries) #a randomly sampled value from a Gaussian with width 1 1k times\n", "meas = meas+unc # the value 100 now smeared with sigma=1\n", "\n", "def function(ix):#our function\n", "    return np.log(ix)\n", "\n", "outmeas = function(meas)\n", "_,_,_=normhist(outmeas)\n", "\n", "analytic_stdev = 0. #YOUR CODE HERE\n", "\n", "print(\"Mean:\",outmeas.mean(),\"Stddeviation:\",outmeas.std())\n", "print(\"Predicted Mean:\",function(mean),\"Stddeviation:\",analytic_stdev)\n"]}, {"cell_type": "markdown", "id": "40b92fd5", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_2_7'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L2.7 Propagating Uncertainties</h2>     \n", "\n", "| [Top](#section_2_0) | [Previous Section](#section_2_6) | [Exercises](#exercises_2_7) |\n"]}, {"cell_type": "code", "execution_count": null, "id": "6628f11e", "metadata": {"tags": ["learner", "py", "lect_07", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L2.7-runcell01\n", "\n", "import csv\n", "import matplotlib.pyplot as plt\n", "import numpy as np\n", "import urllib.request\n", "\n", "#load the file\n", "def load(iName):\n", "    label=iName\n", "    datax=np.array([])\n", "    datay=np.array([])\n", "    datayerr=np.array([])\n", "    with open(label,'r') as csvfile:\n", "        plots = csv.reader(csvfile, delimiter=',')\n", "        for row in plots:\n", "            datax    = np.append(datax,float(row[0]))\n", "            datay    = np.append(datay,float(row[1]))\n", "            datayerr = np.append(datayerr,np.sqrt(float(row[1])))\n", "    return datax,datay,datayerr\n", "\n", "#compute the ratio between data and simulation\n", "def histratio(iydata,iyderr,iysim):\n", "    newydata=np.array([])\n", "    newyderr=np.array([])\n", "    for i0 in range(len(iysim)):\n", "        ynew=iydata[i0]/iysim[i0]\n", "        yner=iyderr[i0]/iysim[i0]\n", "        newydata=np.append(newydata,ynew)\n", "        newyderr=np.append(newyderr,yner)\n", "    return newydata,newyderr\n", "\n", "fig = plt.figure(figsize=(10.5, 9.5))\n", "ax = fig.add_subplot(2,1,1)\n", "datax,datay,datayerr=load(\"data/L02/tmpdata.txt\")\n", "simx,simy,simyerr=load(\"data/L02/tmpmc.txt\")\n", "plt.errorbar(datax,datay,yerr=datayerr,marker='.',c='black',linestyle = 'None')\n", "plt.plot    (datax,simy,drawstyle = 'steps-mid')\n", "ax = fig.add_subplot(2,1,2)\n", "yrdata,yrderr=histratio(datay,datayerr,simy)\n", "ax.errorbar(datax,yrdata,yerr=yrderr,marker='.',c='black',linestyle = 'None')\n", "ax.axhline(1, c='red')\n", "ax.set_ylim(0.5,1.5)\n", "plt.xlabel(\"Mjj [GeV]\")\n", "plt.ylabel(\"Data/Simulation\")\n", "plt.show()\n"]}, {"cell_type": "code", "execution_count": null, "id": "589ad4b2", "metadata": {"tags": ["learner", "py", "lect_07", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L2.7-runcell02\n", "\n", "#Now let's shift the bins of the simulation by a fraction\n", "def shifthist(ixunc,isimy):\n", "    newsimy=np.array([])\n", "    for i0 in range(len(isimy)):\n", "        ynew = isimy[i0]*(1-ixunc)\n", "        if i0 > 1:\n", "            ynew = isimy[i0-1]*ixunc + isimy[i0]*(1-ixunc)\n", "        newsimy=np.append(newsimy,ynew)\n", "    return newsimy\n", "\n", "            \n", "fig = plt.figure(figsize=(10.5, 9.5))\n", "ax = fig.add_subplot(2,1,1)\n", "newsimy=shifthist(0.5,simy)\n", "plt.errorbar(datax,datay,yerr=datayerr,marker='.',c='black',linestyle = 'None')\n", "plt.plot    (datax,simy,drawstyle = 'steps-mid')\n", "plt.plot    (datax,newsimy,drawstyle = 'steps-mid')\n", "\n", "ax = fig.add_subplot(2,1,2)\n", "yrdata,yrderr=histratio(datay,datayerr,newsimy)\n", "ax.errorbar(datax,yrdata,yerr=yrderr,marker='.',c='black',linestyle = 'None')\n", "ax.axhline(1, c='red')\n", "ax.set_ylim(0.5,1.5)\n", "plt.xlabel(\"Mjj [GeV]\")\n", "plt.ylabel(\"Data/Simulation\")\n", "plt.show()\n"]}, {"cell_type": "markdown", "id": "d4f4dd2a", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='exercises_2_7'></a>   \n", "\n", "| [Top](#section_2_0) | [Restart Section](#section_2_7) |\n"]}, {"cell_type": "markdown", "id": "b7fa6ba3", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": [">#### Follow-up 2.7.1a (ungraded)\n", ">    \n", ">Examine the CDF data further. Try other fractional shifts. Does the resulting fit look better or worse (look at the residuals)?\n"]}], "metadata": {"celltoolbar": "Tags", "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}