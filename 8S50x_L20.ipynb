{"cells": [{"cell_type": "markdown", "id": "b4997a0a", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<hr style=\"height: 1px;\">\n", "<i>This notebook was authored by the 8.S50x Course Team, Copyright 2022 MIT All Rights Reserved.</i>\n", "<hr style=\"height: 1px;\">\n", "<br>\n", "\n", "<h1>Lesson 20: Monte Carlo I</h1>"]}, {"cell_type": "markdown", "id": "100dd6f6", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='section_21_0'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L20.0 Overview</h2>\n"]}, {"cell_type": "markdown", "id": "d8d25e2e", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<h3>Navigation</h3>\n", "\n", "<table style=\"width:100%\">\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_21_1\">L20.1 Monte Carlo Computations</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_21_1\">L20.1 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_21_2\">L20.2 Monte Carlo Diffusion</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_21_2\">L20.2 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_21_3\">L20.3 Adding Elements of Realism</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_21_3\">L20.3 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_21_4\">L20.4 Modeling Physics Observables: Bragg Scattering for Proton Therapy</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_21_4\">L20.4 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_21_5\">L20.5 Bragg Scattering for Proton Therapy in Multiple Dimensions</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_21_5\">L20.5 Exercises</a></td>\n", "    </tr>\n", "</table>"]}, {"cell_type": "markdown", "id": "55027b3a", "metadata": {"tags": ["md", "catsoop_00", "learner"]}, "source": ["<h3>Learning Objectives</h3>\n", "\n", "We have been randomly sampling and building toys throughout this class, both of which are elements of Monte Carlo (MC) simulations. However, we have yet to devote a whole Lesson to MC simulation itself. In the next two Lessons, we are going to build a MC simulation similar to one that is critical for proton medical therapy. Then, we are going to explore Machine Learning MC strategies, and show how some of the biggest advances in Artificial Intelligence are changing the way we simulate and model scientific data."]}, {"cell_type": "markdown", "id": "cb43a27a", "metadata": {"tags": ["md", "catsoop_00", "learner"]}, "source": ["<h3>Slides</h3>\n", "\n", "You can access the slides related to this lecture at the following link: <a href=\"https://github.com/mitx-8s50/slides/raw/main/module3_slides/L21_slides.pdf\" target=\"_blank\">L20 Slides</a>"]}, {"cell_type": "markdown", "id": "fa07a2f2", "metadata": {"tags": ["md", "learner"]}, "source": ["<h3>Installing Tools</h3>\n", "\n", "Before we do anything, let's make sure we install the tools we need."]}, {"cell_type": "code", "execution_count": null, "id": "0fdf2709", "metadata": {"tags": ["py", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L20.0-runcell00\n", "\n", "!pip install pylandau #from here: https://pypi.org/project/pylandau/\n", "!pip install git+https://github.com/SengerM/landaupy\n", "\n", "#from here: https://github.com/SengerM/landaupy\n", "#https://github.com/SengerM/landaupy/blob/main/LICENSE"]}, {"cell_type": "markdown", "id": "b1e545ed", "metadata": {"tags": ["md", "learner"]}, "source": ["<h3>Importing Libraries</h3>\n", "\n", "Before beginning, run the cell below to import the relevant libraries for this notebook. "]}, {"cell_type": "code", "execution_count": null, "id": "92e910f7", "metadata": {"tags": ["py", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L20.0-runcell01\n", "\n", "import imageio\n", "from PIL import Image\n", "import pylandau\n", "from landaupy import landau\n", "\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import csv\n", "import math\n", "from scipy import optimize as opt \n", "from scipy.integrate import quad\n", "import random"]}, {"cell_type": "markdown", "id": "1edc15fe", "metadata": {"tags": ["md", "learner"]}, "source": ["<h3>Setting Default Figure Parameters</h3>\n", "\n", "The following code cell sets default values for figure parameters.\n"]}, {"cell_type": "code", "execution_count": null, "id": "6e40a219", "metadata": {"tags": ["py", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L20.0-runcell02\n", "\n", "#set plot resolution\n", "%config InlineBackend.figure_format = 'retina'\n", "\n", "#set default figure parameters\n", "plt.rcParams['figure.figsize'] = (9,6)\n", "\n", "medium_size = 12\n", "large_size = 15\n", "\n", "plt.rc('font', size=medium_size)          # default text sizes\n", "plt.rc('xtick', labelsize=medium_size)    # xtick labels\n", "plt.rc('ytick', labelsize=medium_size)    # ytick labels\n", "plt.rc('legend', fontsize=medium_size)    # legend\n", "plt.rc('axes', titlesize=large_size)      # axes title\n", "plt.rc('axes', labelsize=large_size)      # x and y labels\n", "plt.rc('figure', titlesize=large_size)    # figure title"]}, {"cell_type": "markdown", "id": "cda81f08", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='section_21_1'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L20.1 Monte Carlo Computations</h2>  \n", "\n", "| [Top](#section_21_0) | [Previous Section](#section_21_0) | [Exercises](#exercises_21_1) | [Next Section](#section_21_2) |"]}, {"cell_type": "markdown", "id": "72d59a38", "metadata": {"tags": ["learner", "md", "lect_01"]}, "source": ["*The material in this section is discussed in the video **<a href=\"https://courses.mitxonline.mit.edu/learn/course/course-v1:MITxT+8.S50.3x+3T2023/block-v1:MITxT+8.S50.3x+3T2023+type@sequential+block@seq_LS20/block-v1:MITxT+8.S50.3x+3T2023+type@vertical+block@vert_LS20_vid1\" target=\"_blank\">HERE</a>.** You are encouraged to watch that video and use this notebook concurrently.*\n"]}, {"cell_type": "markdown", "id": "035cf001", "metadata": {"tags": ["learner", "md", "lect_01"]}, "source": ["<h3>Numerical Integration with Monte Carlo</h3>\n", "\n", "You have probably noticed that in many cases where I was finding averages, standard deviations, and other moments of distributions, I just computed the means of the moments using sampled distributions. I did what is referred to as Monte Carlo Integration (or more generally bootstrapping), where I just sampled a distribution and integrated by sampling. Namely,\n", "\n", "$$\n", "\\begin{equation}\n", "E[x^{n}p(x)] = \\int_{-\\infty}^{\\infty} x^{n} p(x) dx = \\frac{1}{N}\\sum_{i=1}^{N} x_{i}^{n}\n", "\\end{equation}\n", "$$\n", "\n", "where here the $x_{i}\\in p(x)$ are sampled from the probability distribution function. So, what happens when we have a distribution but we don't know its analytic form. How can we sample it?  \n", "\n", "There are a lot of ways to do this, perhaps the most well known is Markov Chain Monte Carlo (MCMC). However, the simplest is to just turn our distribution into a 2D image and randomly sample points on the image. Instead of writing the points out, **let's just do it.**\n"]}, {"cell_type": "markdown", "id": "6467ab6c", "metadata": {"tags": ["learner", "md", "lect_01"]}, "source": ["<h3>An Example</h3>\n", "\n", "To see how this works, let's walk through a calculation of integrating the area of a quarter circle of radius 1. We know that the integral is given by $A={\\pi}/{4}$, so we can check our math. What we will do is\n", "\n", "1. Sample randomly in x from 0 to 1\n", "2. Sample randomly in y from 0 to 1\n", "3. Check to see if x and y are within our quarter circle.\n", "4. Compute the ratio of the number of samples within our quarter circle divided by the total number of points.\n", "5. Since we know the area of the full sample is exactly 1, this ratio is the area we are trying to find.\n", "\n", "Let's look at the code. Note that since we are randomly sampling, our uncertainty on our random sample will just be the Poisson uncertainty or $\\frac{A}{\\sqrt{N_{\\rm samples}}}$. Try varying the number of samples to see how the answer and its uncertainty change. Does it look like the Poisson uncertainty gives a good approximation to the deviations from the exact result?"]}, {"cell_type": "code", "execution_count": null, "id": "80a05506", "metadata": {"tags": ["learner", "py", "learner_chopped", "lect_01"]}, "outputs": [], "source": ["#>>>RUN: L20.1-runcell01\n", "\n", "#First let's just compute the area of a quarter circle with radius 1\n", "def quarterarea(iN):\n", "    area=0\n", "    lXin = np.array([])\n", "    lYin = np.array([])\n", "    lXout = np.array([])\n", "    lYout = np.array([])\n", "    for i0 in range(iN):\n", "        #Sample X and Y\n", "        pX = np.random.uniform(0,1)\n", "        pY = np.random.uniform(0,1)\n", "        #Check if its radius is in 1\n", "        if np.sqrt(pX**2+pY**2) < 1:\n", "            lXin = np.append(lXin,pX)\n", "            lYin = np.append(lYin,pY)\n", "            area += 1 # count it\n", "        else:\n", "            lXout = np.append(lXout,pX)\n", "            lYout = np.append(lYout,pY)\n", "    print(area)\n", "    return (float(area)/float(iN)),lXin,lYin,lXout,lYout\n", "\n", "#sample points\n", "lN=1000\n", "#lN=100000\n", "a,lXin,lYin,lXout,lYout=quarterarea(lN)\n", "print(\"Pi (4*area) :\",f\"{a*4:.6f}\",\"+/-\",f\"{4*a/math.sqrt(lN):.6f}\") #gotta put an uncertainty\n", "print(\"Exact answer:\",f\"{np.pi:.6f}\",\"\\nRatio - 1:\",f\"{(a*4/np.pi)-1.0:.6f}\",\"+/-\",f\"{4*a/(np.pi*math.sqrt(lN)):.6f}\")\n", "\n", "#Make the plots square so the quarter circle looks like a circle\n", "plt.rcParams['figure.figsize'] = (7,7)\n", "\n", "plt.plot(lXin,lYin,marker='.',linestyle = 'None')\n", "plt.plot(lXout,lYout,marker='.',linestyle = 'None')\n", "plt.show()\n", "\n", "#Revert to default plot aspect ratio\n", "plt.rcParams['figure.figsize'] = (9,6)"]}, {"cell_type": "markdown", "id": "aaaa975e", "metadata": {"tags": ["learner", "md", "lect_01"]}, "source": ["The idea with Monte Carlo integration is that we calculate an integral by evaluating the function. We don't actually have to compute the integral. This avoids what is potentially a very complicated step.  As you probably know well, computing integrals can be very hard, but this way gets at our answer just through functional evaluation.\n", "\n", "Now, let's compute the integral of some arbitrary function $y=f(x)$. As we did with our circle, we can compute the integral by plotting this function over a range. Here, we will use a range $-6 < x < 3$. From this, what we will do is sample over a uniform distribution given by the $x$ and $y$ ranges. However, how do we know what range in $y$ to use? The option used in this example is to use a minimization function `opt.minimize_scalar`. To use this same function to find the maximum, we simply find the minimum of the negative of the function."]}, {"cell_type": "code", "execution_count": null, "id": "5c3f154e", "metadata": {"tags": ["learner", "py", "learner_chopped", "lect_01"]}, "outputs": [], "source": ["#>>>RUN: L20.1-runcell02\n", "\n", "\n", "#use this random seed\n", "np.random.seed(10)\n", "\n", "#Now let's consider integrating some random function\n", "def f(x):\n", "    return x**4 + 3*(x-2)**3 - 15*(x)**2 + 1\n", "\n", "#Now let's multiply it by -1 to make the range calculation fast\n", "def fneg(x):\n", "    return -1*(x**4 + 3*(x-2)**3 - 15*(x)**2 + 1)\n", "\n", "\n", "#First thing is to define a range in x\n", "xmin=-6\n", "xmax=3\n", "x = np.linspace(xmin, xmax, 100)\n", "plt.plot(x, f(x));\n", "#plt.show()\n", "\n", "\n", "#Now we need to find a range in y\n", "sol=opt.minimize_scalar(f,bounds=(xmin, xmax))#, method='Brent')\n", "ymin=sol.fun\n", "#y-max is to get the minimum of negative f\n", "sol=opt.minimize_scalar(fneg,bounds=(xmin, xmax))#, method='Brent')\n", "ymax=-1*sol.fun\n", "\n", "print('[ymin,ymax]:', ymin, ymax)\n", "\n", "\"\"\"\n", "#Now we need to find a range in y\n", "ymin=min(f(x))\n", "ymax=max(f(x))\n", "print('[ymin,ymax]:', ymin, ymax)\n", "\"\"\"\n", "\n", "lN=10000\n", "#now, let's sample a 2D grid y-min and y-max and compute the integral\n", "lXin = np.array([])\n", "lYin = np.array([])\n", "lXout = np.array([])\n", "lYout = np.array([])\n", "for i0 in range(lN):\n", "    #Try a uniform distribution\n", "    pX = abs(xmax-xmin)*np.random.uniform(0,1)+xmin\n", "    pY = abs(ymax-ymin)*np.random.uniform(0,1)+ymin\n", "    #Try a normal distribution\n", "    #pX = abs(xmax-xmin)*np.random.normal(0,1)+xmin\n", "    #pY = abs(ymax-ymin)*np.random.normal(0,1)+ymin\n", "    pYMin = f(pX)\n", "    if pY < pYMin:\n", "        lXin = np.append(lXin,pX)\n", "        lYin = np.append(lYin,pY)\n", "    else:\n", "        lXout = np.append(lXout,pX)\n", "        lYout = np.append(lYout,pY)\n", "\n", "\n", "plt.plot(lXin,lYin,marker='.',linestyle = 'None', color='orange')\n", "plt.plot(lXout,lYout,marker='.',linestyle = 'None', color='green')\n", "plt.axvline(sol.x, c='red', lw=3)\n", "plt.plot(x, f(x), 'b-', lw=3)\n", "#plt.ylim(-800,0)\n", "#plt.xlim(-6,3)\n", "plt.show();"]}, {"cell_type": "markdown", "id": "b8769a7c", "metadata": {"tags": ["learner", "md", "lect_01"]}, "source": ["From the plot generated by this scenario, we can see that the orange points are below the line from roughly -800 to a little below 0, and the green points are above the line. We can make a histogram of the fraction of the points which are above and below the line for bins in $x$."]}, {"cell_type": "code", "execution_count": null, "id": "66f32b31", "metadata": {"tags": ["learner", "py", "learner_chopped", "lect_01"]}, "outputs": [], "source": ["#>>>RUN: L20.1-runcell03\n", "\n", "_,bins,_= plt.hist(lXin,bins=10,alpha=0.5,density=True, label='below') #blue in histogram\n", "plt.hist(lXout,alpha=0.5,bins=bins,density=True, label='above') #orange in histogram\n", "#plt.xlim(-6,3)\n", "plt.legend(loc=1)\n", "plt.show();\n", "\n", "print(\"number below:\",len(lXin),\"number above:\",len(lXout))"]}, {"cell_type": "markdown", "id": "88dc5ae9", "metadata": {"tags": ["learner", "md", "lect_01"]}, "source": ["Note that a uniform distribution in the variable of integration (the $x$ values in the example above) may not always be the best choice. However, we have to be careful with this method of finding an integral if we are sampling, for example, a Gaussian distribution. In that case, our sampling would be biased by the Gaussian we chose, which means our integral will not be correct. We can write this out as the product of our function times the phase space we are sampling. In this case, the phase space is given mutliplying by Guassian weighted pdf $p_{G}(x,y)$:\n", "\n", "\n", "$$\n", "\\begin{equation}\n", "\\mathcal{I}=\\int_{\\rm space} f(x,y) p_{G}(x,y) dx dy\n", "\\end{equation}\n", "$$\n", "\n", "\n", "The procedure described above is known as \"Area-based\" sampling, and is considered a method of Monte-Carlo Integration, which is a very rich field. In fact, all high energy physics simulations are based on it. Basically, the function we sample from starts with a collision found using the probability distribution of a set of possible collision outcomes. We then proceed to put the particles generated in this collision through a point by point simulation, wherein each particle is followed as it go through all the elements of a particular detector. At each step, the probability of each particle to interact with, or leave a signal in, the detector material is sampled. Finally, we aggregate our distributions based on the full set of detector responses. We will discuss the usefulness of Monte Carlo Simulation in more detail later on.\n"]}, {"cell_type": "markdown", "id": "12043b7b", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='exercises_21_1'></a>     \n", "\n", "| [Top](#section_21_0) | [Restart Section](#section_21_1) | [Next Section](#section_21_2) |\n"]}, {"cell_type": "markdown", "id": "5690b01d", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-20.1.1</span>\n", "\n", "\n", "How would you compute the integral of the function given in code cell `L20.1-runcell02` over the range `[-6,3]`? Select the correct answer below, where the numbers above and below the line refer to the output of code cell `L20.1-runcell03`. Think carefully about how one might need to consider negative signs in each case.\n", "\n", "\n", "A) The integral is equal to the total area sampled times the fraction of the points above the line defined by our function.\\\n", "B) The integral is the negative of the quantity given in option A.\\\n", "C) The integral is equal to the total area sampled times the fraction of the points below the line defined by our function.\\\n", "D) The integral is the negative of the quantity given in option C.\\\n", "E) To calculate the integral using the number of points above and below the line found by code cell `L20.1-runcell03`, corrections need to be made for the fact that $y_{max}$ is not zero.\\\n", "F) To calculate the integral using the number of points above and below the line found by code cell `L20.1-runcell03`, corrections need to be made for the region with negative $x$ values.\\\n", "G) To calculate the integral using the number of points above and below the line found by code cell `L20.1-runcell03`, corrections need to be made for the issues mentioned in both options E and F.\n"]}, {"cell_type": "markdown", "id": "3afd9da9", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-20.1.2 </span>\n", "\n", "Calculate the integral of this function using the Monte Carlo method outlined above, and report your answer as a number with precision `1e-2`. In order to compare your answer to ours, use the same conditions as defined above, namely:\n", "\n", "<pre>\n", "#use this random seed\n", "np.random.seed(10)\n", "\n", "#use this array of x-values\n", "xmin=-6\n", "xmax=3\n", "x = np.linspace(xmin, xmax, 100)\n", "\n", "#use this number of points\n", "lN=10000\n", "</pre>\n", "\n", "<b>Remember to correctly apply a negative sign, if applicable!</b>\n", "\n", "How does your numerically calculated value compare to the expected value? You can explicitly solve the integral mathematically, or use a built-in `scipy` integration method (e.g., `scipy.integrate.quad`) to compare to your Monte Carlo integration.\n", "\n", "Bonus: Write a Monte Carlo integrator that computes the definite integral of any generic function."]}, {"cell_type": "code", "execution_count": null, "id": "5e29cf83", "metadata": {"tags": ["py", "draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L20.1.2\n", "\n", "#define the fraction of points above the function\n", "frac_above = None\n", "\n", "#define the total area of the integration region,\n", "#i.e., where the points are distributed\n", "area = None\n", "\n", "#define an adjustment to the total area\n", "#since the function in this range is\n", "#completely below the y-axis\n", "adjust = None\n", "\n", "#define the integral using the terms above\n", "MC_integal =  None\n", "\n", "print('Monte Carlo integration:', MC_integal)\n", "\n", "#COMPARE TO PRE-DEFINED NUMERICAL INTEGRATOR\n", "# call quad to integrate f from -6 to 3\n", "builtin_int = None\n", "\n", "print('Numerical integration:', builtin_int)\n", "print('Ratio of MC/exact:',MC_integal/builtin_int)"]}, {"cell_type": "markdown", "id": "327873ec", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-20.1.3 </span>\n", "\n", "To get a more accurate answer using the Monte Carlo integration method that we just explored, which of the following approaches could you implement? Select ALL that apply.\n", "\n", "A) Increase the number of random points sampled.\\\n", "B) Average over several different trials, using different starting random seeds.\\\n", "C) Modify the code to generate more samples in the regions where the function varies most steeply.\n"]}, {"cell_type": "markdown", "id": "20337258", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='section_21_2'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L20.2 Monte Carlo Diffusion</h2>  \n", "\n", "| [Top](#section_21_0) | [Previous Section](#section_21_1) | [Exercises](#exercises_21_2) | [Next Section](#section_21_3) |"]}, {"cell_type": "markdown", "id": "5a115e74", "metadata": {"tags": ["lect_02", "learner"]}, "source": ["*The material in this section is discussed in the video **<a href=\"https://courses.mitxonline.mit.edu/learn/course/course-v1:MITxT+8.S50.3x+3T2023/block-v1:MITxT+8.S50.3x+3T2023+type@sequential+block@seq_LS20/block-v1:MITxT+8.S50.3x+3T2023+type@vertical+block@vert_LS20_vid2\" target=\"_blank\">HERE</a>.** You are encouraged to watch that video and use this notebook concurrently.*"]}, {"cell_type": "markdown", "id": "801e79c8", "metadata": {"tags": ["lect_02", "learner"]}, "source": ["<h3>Overview</h3>\n", "\n", "Another system that can be simulated with Monte Carlo techniques is a collection of particles undergoing random walks. To start with, let's consider a simple diffusion model. This works by considering a particle moving through some sort of fluid (i.e., a collection of other particles) with velocity $\\vec{v}$ in a specific direction. We assume that it will move a distance $\\ell$ and then scatter off one of the particles in the fluid. The scattering will cause the direction of the first particle's velocity to change in a random direction. The angular spread of the deflection depends on the velocity (or equivalently the average energy) of the particles in the fluid, which could be, for example, the atmosphere.\n", "\n", "To build a simple model, let's consider just Brownian motion, where we simulate each timestep and give the particle a random kick corresponding to a collision with a single other particle. Thus, we can write this as randomly choosing an angle every time step, and simulating the particle motion.\n", "\n", "For each particle, we will step the particle 100 times. Furthermore, to show some intelligent thought about parallel computing, we are going to do this simultaneously for 1000 particles at a time. That means we will make an array of 1000 particles and run the simulation simultaneously using array manipulations as we have done previously.\n", "\n", "We start each particle at the origin with a Gaussian distributed velocity. We give the particles it will scatter off (which we assume are the same mass) the same Gaussian distribution of velocities. We assume that the scatterings are elastic, which is most easily handled by going to the center of mass frame of the two particles. In this frame, the magnitudes of the velocities of the two particles, which are equal and opposite velocities don't change. Instead, the two particle emerge deflected by a random angle uniformly distributed over $2\\pi$.\n", "\n", "Note, in the last little bit of the code below, we will make a rotation matrix that we tile (i.e., we create an array of matrices). Then, we apply the rotation matrices to our velocities using the following Einstein summation notation.\n", "\n", "$$\n", "v^{u}_{j} =  R^{u}_{\\theta,ij} \\left(v^{u}_{i}\\right)\n", "$$"]}, {"cell_type": "code", "execution_count": null, "id": "55c8e9ae", "metadata": {"tags": ["lect_02", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L20.2-runcell01\n", "\n", "def MCSim(sigmav=1,nsteps=10000,ntoys=5000,dt=0.01,iDump=True):\n", "    partpos=np.zeros((ntoys,2)) #x and y\n", "    partvel=np.random.normal(0,1,(ntoys,2)) #let's assume all particles are randomly distributed\n", "    for t0 in range(nsteps):\n", "        partpos += partvel*dt\n", "        #now at each step we will assume the particle collides with another\n", "        opartvel = np.random.normal(0,1,(ntoys,2)) #Sample the \"other\" particles momentum\n", "        comvel   = 0.5*(partvel + opartvel) #Now compute the comoving velocities in the COM frame\n", "        difvel   = 0.5*(partvel - opartvel) #Now compute the collision velocity in the COM frame\n", "        theta = np.random.uniform(0,2.*np.pi,ntoys)#elastic collisions in the COM equate to equal energy ad a theta rotation\n", "        R     = np.array(((np.cos(theta), -1*np.sin(theta)), (np.sin(theta), np.cos(theta))))\n", "        #shape things so they are right\n", "        RMat  = np.swapaxes(R,0,2)\n", "        tmp=np.einsum('BNi,Bi ->BN', RMat, difvel) #Now rotate the colliding velocities over all toys\n", "        partvel = comvel+tmp\n", "\n", "    if iDump:\n", "        plt.hist(np.sqrt(partpos[:,0]**2+partpos[:,1]**2))\n", "        plt.xlabel(\"$\\sqrt{\\Delta x^2 + \\Delta y^2}$\")\n", "        plt.ylabel(\"toys\")\n", "        print(\"Mean distance from the starting point\",np.mean(np.sqrt(partpos[:,0]**2+partpos[:,1]**2)))\n", "        print(\"Standard deviation of the distance in x:\",np.std(partpos[:,1]),\"y:\",np.std(partpos[:,0]))\n", "        print(\"Mean magnitude of the velocity\",np.mean(np.sqrt(partvel[:,0]**2+partvel[:,1]**2)))\n", "        plt.show()\n", "        plt.hist(partvel[:,0])\n", "        plt.xlabel(\"$v_{x}$\")\n", "        plt.ylabel(\"toys\")\n", "        plt.show()\n", "\n", "#MCSim(nsteps=1) #perform only one step\n", "MCSim() #perform default number of steps"]}, {"cell_type": "markdown", "id": "ffa82623", "metadata": {"tags": ["lect_02", "learner"]}, "source": ["Now, we can compare these numbers with our knowledge of Brownian motion, noting how things diffuse. We would like to confirm our measurement of the RMS $x_{\\rm rms}=\\sqrt{\\langle \\bar{x}^2 \\rangle}$.\n", "\n", "We can think of this as the width of the distribution after $N$ collisions with a collision length of $\\ell$. For a time $t$ and a velocity $v$ the number collisions will be $N=(vt)/\\ell$ or, in other words:\n", "\n", "$$\n", "x_{\\rm rms} = \\sqrt{N}\\ell = \\sqrt{vt\\ell}\n", "$$\n", "\n", "Anther way of thinking of this is in terms of the velocity:\n", "\n", "$$\n", "\\frac{d}{dt}\\langle \\bar{x}^2 \\rangle = 2\\bar{x}\\cdot\\frac{d \\bar{x}}{dt} = 2\\langle \\bar{x}\\cdot\\bar{v} \\rangle\\approx2\\langle v^2\\rangle t\n", "$$\n", "\n", "You can read more discussion of Brownian motion in Section 5 of this <a href=\"https://scholar.harvard.edu/files/schwartz/files/2-diffusion.pdf\">article</a>. What this means is that we can exactly predict the rate of diffusion analytically and compare to the output of our MC simulation. Let's go ahead and do that.\n", "\n", "First, the average total velocity in two dimensions can be defined as $\\langle\\sqrt{v_{x}^2+v_{y}^2}\\rangle$. Since $v_{x}$ and $v_{y}$ are both Gaussian distributions, the sum of the squares of these distributions is known as a <a href=\"https://en.wikipedia.org/wiki/Rayleigh_distribution\">Rayleigh distribution</a> ($f(x,\\sigma)$), which is  just a $\\chi^{2}_{2}$ distribution of 2 degrees of freedom with an additional scale term.\n", "\n", "$$\n", "\\langle\\sqrt{v_{x}^2+v_{y}^2}\\rangle = \\langle f(x,\\sigma_{v_{i}}) \\rangle = \\sigma_{v_{i}}\\sqrt{\\frac{\\pi}{2}}\n", "$$\n", "\n", "From the above, we can immediately calculate the average RMS of $x$ for a single collision. Note that our simulation forces the distance between collisions to be $\\ell=2vdt$, where the factor of 2 comes from the fact that both particles are moving towards each other:\n", "\n", "$$\n", "\\langle \\ell \\rangle =  \\langle 2 v dt \\rangle\\\\\n", "x_{\\rm rms} = \\sqrt{N}\\langle\\ell\\rangle= \\sqrt{N}\\sqrt{2\\langle v^2\\rangle} dt = \\sqrt{N2\\frac{\\pi}{2}}dt\n", "$$\n", "\n", "\n", " Since the velocity Gaussians in our specific model both have  $\\sigma_{v_{i}}=1$, we have:\n", "\n", "$$\n", "x_{\\rm rms} = \\sqrt{2\\sigma^{2}_{v_{i}}\\frac{\\pi}{2}}\\sqrt{N}dt=\\sqrt{\\pi N}dt\n", "$$\n", "\n", "Let's compute these values."]}, {"cell_type": "code", "execution_count": null, "id": "dfca0f8f", "metadata": {"tags": ["lect_02", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L20.2-runcell02\n", "\n", "print(\"Rayleigh\",np.sqrt(np.pi/2))\n", "print(\"Rayleigh dt sqrt(N pi)\",np.sqrt(np.pi/2)*np.sqrt(2)*0.01*np.sqrt(10000))\n", "print(\"Expected mean distance from the center: \",np.sqrt(np.pi/2)*np.sqrt(2)*0.01*np.sqrt(10000)*np.sqrt(np.pi/2))\n"]}, {"cell_type": "markdown", "id": "16c2ed06", "metadata": {"tags": ["lect_02", "learner"]}, "source": ["These agree well with the MC values for average distance $x\\approx 2.2$ and its standard deviation $x_{rms}\\approx 1.7$."]}, {"cell_type": "markdown", "id": "e1779e8a", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='exercises_21_2'></a>     \n", "\n", "| [Top](#section_21_0) | [Restart Section](#section_21_2) | [Next Section](#section_21_3) |\n"]}, {"cell_type": "markdown", "id": "c1f394d7", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-20.2.1</span>\n", "\n", "What happens to the velocity distribution as we run our simulation over many time steps? Complete the function below, which is just a slight change to the function `MCSim` above, to compare the total velocity before and after, then choose the best option below:\n", "\n", "A) There is at most only a very small change which is not statistically significant.\\\n", "B) After a long time, the velocity decreases\\\n", "C) After a long time, the velocity increases."]}, {"cell_type": "code", "execution_count": null, "id": "15624cd4", "metadata": {"tags": ["py", "learner", "draft"]}, "outputs": [], "source": ["#>>>EXERCISE: L20.2.2\n", "\n", "def MCSim_compare(sigmav=1,nsteps=10000,ntoys=5000,dt=0.01,iDump=True):\n", "    partpos=np.zeros((ntoys,2)) #x and y\n", "    partvel=np.random.normal(0,1,(ntoys,2))\n", "    \n", "    print(\"velocity before:\", #YOUR CODE HERE)\n", "    \n", "    #YOUR CODE HERE\n", "    #HINT: see function in `L20.2-runcell01`\n", "   \n", "    print(\"velocity after:\", #YOUR CODE HERE)\n", "\n", "MCSim()"]}, {"cell_type": "markdown", "id": "8fc6c3e8", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-20.2.2</span>\n", "\n", "Consider a microscopic particle undergoing Brownian motion in a fluid. The particle's displacement at each time step follows a random walk pattern due to collisions with surrounding molecules. Which of the following statements about Brownian motion and random walks is/are correct? Select ALL that apply:\n", "\n", "A) Brownian motion follows a deterministic trajectory governed by classical mechanics, and the particle's position at any given time can be precisely predicted.\n", "\n", "B) In Brownian motion, the particle's path is continuous, smooth, and follows a well-defined trajectory over time.\n", "\n", "C) The increments of a random walk in Brownian motion are often modeled as independent, identically distributed Gaussian random variables.\n", "\n", "D) Brownian motion violates the conservation of energy principle, leading to erratic behavior that contradicts classical physics."]}, {"cell_type": "markdown", "id": "41bb197f", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='section_21_3'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L20.3 Adding Elements of Realism</h2>  \n", "\n", "| [Top](#section_21_0) | [Previous Section](#section_21_2) | [Exercises](#exercises_21_3) | [Next Section](#section_21_4) |"]}, {"cell_type": "markdown", "id": "4b46a028", "metadata": {"tags": ["lect_03", "learner"]}, "source": ["*The material in this section is discussed in the video **<a href=\"https://courses.mitxonline.mit.edu/learn/course/course-v1:MITxT+8.S50.3x+3T2023/block-v1:MITxT+8.S50.3x+3T2023+type@sequential+block@seq_LS20/block-v1:MITxT+8.S50.3x+3T2023+type@vertical+block@vert_LS20_vid3\" target=\"_blank\">HERE</a>.** You are encouraged to watch that video and use this notebook concurrently.*"]}, {"cell_type": "markdown", "id": "af4ff315", "metadata": {"tags": ["lect_03", "learner"]}, "source": ["Now, starting from our initial idealized Monte Carlo simulation, we can start to add elements of realism which will, of course, inevitably will make our MC code slower. As a first example, let's put a wall in our particle simulation. When a particle hits the wall, we will need to invert the component of the velocity perpendicular to the wall.\n", "\n", "Let's go ahead and implement this. If the x-position of our sample is greater than the wall value ($x=2$ in the code below) then,  instead of simulating an elastic collision, we simply flip the $x$ component of the velocity. "]}, {"cell_type": "code", "execution_count": null, "id": "63a61093", "metadata": {"tags": ["lect_03", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L20.3-runcell01\n", "\n", "def MCSim(sigmav=1,nsteps=10000,ntoys=5000,dt=0.01,iDump=True):\n", "    partpos=np.zeros((ntoys,2)) #x and y\n", "    partvel=np.random.normal(0,1,(ntoys,2))\n", "    for t0 in range(nsteps):\n", "        opartvel = np.random.normal(0,1,(ntoys,2))\n", "        partpos += partvel*dt\n", "        comvel   = 0.5*(partvel + opartvel)\n", "        difvel   = 0.5*(partvel - opartvel)        \n", "        theta = np.random.uniform(0,2.*np.pi,ntoys)\n", "        R     = np.array(((np.cos(theta), -1*np.sin(theta)), (np.sin(theta), np.cos(theta))))\n", "        RMat  = np.swapaxes(R,0,2)\n", "        tmp=np.einsum('BNi,Bi ->BN', RMat, difvel)\n", "        #Now, let's add our velocity if its not at the well\n", "        partvel[partpos[:,0] < 2] = comvel[partpos[:,0] < 2]+tmp[partpos[:,0] < 2]\n", "        #And let's flip it if it is at the wall        \n", "        partvel[partpos[:,0] > 2] = [-1,1]*partvel[partpos[:,0] > 2]\n", "        \n", "    if iDump:\n", "        _,bins,_=plt.hist(partpos[:,1],bins=30,alpha=0.5,label='y-position')\n", "        plt.hist(partpos[:,0],bins=bins,alpha=0.5,label='x-position')\n", "        plt.legend()\n", "        plt.show()\n", "        _,bins,_=plt.hist(partvel[:,1],bins=30,alpha=0.5,label='y-velocity')\n", "        plt.hist(partvel[:,0],bins=bins,alpha=0.5,label='x-velocity')\n", "        plt.legend()\n", "        plt.show()\n", "MCSim()"]}, {"cell_type": "markdown", "id": "91ec0a27", "metadata": {"tags": ["lect_03", "learner"]}, "source": ["Now, we could do something even more complicated by imagining that we have a tube and we are looking at the Brownian motion within the tube. Particles which hit the tube will then have both the $x$ and $y$ components of their velocities reflected in the opposite direction. In other words, we have\n", "\n", "$$\n", "v_{i} = - v_{i} \\forall i {\\rm~ where~} r_{i}=\\sqrt{x_{i}^2+y_{i}^2} > r_{\\rm tube}\n", "$$\n", "\n", "or reflecting particles that try to escape the tube. Let's go ahead and make a tube of radius $2$."]}, {"cell_type": "code", "execution_count": null, "id": "b3673b8c", "metadata": {"tags": ["lect_03", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L20.3-runcell02\n", "\n", "def MCSim_tube(sigmav=1,nsteps=10000,ntoys=5000,dt=0.01,rtube=2.0,iDump=True):\n", "    partpos=np.zeros((ntoys,2)) #x and y\n", "    partvel=np.random.normal(0,sigmav,(ntoys,2))\n", "    for t0 in range(nsteps):\n", "        opartvel = np.random.normal(0,sigmav,(ntoys,2))\n", "        partpos += partvel*dt\n", "        comvel   = 0.5*(partvel + opartvel)\n", "        difvel   = 0.5*(partvel - opartvel)\n", "        theta = np.random.uniform(0,2.*np.pi,ntoys)\n", "        R     = np.array(((np.cos(theta), -1*np.sin(theta)), (np.sin(theta), np.cos(theta))))\n", "        RMat  = np.swapaxes(R,0,2)\n", "        #tmp2=np.matmul(RMat[0],difvel[0])\n", "        tmp=np.einsum('BNi,Bi ->BN', RMat, difvel)\n", "        #Now define inside the tube\n", "        intube  = partpos[:,0]**2+partpos[:,1]**2 < rtube**2\n", "        partvel[intube]  = comvel[intube]+tmp[intube]\n", "        partvel[~intube] = -partvel[~intube]\n", "    if iDump:\n", "        _,bins,_=plt.hist(partpos[:,1],bins=30,alpha=0.5,label='y-position')\n", "        plt.hist(partpos[:,0],bins=bins,alpha=0.5,label='x-position')\n", "        plt.legend()\n", "        plt.show()\n", "        _,bins,_=plt.hist(partvel[:,1],bins=30,alpha=0.5,label='y-velocity')\n", "        plt.hist(partvel[:,0],bins=bins,alpha=0.5,label='x-velocity')\n", "        plt.legend()\n", "        plt.show()\n", "        \n", "MCSim()"]}, {"cell_type": "markdown", "id": "4f0ac2ed", "metadata": {"tags": ["lect_03", "learner"]}, "source": ["We can imagine considering even more complicated scenarios, and the nice thing is that all this really needs is for us to program it! It is also important here to note that we are taking advantage of the numpy scheme to parallelize everything. This allows us to simulate 1000s of particles at the same time, and makes everything nice and fast!"]}, {"cell_type": "markdown", "id": "2c715e96", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='exercises_21_3'></a>     \n", "\n", "| [Top](#section_21_0) | [Restart Section](#section_21_3) | [Next Section](#section_21_4) |\n"]}, {"cell_type": "markdown", "id": "485738db", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-20.3.1</span>\n", "\n", "For particles in a tube, as simulated in code cell `L20.3-runcell02`, how do the spatial and velocity distributions of the particles change if we increase the velocity spread of the particles (in other words, if we increase `sigmav`)? Complete and run the code below to help answer this question. In order to make the tube less restrictive, set its radius to 10. Select ALL that apply.\n", "\n", "Note: To ensure the same approximate number of collisions, one should appropriately increase the time step at lower velocities.\n", "\n", "When the velocity spread is broader (i.e., larger `sigmav`),\n", "\n", "A) the spatial distribution of particles becomes narrower.\n", "\n", "B) the spatial distribution of particles remains the same.\n", "\n", "C) the spatial distribution of particles becomes more wider.\n", "\n", "D) the distribution of particle velocities becomes narrower.\n", "\n", "E) the distribution of particle velocities remains the same.\n", "\n", "F) the distribution of particle velocities becomes wider.\n"]}, {"cell_type": "code", "execution_count": null, "id": "c822c309", "metadata": {"scrolled": false, "tags": ["py", "draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L20.3.1\n", "\n", "print('sigmav=100')\n", "#RUN `MCSim` with appropriate parameters\n", "print()\n", "\n", "print('sigmav=1')\n", "#RUN `MCSim` with appropriate parameters"]}, {"cell_type": "markdown", "id": "4f6ee8dc", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-20.3.2</span>\n", "\n", "What would the distribution of the particles look like if you had a box with walls at $x=\\pm2$ and $y=\\pm2$? Edit the `inbox` variables in the code below and run it to help answer this question.\n", "\n", "A) The distribution is concentrated around the center of the square.\n", "\n", "B) Particle density is higher at the corners of the square.\n", "\n", "C) Particles are uniformly distributed in both dimensions.\n", "\n", "D) Particles are more likely to be found near the edges of the square.\n"]}, {"cell_type": "code", "execution_count": null, "id": "6b00da8e", "metadata": {"tags": ["py", "draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L20.3.2\n", "\n", "def MCSim_box(sigmav=1,nsteps=10000,ntoys=5000,dt=0.01,iDump=True):\n", "    partpos=np.zeros((ntoys,2)) #x and y\n", "    partvel=np.random.normal(0,sigmav,(ntoys,2))\n", "    for t0 in range(nsteps):\n", "        opartvel = np.random.normal(0,sigmav,(ntoys,2))\n", "        partpos += partvel*dt\n", "        comvel   = 0.5*(partvel + opartvel)\n", "        difvel   = 0.5*(partvel - opartvel)\n", "        theta = np.random.uniform(0,2.*np.pi,ntoys)#elastic collisions in the COM equate to equal energy ad a theta rotation\n", "        R     = np.array(((np.cos(theta), -1*np.sin(theta)), (np.sin(theta), np.cos(theta))))\n", "        RMat  = np.swapaxes(R,0,2)\n", "        tmp=np.einsum('BNi,Bi ->BN', RMat, difvel)\n", "\n", "        inbox  = #YOUR CODE HERE\n", "        inbox_x  = #YOUR CODE HERE\n", "        inbox_y  = #YOUR CODE HERE\n", "        \n", "        partvel[inbox]  = comvel[inbox]+tmp[inbox]\n", "        partvel[~inbox_x] = [-1.,1]*partvel[~inbox_x] \n", "        partvel[~inbox_y] = [1.,-1]*partvel[~inbox_y]\n", "    if iDump:\n", "        _,bins,_=plt.hist(partpos[:,1],bins=30,alpha=0.5,label='y-position')\n", "        plt.hist(partpos[:,0],bins=bins,alpha=0.5,label='x-position')\n", "        plt.legend()\n", "        plt.show()\n", "        _,bins,_=plt.hist(partvel[:,1],bins=30,alpha=0.5,label='y-velocity')\n", "        plt.hist(partvel[:,0],bins=bins,alpha=0.5,label='x-velocity')\n", "        plt.legend()\n", "        plt.show()\n", "\n", "MCSim_box()"]}, {"cell_type": "markdown", "id": "ea30879b", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='section_21_4'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L20.4 Modeling Physics Observables: Bragg Scattering for Proton Therapy</h2>  \n", "\n", "| [Top](#section_21_0) | [Previous Section](#section_21_3) | [Exercises](#exercises_21_4) | [Next Section](#section_21_5) |"]}, {"cell_type": "markdown", "id": "70caebc8", "metadata": {"tags": ["lect_04", "learner"]}, "source": ["*The material in this section is discussed in the video **<a href=\"https://courses.mitxonline.mit.edu/learn/course/course-v1:MITxT+8.S50.3x+3T2023/block-v1:MITxT+8.S50.3x+3T2023+type@sequential+block@seq_LS20/block-v1:MITxT+8.S50.3x+3T2023+type@vertical+block@vert_LS20_vid4\" target=\"_blank\">HERE</a>.** You are encouraged to watch that video and use this notebook concurrently.*\n"]}, {"cell_type": "markdown", "id": "e6676062", "metadata": {"tags": ["lect_04", "learner"]}, "source": ["<h3>Overview</h3>\n", "\n", "There are a broad range of physics processes that we can use Monte Carlo techniques to simulate. They typically involve scenarios where we don't have a good understanding of the analytic form of the whole system, but we understand how it works. Let's try an example by simulating a particle passing through matter. This is one of the most common simulations, because we understand all the different subprocesses well, but when we put them all together they are rather complicated.\n", "\n", "We will do this in the context of proton therapy data. Proton therapy is a way to treat cancerous cells through a non-invasive approach whereby we fire energetic proton beams aimed at various body parts. These beams are precisely controlled to deliver a dose of radiation at just the right spot. Let's go ahead and do a simple simulation.\n"]}, {"cell_type": "markdown", "id": "70afbe99", "metadata": {"tags": ["lect_04", "learner"]}, "source": ["<h3>Sources</h3>\n", "\n", "In what follows, we reference this paper (although the specific notation we use differs from that in the paper): https://pdg.lbl.gov/2022/reviews/rpp2022-rev-passage-particles-matter.pdf\n", "\n", "The code we are using is from a \"Toolkit for Monte Carlo simulation of ionizing radiation\": https://github.com/nrc-cnrc/EGSnrc\n"]}, {"cell_type": "markdown", "id": "f64b28f8", "metadata": {"tags": ["lect_04", "learner"]}, "source": ["<h3>The Model</h3>\n", "\n", "What we are going to do first is model the energy loss (or mass stopping power) of a charged particle traveling through matter, which is given by the **Bethe-Bloch formula:**\n", "\n", "$$\n", "-\\frac{dE}{dx} = \\frac{4\\pi nz^2}{m_{e}c^{2}\\beta^{2}}\\left(\\frac{e^{2}}{4\\pi\\epsilon_{0}}\\right)^{2}\\left[\\log\\left(\\frac{2\\gamma^{2}m_{e}c^{2}\\beta^{2}T_{\\rm max}}{I(1-\\beta)^{2}}\\right)-\\beta^{2}-\\frac{\\delta(\\beta\\gamma)}{2}\\right]\n", "$$\n", "\n", "Let's break down the terms in this equation:\n", "\n", "**1.** $-\\dfrac{dE}{dx}$: The rate of energy loss per unit length (path length) of a charged particle as it moves through a material.\n", "\n", "You might wonder why we don't write an equation for the change in energy $dE/dx$ and put the minus sign on the right to indicate that energy is lost. For obscure historical reasons, this somewhat odd looking notation is the conventional way that this equation is presented.\n", "   \n", "<br>\n", "\n", "**2.** $\\dfrac{4\\pi nz^2}{m_{e}c^{2}\\beta^{2}}\\left(\\dfrac{e^{2}}{4\\pi\\epsilon_{0}}\\right)^{2}$: Various physical constants and characteristics of the particle and the material:\n", " - $n$ is the number density of electrons in the material.\n", " - $z$ is the charge of the particle.\n", " - $m_{e}$ is the rest mass of the electron.\n", " - $c$ is the speed of light.\n", " - $\\beta$ is the velocity of the charged particle normalized to the speed of light ($\\beta={v}/{c}$).\n", " - $e$ is the elementary charge (i.e. the magnitude of the charge of an electron or proton).\n", " - $\\epsilon_{0}$ is the vacuum permittivity (the constant found in the equation for the force between two charged particles).\n", "\n", "\n", "**3.** $\\log\\left(\\dfrac{2\\gamma^{2}m_{e}c^{2}\\beta^{2}T_{\\rm max}}{I(1-\\beta)^{2}}\\right)-\\beta^{2}-\\dfrac{\\delta(\\beta\\gamma)}{2}$: The functional form describing the particle's energy loss processes, where:\n", " - $\\gamma$ is the Lorentz factor $\\left ({1}/{\\sqrt{1-\\beta^{2}}}\\right)$ for the particle.\n", " - $T_{\\rm max}$ is the maximum kinetic energy transfer in a single collision between the particle and an electron in the material. This can be calculated exactly for a 2-body elastic collision giving:\n", " $$T_{\\rm max}=\\frac{2m_{e}\\left (c\\beta\\gamma\\right )^2}{1+\\dfrac{2\\gamma m_{e}}{m}+\\left(\\dfrac{m_{e}}{m}\\right )^2}$$\n", " with $m$ being the particle's mass.\n", " - $I$ is the mean ionization energy of the material.\n", " - $\\delta(\\beta\\gamma)$ is a density correction term, accounting for the effects of atomic screening of the energy loss.\n"]}, {"cell_type": "markdown", "id": "df286559", "metadata": {"tags": ["lect_04", "learner"]}, "source": ["Now, to make a realistic numerical calculation, we need the value of the ionization energy, $I$, which you can find tabulated in numerous places. In particular, it is plotted as a function of the atomic number $Z$ of the material in Fig. 34.5 on page 9 of the <a href=\"https://pdg.lbl.gov/2022/reviews/rpp2022-rev-passage-particles-matter.pdf\" target=\"_blank\">paper</a> mentioned above. It depends on the atomic structure of each element, but is roughly flat as a function $Z$ as you get to heavier elements. For our purposes, we will just parameterize this using as table.\n", "\n", "In addition, we also need the atomic masses $A$ of all the elements, which we can again take from various online sources. For people familiar with the MC code most often used to simulate physics detectors, we have taken these values from the particle simulation code Geant in Fortran. Let's plot these two quantities."]}, {"cell_type": "code", "execution_count": null, "id": "2ac201a3", "metadata": {"scrolled": false, "tags": ["lect_04", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L20.4-runcell01\n", "\n", "#values\n", "def I(iZ,iPlot=False):\n", "    #https://github.com/nrc-cnrc/EGSnrc/blob/master/HEN_HOUSE/pegs4/pegs4.mortran#L1354-L1391\n", "    lI=[19.2,41.8,40.,63.7,76.0,78.0,82.0,95.0,115.,137.,\n", "     149.,156.,166.,173.,173.,180.,174.,188.,190.,191.,216.,233.,245.,\n", "     257.,272.,286.,297.,311.,322.,330.,334.,350.,347.,348.,357.,352.,\n", "     363.,366.,379.,393.,417.,424.,428.,441.,449.,470.,470.,469.,488.,\n", "     488.,487.,485.,491.,482.,488.,491.,501.,523.,535.,546.,560.,574.,\n", "     580.,591.,614.,628.,650.,658.,674.,684.,694.,705.,718.,727.,736.,\n", "     746.,757.,790.,790.,800.,810.,823.,823.,830.,825.,794.,827.,826.,\n", "     841.,847.,878.,890.,902.,921.,934.,939.,952.,966.,980.,994.]\n", "    lZ=np.arange(1,len(lI)+1)\n", "    if iPlot:\n", "        plt.plot(lZ,lI/lZ)\n", "        plt.xlabel('Z')\n", "        plt.ylabel('I$_{adj}$/Z (eV/Z)')\n", "        plt.show()\n", "    return lI[iZ]*1e-6 #MeV not eV\n", "\n", "def A(iZ,iPlot=False):\n", "    #https://github.com/nrc-cnrc/EGSnrc/blob/master/HEN_HOUSE/pegs4/pegs4.mortran#L1354-L1391\n", "    lA=[1.00797,4.0026,6.939,9.0122,10.811,12.01115,14.0067,\n", "     15.9994,18.9984,20.183,22.9898,24.312,26.9815,28.088,30.9738,\n", "     32.064,35.453,39.948,39.102,40.08,44.956,47.90,50.942,51.998,\n", "     54.9380,55.847,58.9332,58.71,63.54,65.37,69.72,72.59,74.9216,\n", "     78.96,79.808,83.80,85.47,87.62,88.905,91.22,92.906,95.94,99.0,\n", "     101.07,102.905,106.4,107.87,112.4,114.82,118.69,121.75,127.60,\n", "     126.9044,131.30,132.905,137.34,138.91,\n", "     140.12,140.907,144.24,147.,150.35,151.98,157.25,158.924,162.50,\n", "     164.930,167.26,168.934,173.04,174.97,178.49,180.948,183.85,\n", "     186.2,190.2,192.2,195.08,196.987,200.59,204.37,207.19,208.980,\n", "     210.,210.,222.,223.,226.,227.,232.036,231.,238.03,237.,242.,\n", "     243.,247.,247.,248.,254.,253.   \n", "    ]\n", "    lZ=np.arange(1,len(lA)+1)\n", "    if iPlot:\n", "        plt.plot(lZ,lA/lZ)\n", "        plt.xlabel('Z')\n", "        plt.ylabel('A/Z (Atomic mass/Z)')\n", "        plt.show()\n", "    return lA[iZ-1]\n", "lItmp=I(1,True)\n", "lItmp=A(1,True)"]}, {"cell_type": "markdown", "id": "7d5195e9", "metadata": {"tags": ["lect_04", "learner"]}, "source": ["Now we have all the elements to compute the Bethe-Bloch formula and look at charged particle energy loss over distance. For this part, we are going to focus on protons. However, this generally applies to a lot of different phenomena.  \n", "\n", "Additionally, we will plot this for two atomic elements. Since we care about the human body, we will plot this for water (specifically the oxygen). In order to  show something heavier that's found in a human, we'll also calculate this for calcium, which is a major component of bone. More information about what a human body is comprised of can be found <a href=\"https://en.wikipedia.org/wiki/Composition_of_the_human_body\" target=\"_blank\">here.</a>\n", "\n", "For comparison, we'll also show the energy loss for pions and muons. In all three cases, we'll plot the energy loss as a function of momentum.\n", "\n", "You will note that the momentum axis is labelled \"MeV\" (million electron volts), which is actually a unit of energy. A more accurate notation with correct units is \"MeV/$c$\" (where $c$ is the speed of light). Physicists tend to get lazy about including factors of $c$. As another example, they also refer to the mass of particles using energy units (see the line `m_e = 0.511 # Mass of electron in MeV` in the code cell below), which omits the factor of $c^2$ that relates mass and energy in Einstein's famous equation $E=mc^2$."]}, {"cell_type": "code", "execution_count": null, "id": "fb55e1f5", "metadata": {"tags": ["lect_04", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L20.4-runcell02\n", "\n", "#https://indico.cern.ch/event/753612/contributions/3121551/attachments/1974578/3285956/MC_2019.pdf\n", "#https://www.nature.com/articles/s41598-017-10554-0\n", "\n", "m_e = 0.511 # Mass of electron in MeV\n", "\n", "def gamma(ip,im): #E^2=gamma^2m^2=p^2+m^2\n", "    return np.sqrt(1+(ip/im)**2)\n", "\n", "def beta(ip,im): #gamma=1/sqrt(1-b^2)\n", "    g=gamma(ip,im)\n", "    return np.sqrt(1-1./g**2)\n", "\n", "def betagamma(ip,im):#p=bgm\n", "    return ip/im\n", "\n", "def Tmax(ip,im): # Maximum energy transfer in one collision in MeV\n", "    return 2*m_e*(ip/im)**2/(1+2*gamma(ip,im)*m_e/im+(m_e/im)**2)\n", "\n", "def TKinheavy(ip,im): #(T+M)^2=sqrt(p)+sqrt(m)\n", "    return np.sqrt(np.sqrt(ip)+np.sqrt(um))-im\n", "\n", "def delta(ip,im):\n", "    C = 4.44\n", "    a = 0.1492\n", "    m = 3.25\n", "    X1 = 2.87\n", "    X0 = 0.2014\n", "    delta0 = 0.14\n", "    x = np.log10(ip/im)\n", "    #f1 = lambda x: delta0 * 10**(2*(x-X0)) # conductors pdg\n", "    f2 = 2 * x * np.log(10) - C + (a * np.maximum(0, (X1 - x))**m) #using np.maximum to prevent warning when x > X1\n", "    f3 = 2 * x * np.log(10) - C\n", "    delta_full = np.where(x < X0 , 0, f2)\n", "    delta_full = np.where(x < X1, delta_full, f3)\n", "    return delta_full\n", "        \n", "def dEdxF(ip,im,iZ,zpart=1,rho=1.0,nodelta=False): #Bethe-Bloch equation\n", "    K = 0.307075 # constant K in MeV cm mol^-1\n", "    #rho = 2.336 # Density of material in g cm^-3 (here: silicon density)\n", "    const   = zpart**2 * (K * rho * iZ ) / (2 * A(iZ)) * (1./beta(ip,im)**2)\n", "    logterm = 2 * m_e * Tmax(ip,im) * ((ip/im)**2)/(I(iZ)**2) \n", "    dEdxV   =  const * (np.log(logterm)  - 2*(beta(ip,im))**2 - delta(ip,im))              \n", "    if nodelta:\n", "        print(\"delta:\",delta(ip,im),dEdxV)\n", "        dEdxV    =  const * (np.log(logterm) - 2*(beta(ip,im))**2)\n", "    return dEdxV\n", "    \n", "mproton=938\n", "mpion=135.4\n", "mmuon=105.4\n", "print(\"Gamma and Beta for a proton of momentum 100 MeV:\",gamma(100,mproton),beta(100,mproton))\n", "p=np.arange(15,1000000,10)\n", "dEdxOut1p = dEdxF(p,mproton,8,1)\n", "dEdxOut2p = dEdxF(p,mproton,18,1)\n", "dEdxOut1pi = dEdxF(p,mpion,8,1)\n", "dEdxOut2pi = dEdxF(p,mpion,18,1)\n", "dEdxOut1mu = dEdxF(p,mmuon,8,1)\n", "dEdxOut2mu = dEdxF(p,mmuon,18,1)\n", "\n", "plt.plot(p,dEdxOut1p,label=\"Proton\")\n", "plt.plot(p,dEdxOut2p,label=\"Proton(Calcium)\")\n", "\n", "plt.plot(p,dEdxOut1pi,label=\"Pion\")\n", "plt.plot(p,dEdxOut2pi,label=\"Pion(Calcium)\")\n", "\n", "plt.plot(p,dEdxOut1mu,label=\"Muon\")\n", "plt.plot(p,dEdxOut2mu,label=\"Muon(Calcium)\")\n", "\n", "plt.xlabel('Momentum (MeV)')\n", "plt.ylabel('dE/dx (MeV/cm) (rho=1 g/cm$^{3}$)')\n", "plt.xscale('log')\n", "plt.yscale('log')\n", "plt.legend()\n", "plt.show()\n", "\n", "\n", "print(\"Beta for a proton of momentum 935 MeV (the same as its mass):\",beta(935,mproton))"]}, {"cell_type": "markdown", "id": "515332b2", "metadata": {"tags": ["lect_04", "learner"]}, "source": ["<h3>A Basic Simulation</h3>\n", "\n", "We see that more energy is deposited at lower momentum, but the behavior is not monotonic. We can run a basic simulation of how the energy of a particle changes as it moves through matter by giving it some initial energy, and then stepping down the kinetic energy by subtracting the energy loss at each increment of distance. Ultimately, we want to plot both momentum and energy loss as functions of distance. We could perhaps do this analytically, but using the above formula makes it particularly nice and elegant. Let's go ahead and run our simulation for our proton energy beam!\n", "\n", "The plot above showed energy loss as a function of momentum. However, in the following, when we say we have a 350 MeV proton, we actually mean the kinetic energy is 350 MeV. The momentum is given by:\n", "\n", "$$\n", "E_{\\rm Total}^2 = \\left (E_{\\rm kin} + m \\right )^2  = p^2 + m^2 \\\\\n", "p^2 = (E_{kin} + m)^2 - m^2\n", "$$\n", "\n", "As mentioned above, the factors of $c^2$ attached to the mass have been omitted.\n", "\n", "If the particle is nonrelativistic ($E_{\\rm kin}\\ll m$), this reduces to:\n", "\n", "$$\n", "p=\\sqrt{2 E_{\\rm kin} m}=mv\n", "$$"]}, {"cell_type": "code", "execution_count": null, "id": "37c169b4", "metadata": {"scrolled": false, "tags": ["lect_04", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L20.4-runcell03\n", "\n", "def dP(dE,ip,im): #solving \n", "    #dp = ip - np.sqrt(dE**2+ip**2-2*dE*np.sqrt(ip**2+im**2))\n", "    #E=p^2/2m=> p=\\sqrt(2mE)=>dp=sqrt(2m)/sqrt(E) dE\n", "    #return dE*(np.sqrt(ip**2+im**2)/ip)*gamma(ip,im)\n", "    return dE#*(ip/im)\n", "\n", "def eToP(iE,im):\n", "    return np.sqrt((iE+im)**2-im**2)\n", "\n", "def sim(ie=500,im=935,idt=1e-11,iZ=8):\n", "    xstep  = np.array([])\n", "    estep  = np.array([])\n", "    pstep  = np.array([])\n", "    c=3e10\n", "    dist=0\n", "    e=ie\n", "    while e > 5:\n", "        p = eToP(e,im)\n", "        dEdxS  = dEdxF(p,im,iZ=iZ,rho=1.06)\n", "        #print(dEdxS)\n", "        dx     = beta(p,im)*c*idt#speed of light\n", "        #print(dEdxS,dP(dEdxS*dx,p,im))\n", "        e      -= dEdxS*dx\n", "        dist   += dx\n", "        xstep  = np.append(xstep,dist)\n", "        estep  = np.append(estep,dEdxS*dx)\n", "        pstep  = np.append(pstep,e)\n", "    return xstep,pstep,estep\n", "    \n", "print(\"350 MeV Proton Momentum:\",eToP(350,mproton))\n", "xstep150,pstep150,estep150 = sim(ie=150,im=mproton,idt=1e-11,iZ=8)\n", "xstep200,pstep200,estep200 = sim(ie=200,im=mproton,idt=1e-11,iZ=8)\n", "xstep250,pstep250,estep250 = sim(ie=250,im=mproton,idt=1e-11,iZ=8)\n", "xstep300,pstep300,estep300 = sim(ie=300,im=mproton,idt=1e-11,iZ=8)\n", "\n", "plt.plot(xstep150,pstep150,label='150 MeV')\n", "plt.plot(xstep200,pstep200,label='200 MeV')\n", "plt.plot(xstep250,pstep250,label='250 MeV')\n", "plt.plot(xstep300,pstep300,label='300 MeV')\n", "plt.xlabel('Distance(cm)')\n", "plt.ylabel('Momentum(MeV)')\n", "plt.legend()\n", "plt.show()\n", "plt.plot(xstep150,estep150,label='150 MeV')\n", "plt.plot(xstep200,estep200,label='200 MeV')\n", "plt.plot(xstep250,estep250,label='250 MeV')\n", "plt.plot(xstep300,estep300,label='300 MeV')\n", "plt.xlabel('Distance(cm)')\n", "plt.ylabel('E-deposit(MeV/mm)')\n", "plt.legend()\n", "plt.show()\n", "\n", "#sim(60,dt=1e-12)"]}, {"cell_type": "markdown", "id": "43f8337b", "metadata": {"tags": ["lect_04", "learner"]}, "source": ["Now, what you see is that we get a very sharp increase in the energy deposit in a relatively narrow region. As a result, we can use proton beams for cancer therapy by depositing a huge amount of energy in the body at a specific location. This peak is known as the **Bragg peak.** You can see that different beam energies can be selected in order to target different locations in the body."]}, {"cell_type": "markdown", "id": "1c3208ac", "metadata": {"tags": ["lect_04", "learner"]}, "source": ["<h3>More Realistic Simulations</h3>\n", "\n", "Let's go one step further and make our simulation even more realistic. There are three ways to do this:\n", "1. Sample the full energy profile interaction as the particle moves through the material.\n", "2. Smear the initial beam energy by the input resolution.\n", "3. Add other effects, in particular multiple scattering.\n", "\n", "Let's go ahead and start with the first option, since this is often the most illustrative.\n", "\n", "The energy loss over a particular step is not exactly the unique fixed amount given by the Bethe-Bloch formula but, instead, is actually governed by a Landau distribution, whose probability (for a mean of zero and a specific scale factor) is given by\n", "\n", "$$\n", "p(x|\\mu,c) = \\frac{1}{c\\pi}\\int_{0}^{\\infty} e^{-t}\\cos\\left(t\\left(\\frac{x-\\mu}{c}\\right) + \\frac{2t}{\\pi}\\log\\left(\\frac{t}{c}\\right)\\right) dt\n", "$$\n", "\n", "where $\\mu$ is the most probable value (MPV) and $c$ is a width parameter. In the code below we label the mean as `landauMPV`, the width term $c$ is labeled as constant. These terms are extracted from the Physics particle data-group, and are well studied. \n", "\n", "To model energy loss more accurately, what we need to do is sample a Landau distribution at every step and use that sampled value in our calculation of $dE/dx$. Let's first go ahead and plot the probability density function of energy loss using the Landau distribution, and then come up with a scheme to sample it.\n", "\n", "\n", "First lets plot the landaus.\n"]}, {"cell_type": "code", "execution_count": null, "id": "bd4f90b7", "metadata": {"tags": ["lect_04", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L20.4-runcell04\n", "\n", "import pylandau\n", "from landaupy import landau\n", "\n", "def landauMPV(ip,im,iZ,irho=1,zpart=1):\n", "    K = 0.307075 # constant K in MeV cm mol^-1\n", "    const   = zpart**2 * (K * irho * iZ ) / (2 * A(iZ)) * (1./beta(ip,im)**2)\n", "    #logterm  = 2 * m_e * Tmax(ip,im) * ((ip/im)**2)/(I(iZ)**2) \n", "    logterm1 = 2 * m_e *               ((ip/im)**2)/(I(iZ)) \n", "    logterm2 = const/I(iZ)\n", "    dEdxV    =  const * (np.log(logterm1) + np.log(logterm2) + 0.2     - (beta(ip,im))**2 - delta(ip,im))       # \n", "    return dEdxV,const\n", "\n", "def plotLandau(ip,im,idx,iZ=14,irho=1,zpart=1):\n", "    lP=eToP(ip,im)\n", "    lMPV,lWMPV = landauMPV(lP,im,iZ,irho,zpart)\n", "    lMPV*=idx; lWMPV*=idx\n", "    x=np.arange(0,15.5,0.01)\n", "    landpy=landau.pdf(x,lMPV,lWMPV)\n", "    return x,landpy\n", "\n", "x,landZ150=plotLandau(150,mproton,1.0,iZ=8,irho=1.0)\n", "x,landZ200=plotLandau(200,mproton,1.0,iZ=8,irho=1.0)\n", "x,landZ250=plotLandau(250,mproton,1.0,iZ=8,irho=1.0)\n", "x,landZ300=plotLandau(300,mproton,1.0,iZ=8,irho=1.0)\n", "\n", "plt.plot(x,landZ150,label='E=150 MeV')\n", "plt.plot(x,landZ200,label='E=200 MeV')\n", "plt.plot(x,landZ250,label='E=250 MeV')\n", "plt.plot(x,landZ300,label='E=300 MeV')\n", "plt.xlabel(\"dE/dx (MeV/cm)/rho\")\n", "plt.ylabel(\"pdf\")\n", "plt.legend()\n", "plt.show()\n"]}, {"cell_type": "markdown", "id": "1339ae05", "metadata": {"tags": ["lect_04", "learner"]}, "source": ["Now, what we can do to add some level of realism as we move along our path of the proton going through matter. Every time we step, we can sample the landau distribution pdf and step our energy loss. Given that we are sampling, it now makes sense to run this experiment a number of times. This now starts to give us a real Monte Carlo description!  \n", "\n", "Sampling complicated distributions like this can often be slow. This code was implemented <a href=\"https://github.com/SengerM/landaupy/blob/main/landaupy/samplers.py#L42\" target=\"_blank\">here</a>. The strategy is to randomly sample a number from 0 to 1 to get a p-value, then you can get the x-value by inverting the CDF since we know that\n", "\n", "$$\n", "\\rm{cdf}(x)=\\int_{-\\infty}^{x} p(x^{\\prime}) dx^{\\prime}\n", "$$\n", "\n", "So, we can treat the cdf as a 1-to-1 map, where the $y$ axis is probability and the $x$ axis is the pdf value integrated from $-\\infty$ up to $x$. By inverting the cdf, i.e. inverting the function so that ${\\rm cdf}^{-1}(y)=x$, we are effectively treating this as a lookup table.\n", "\n", "We will stop our proton beam once its kinetic energy is less than 5 MeV. We will take a timestep of 10 picoseconds, which is roughly 1% of the total travel time. Furthemore more,  following what is shown on slide 9 in this <a href=\"https://indico.cern.ch/event/654712/contributions/2666034/attachments/1531773/2397743/SJ_STFCDetectors_ProCal_25-09-17.pdf\" target=\"_blank\">talk.</a> we expect a resolutoin of roughly 1.5%, which motviates the choice of the time step. \n"]}, {"cell_type": "code", "execution_count": null, "id": "8fda3b27", "metadata": {"tags": ["lect_04", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L20.4-runcell05\n", "\n", "def simSample(ie=500,im=935,idt=1e-11,iZ=8):\n", "    xstep  = np.array([])\n", "    estep  = np.array([])\n", "    pstep  = np.array([])\n", "    c=3e10\n", "    dist=0\n", "    e=ie\n", "    while e > 5:\n", "        p = eToP(e,im)\n", "        lMPV,lWMPV  = landauMPV(p,im,iZ=iZ,irho=1.06)\n", "        dE     = landau.sample(lMPV, lWMPV, 1)\n", "        dx     = beta(p,im)*c*idt#speed of light\n", "        e      -= dE*dx\n", "        dist   += dx\n", "        xstep  = np.append(xstep,dist)\n", "        estep  = np.append(estep,dE*dx)\n", "        pstep  = np.append(pstep,e)\n", "    return xstep,pstep,estep\n", "\n", "xstep150,pstep150,estep150 = simSample(ie=150,im=mproton,idt=1e-11,iZ=8)\n", "xstep200,pstep200,estep200 = simSample(ie=200,im=mproton,idt=1e-11,iZ=8)\n", "xstep250,pstep250,estep250 = simSample(ie=250,im=mproton,idt=1e-11,iZ=8)\n", "xstep300,pstep300,estep300 = simSample(ie=300,im=mproton,idt=1e-11,iZ=8)\n", "\n", "plt.plot(xstep150,pstep150,label='150 MeV')\n", "plt.plot(xstep200,pstep200,label='200 MeV')\n", "plt.plot(xstep250,pstep250,label='250 MeV')\n", "plt.plot(xstep300,pstep300,label='300 MeV')\n", "plt.xlabel('Distance(cm)')\n", "plt.ylabel('Momentum(MeV)')\n", "plt.legend()\n", "plt.show()\n", "plt.plot(xstep150,estep150,label='150 MeV')\n", "plt.plot(xstep200,estep200,label='200 MeV')\n", "plt.plot(xstep250,estep250,label='250 MeV')\n", "plt.plot(xstep300,estep300,label='300 MeV')\n", "plt.xlabel('Distance(cm)')\n", "plt.ylabel('E-deposit(MeV/mm)')\n", "plt.legend()\n", "plt.show()\n", "\n"]}, {"cell_type": "markdown", "id": "e1a7c352", "metadata": {"tags": ["lect_04", "learner"]}, "source": ["You can observe two differences between these plots and the ones without the Landau effect. First, the curves of energy loss versus momentum look less smooth as a result of some values sampled from the Landau probability being larger or smaller than given by the exact Bethe-Bloch formula.\n", "\n", "The much more dramatic effect is the spikes in the energy deposition as a function of distance. These occur because the Landau probability distribution has a very long tail on the high energy side. As a result, while it's still true that the energy deposition is largest at the very end, this difference is reduced somewhat.\n"]}, {"cell_type": "markdown", "id": "ce1d77bd", "metadata": {"tags": ["lect_04", "learner"]}, "source": ["Let's step through this more realistic version and look at the distribution of energy deposited in our system. We will run our simulation 100 times for a proton with a kinetic energy of 150 MeV and see how much the energy deposit varies, as well as how much the length of propagation varies.\n", "\n", "For this, we will define a few observables. Let's look at following:\n", "\n", "(1) Distance: The total distance that the particle travels\\\n", "(2) E-deposit Front: The total energy deposited in the first 3 cm of travel\\\n", "(3) E-deposit Back:  The total energy deposited in the last 3 cm of travel"]}, {"cell_type": "code", "execution_count": null, "id": "8b5fb56d", "metadata": {"scrolled": false, "tags": ["lect_04", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L20.4-runcell06\n", "\n", "def observables(iXArr,iPArr,iEArr):\n", "    lX=iXArr[-1]\n", "    dEEnd=np.sum(iEArr[(iXArr > iXArr[-1]-3)])\n", "    dEFrt=np.sum(iEArr[(iXArr < 3)])\n", "    return lX,dEEnd,dEFrt  \n", "    \n", "def simNSamples(ie=150,im=mproton,iN=100,idt=1e-11,iZ=8):\n", "    pXArr = np.array([])\n", "    pdEBArr = np.array([])\n", "    pdEFArr = np.array([])\n", "    for i0 in range(iN):\n", "        if i0 % 25 == 0:\n", "            print(i0)\n", "        pXstep,pPstep,pEstep = simSample(ie=ie,im=im,idt=idt,iZ=iZ)\n", "        pX,pdEEnd,pdEFrt = observables(pXstep,pPstep,pEstep)\n", "        pXArr   = np.append(pXArr,  pX)\n", "        pdEBArr = np.append(pdEBArr,pdEEnd)\n", "        pdEFArr = np.append(pdEFArr,pdEFrt)\n", "\n", "\n", "    plt.hist(pXArr,label='Distance')\n", "    plt.xlabel('Distance')\n", "    plt.ylabel('N')\n", "    plt.legend()\n", "    plt.show()\n", "    \n", "    plt.hist(pdEFArr,label='dE/dx Front')\n", "    plt.xlabel('E-Deposit Front')\n", "    plt.ylabel('N)')\n", "    plt.legend()\n", "    plt.show()\n", "\n", "    plt.hist(pdEBArr,label='dE/dx Back')\n", "    plt.xlabel('E-Deposit Back')\n", "    plt.ylabel('N)')\n", "    plt.legend()\n", "    plt.show()\n", "\n", "\n", "#plt.plot(xstep150,estep150,label='150 MeV')\n", "#plt.plot(xstep200,estep200,label='200 MeV')\n", "#plt.plot(xstep250,estep250,label='250 MeV')\n", "#plt.plot(xstep300,estep300,label='300 MeV')\n", "#plt.xlabel('Distance(cm)')\n", "#plt.ylabel('E-deposit(MeV/mm)')\n", "#plt.legend()\n", "#plt.show()\n", "\n", "simNSamples()\n"]}, {"cell_type": "markdown", "id": "d07c353b", "metadata": {"tags": ["lect_04", "learner"]}, "source": ["As expected, there are fluctuations in the deposited energy, in particular on the higher energy side and the energy deposited at the end is a factor of 3-4 higher than at the beginning. Perhaps surprisingly, the total distance traveled is a relatively narrow peak, varying by lass than 10%.\n", "\n", "However, running that simulation was kind of slow. Can we speed up this process?\n", "\n", "The way we will do this is we will step through 500 simulations all at the same time in parallel. The one thing that is tricky is that sampling the Landau in parallel is not supported, so we will have to add a `for` loop to do that bit. Otherwise, we can run everything else in parallel. Let's use that extra speed to run 500 samples of 4 different values of the kinetic energy for a total of 20 times more than we did with the previous code.\n"]}, {"cell_type": "code", "execution_count": null, "id": "d85fa1c0", "metadata": {"tags": ["lect_04", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L20.4-runcell07\n", "\n", "def simNParallelSample(iN, ie=500,im=935,idt=1e-10,iZ=8):\n", "    xstep  = np.empty((0,iN))\n", "    estep  = np.empty((0,iN))\n", "    pstep  = np.empty((0,iN))\n", "    c=3e10\n", "    dist=np.zeros(iN)\n", "    e=np.ones(iN)*ie\n", "    print(\"Scanning:\",ie)\n", "    while np.any(e > 5):\n", "        p = eToP(e,im)\n", "        lMPV,lWMPV  = landauMPV(p,im,iZ=iZ,irho=1.06)\n", "        dE = np.zeros(lMPV.shape)\n", "        ##Here we have to parallelize by hand, this is not good\n", "        for i0, (pMPV,pWMPV) in enumerate(zip(lMPV,lWMPV)):\n", "            dE[i0]     = landau.sample(pMPV, pWMPV,1)\n", "        dx     = beta(p,im)*c*idt#speed of light\n", "        pdEdX  = np.minimum(dE*dx,e-0.1)\n", "        e      -= pdEdX\n", "        dist   += dx\n", "        xstep  = np.vstack((xstep,dist))\n", "        estep  = np.vstack((estep,pdEdX))\n", "        pstep  = np.vstack((pstep,e))\n", "    xstep = xstep.T\n", "    estep = estep.T\n", "    pstep = pstep.T\n", "    return xstep,pstep,estep\n", "\n", "def simNSamples(ie=100,im=mproton,iN=500,idt=5e-11,iZ=8):\n", "    xstep,pstep,estep=simNParallelSample(iN,ie=ie,im=im,idt=idt,iZ=iZ)\n", "    plt.hist(xstep[:,-1],alpha=0.5)\n", "    plt.show()\n", "    efront=np.zeros(xstep.shape[0])\n", "    eback =np.zeros(xstep.shape[0])\n", "    for i0 in range(xstep.shape[0]):\n", "        efront[i0] = np.sum(estep[i0,xstep[i0] < 3])/3.\n", "        eback[i0]  = np.sum(estep[i0,xstep[i0] > xstep[i0]-3])/3.\n", "    xrange=np.arange(0,150,2.5)\n", "    _,bins,_=plt.hist(efront,bins=xrange,alpha=0.5,label='dE/dx Front')\n", "    plt.hist(eback, bins=bins,alpha=0.5,label='dE/dx Back')\n", "    plt.legend()\n", "    plt.show()\n", "    \n", "def sumEstep(estep,xstep):\n", "    efront=np.zeros(xstep.shape[0])\n", "    eback =np.zeros(xstep.shape[0])\n", "    for i0 in range(xstep.shape[0]):\n", "        efront[i0] = np.sum(estep[i0,xstep[i0] < 3])/3.\n", "        #print(xstep[i0] < 3,xstep[i0] > xstep[i0,-1]-3,xstep[i0,-1]-3,xstep[i0],estep[i0])\n", "        eback[i0]  = np.sum(estep[i0,xstep[i0] > xstep[i0,-1]-3])/3.\n", "    return efront,eback\n", "\n", "xstep150,pstep150,estep150=simNParallelSample(ie=150,im=mproton,iN=500,idt=1e-10,iZ=8)\n", "xstep200,pstep200,estep200=simNParallelSample(ie=200,im=mproton,iN=500,idt=1e-10,iZ=8)\n", "xstep250,pstep250,estep250=simNParallelSample(ie=250,im=mproton,iN=500,idt=1e-10,iZ=8)\n", "xstep300,pstep300,estep300=simNParallelSample(ie=300,im=mproton,iN=500,idt=1e-10,iZ=8)\n", "\n", "plt.hist(xstep150[:,-1],alpha=0.5,label='E=150 MeV')\n", "plt.hist(xstep200[:,-1],alpha=0.5,label='E=200 MeV')\n", "plt.hist(xstep250[:,-1],alpha=0.5,label='E=250 MeV')\n", "plt.hist(xstep300[:,-1],alpha=0.5,label='E=300 MeV')\n", "plt.xlabel('Distance')\n", "plt.ylabel('N')\n", "plt.legend()\n", "plt.show()\n", "\n", "ef150,eb150=sumEstep(estep150,xstep150)\n", "ef200,eb200=sumEstep(estep200,xstep200)\n", "ef250,eb250=sumEstep(estep250,xstep250)\n", "ef300,eb300=sumEstep(estep300,xstep300)\n", "\n", "xrange=np.arange(0,10,0.25)\n", "plt.hist(ef150,bins=xrange,alpha=0.5,label='E=150 MeV (dE/dx Front)')\n", "plt.hist(ef200,bins=xrange,alpha=0.5,label='E=200 MeV (dE/dx Front)')\n", "plt.hist(ef250,bins=xrange,alpha=0.5,label='E=250 MeV (dE/dx Front)')\n", "plt.hist(ef300,bins=xrange,alpha=0.5,label='E=300 MeV (dE/dx Front)')\n", "plt.xlabel('E-Deposit Front')\n", "plt.ylabel('N)')\n", "plt.legend()\n", "plt.show()\n", "\n", "xrange=np.arange(0,60,2)\n", "plt.hist(eb150,bins=xrange,alpha=0.5,label='E=150 MeV (dE/dx Back)')\n", "plt.hist(eb200,bins=xrange,alpha=0.5,label='E=200 MeV (dE/dx Back)')\n", "plt.hist(eb250,bins=xrange,alpha=0.5,label='E=250 MeV (dE/dx Back)')\n", "plt.hist(eb300,bins=xrange,alpha=0.5,label='E=300 MeV (dE/dx Back)')\n", "plt.xlabel('E-Deposit Back')\n", "plt.ylabel('N)')\n", "plt.legend()\n", "plt.show()\n"]}, {"cell_type": "markdown", "id": "8da3f4dc", "metadata": {"tags": ["lect_04", "learner"]}, "source": ["From these distributions, we can start to make interesting conclusions. As expected, the higher energy beams tend to go farther. They also deposit slightly less energy in the front, but deposit about the same as the lower energies in the back. Notice also the 150 MeV feature where a non-trivial fraction of the protons deposit a lot more than the average in the first 3 cm.\n", "\n", "This Monte Carlo we have developed is pretty sophisticated, but we can do even better if we take into account that our beam is a full 3D distribution. We will consider this next!\n"]}, {"cell_type": "markdown", "id": "cfb89b71", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='exercises_21_4'></a>     \n", "\n", "| [Top](#section_21_0) | [Restart Section](#section_21_4) | [Next Section](#section_21_5) |\n"]}, {"cell_type": "markdown", "id": "1c9251de", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-20.4.1</span>\n", "\n", "In the preceding section, we used `sumEstep` to determine the total amount of energy deposited in the first and last 3 cm of a particle's path, and created a histogram. Now, write a function `sumEstepInWindow` that performs a similar action within a window of width `w`, centered at a position `d`.\n", "\n", "What is the total energy deposited in a window of width 3 cm, centered at a distance of 5 cm, for an initial energy of 250 MeV? Report your answer as a number in MeV with precision 0.1 MeV.\n", "\n", "<br>"]}, {"cell_type": "code", "execution_count": null, "id": "b916862c", "metadata": {"tags": ["learner_chopped", "draft", "py"]}, "outputs": [], "source": ["#>>>EXERCISE: L20.4.1\n", "\n", "def sumEstepInWindow(estep, xstep, d, w):\n", "    ewindow = np.zeros(xstep.shape[0])\n", "    #YOUR CODE HERE\n", "    return ewindow\n", "\n", "# Define the window width w and center distance d\n", "w = 3  # cm, change this value as needed\n", "d = 5  # cm, change this value as needed\n", "\n", "# Calculate total energy deposited in the window of width w cm centered at distance d cm for each initial energy\n", "total_deposited_150 = np.round(np.mean(sumEstepInWindow(estep150, xstep150, d, w)),1)\n", "total_deposited_200 = np.round(np.mean(sumEstepInWindow(estep200, xstep200, d, w)),1)\n", "total_deposited_250 = np.round(np.mean(sumEstepInWindow(estep250, xstep250, d, w)),1)\n", "total_deposited_300 = np.round(np.mean(sumEstepInWindow(estep300, xstep300, d, w)),1)\n", "\n", "print(f'Total energy deposited in a {w} cm window centered at {d} cm for 150 MeV: {total_deposited_150} MeV')\n", "print(f'Total energy deposited in a {w} cm window centered at {d} cm for 200 MeV: {total_deposited_200} MeV')\n", "print(f'Total energy deposited in a {w} cm window centered at {d} cm for 250 MeV: {total_deposited_250} MeV')\n", "print(f'Total energy deposited in a {w} cm window centered at {d} cm for 300 MeV: {total_deposited_300} MeV')"]}, {"cell_type": "markdown", "id": "5839b32e", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-20.4.2</span>\n", "\n", "Now, we will use the code from the preceding exercise to obtain the total energy deposited within a 3 cm window as a function of distance. A plot of energy deposited versus distance will yield the Bragg peak for a given initial energy! Create this plot for all 4 initial energies that we have been considering. For your answer to this exercise, find the location of the Bragg peak for the 250 MeV protons. Enter your answer as a number in centimeters with precision $\\pm 0.5$.\n", "\n", "<br>"]}, {"cell_type": "code", "execution_count": null, "id": "de8787d9", "metadata": {"tags": ["learner_chopped", "draft", "py"]}, "outputs": [], "source": ["#>>>EXERCISE: L20.4.2\n", "\n", "# Define the window width w\n", "w = 3  # cm, change this value as needed\n", "\n", "# Define the range of d values\n", "d_values = np.arange(0, 60, 0.5)  # cm, change this range as needed\n", "\n", "# Initialize arrays to store total energy deposited for each initial energy and each d value\n", "total_deposited_150 = []\n", "total_deposited_200 = []\n", "total_deposited_250 = []\n", "total_deposited_300 = []\n", "\n", "# Calculate total energy deposited in the window for each d value\n", "#YOUR CODE HERE\n", "\n", "# Plot the results\n", "#YOUR CODE HERE\n", "\n", "# Find the highest peak for each energy\n", "#YOUR CODE HERE\n", "    \n", "# Print peak information\n", "#YOUR CODE HERE"]}, {"cell_type": "markdown", "id": "f528079c", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-20.4.3</span>\n", "\n", "Now, create a plot of beam energy as a function of depth of maximum energy deposition. In other words, determine the Bragg peak for a given beam energy using the tools above, and then create a plot of beam energy vs. Bragg peak location. You can use the same 4 starting kinetic energies considered previously. You may find it helpful to use the `interp1d` function in the `scipy.interpolate` library.\n", "\n", "Approximately what beam energy is required to make its maximum energy deposit at a depth of 25 cm? Enter your answer as a number in MeV with precision $\\pm 10$.\n", "\n", "<br>"]}, {"cell_type": "code", "execution_count": null, "id": "86cf5180", "metadata": {"tags": ["learner_chopped", "draft", "py"]}, "outputs": [], "source": ["#>>>EXERCISE: L20.4.3\n", "\n", "# Define the range of initial energies\n", "initial_energies = [150, 200, 250, 300]\n", "peak_distances = []#YOUR CODE HERE\n", "\n", "\n", "# Plot the distance of the peak vs initial energy\n", "plt.plot(peak_distances, initial_energies, marker='o')\n", "plt.ylabel('Initial Energy (MeV)')\n", "plt.xlabel('Depth of Max Energy Deposit (cm)')\n", "plt.title('Initial Energy vs Depth of Max Energy Deposit')\n", "plt.grid(True)\n", "plt.show()\n", "\n", "\n", "# Interpolate the data to find the initial energy required for a desired penetration depth\n", "from scipy.interpolate import interp1d\n", "\n", "desired_depth = 25  # cm, change this value as needed\n", "\n", "#YOUR CODE HERE"]}, {"cell_type": "markdown", "id": "43e1bdf9", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='section_21_5'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L20.5 Bragg Scattering for Proton Therapy in Multiple Dimensions </h2>  \n", "\n", "| [Top](#section_21_0) | [Previous Section](#section_21_4) | [Exercises](#exercises_21_5) |"]}, {"cell_type": "markdown", "id": "813667ee", "metadata": {"tags": ["lect_05", "learner"]}, "source": ["*The material in this section is discussed in the video **<a href=\"https://courses.mitxonline.mit.edu/learn/course/course-v1:MITxT+8.S50.3x+3T2023/block-v1:MITxT+8.S50.3x+3T2023+type@sequential+block@seq_LS20/block-v1:MITxT+8.S50.3x+3T2023+type@vertical+block@vert_LS20_vid5\" target=\"_blank\">HERE</a>.** You are encouraged to watch that video and use this notebook concurrently.*"]}, {"cell_type": "markdown", "id": "c339d2a6", "metadata": {"tags": ["lect_05", "learner"]}, "source": ["<h3>Overview</h3>\n", "\n", "In addition to losing energy, the proton beam will also scatter in different directions as it moves through the body. The scattering occurs from the fact that the proton is charged, and the nuclei of the atoms in the material are charged, and so we have Coulomb scattering (aka Rutherford scattering)of the proton from the nuclei. This is an elastic process that will inevitably spread the beam out in the transverse direction. Because of the very large mass difference, the collisions of protons with electrons (which is responsible for the energy loss) does not cause appreciable scattering. In contrast, the nuclei are much heavier than the proton so those collisions cause scattering but not much energy loss. The scattering angle is often written as:\n", "\n", "$$\n", "\\sigma_{\\theta} = \\frac{13.6 \\rm MeV}{\\beta cp} z \\sqrt{\\frac{x}{X_{0}}}\\left(1+0.038\\log\\left(\\frac{xz^{2}}{X_{0}\\beta^{2}}\\right)\\right)\n", "$$\n", "\n", "where $z$ is the particle charge $X_{0}(z)$ is the electron density of the material, known as the radaition length, $\\beta$ is the velocity particles divided by the speed of light, $c$, $p$ is the momentum. Finally $x$ is the distance traversed. The more distance, the larger the scatter. Lastly, to get $X_{0}$ we will just use a formula. Suffice it to say its a function of the nuclear charge $Z$, I won't go into the details but you can read more about $X_{0}$ and the formula above <a href=\"https://pdg.lbl.gov/2022/reviews/rpp2022-rev-passage-particles-matter.pdf\" target=\"_blank\"> here</a>. \n", "\n", "We can simplify things since the actual properties of this scattering have been studied experimentally and the results can be fit with a parameterization containing the following two terms:\n", "\n", "$$\n", "\\Delta y = z_{1} \\Delta x \\frac{\\sigma_{\\theta}}{\\sqrt{12}} + \\frac{z_{2} \\Delta x\\sigma_{\\theta}}{2}\\\\\n", "\\Delta \\theta     = z_{2} \\sigma_{\\theta}\n", "$$\n", "\n", "where $\\Delta x$ is the distance traveled through the material, while $\\Delta y$ and $\\Delta \\theta$ are the y-scatter  of the beam in the transverse direction to its motion and the scatter of the angular deflection of the beam, respectively, The quantities $z_{1}$ and $z_{2}$ are two normal randomly sampled distributions with $\\sigma=1$ that are independent of one another.\n", "\n", "Lets go ahead and plot these. Note that the first block below is just the code from above, so that we can quickly load it here. "]}, {"cell_type": "code", "execution_count": null, "id": "0e5830b3", "metadata": {"tags": ["lect_05", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L20.5-runcell00\n", "\n", "#redefining relevant data and functions from above\n", "\n", "def A(iZ,iPlot=False):\n", "    #https://github.com/nrc-cnrc/EGSnrc/blob/master/HEN_HOUSE/pegs4/pegs4.mortran#L1354-L1391\n", "    lA=[1.00797,4.0026,6.939,9.0122,10.811,12.01115,14.0067,\n", "     15.9994,18.9984,20.183,22.9898,24.312,26.9815,28.088,30.9738,\n", "     32.064,35.453,39.948,39.102,40.08,44.956,47.90,50.942,51.998,\n", "     54.9380,55.847,58.9332,58.71,63.54,65.37,69.72,72.59,74.9216,\n", "     78.96,79.808,83.80,85.47,87.62,88.905,91.22,92.906,95.94,99.0,\n", "     101.07,102.905,106.4,107.87,112.4,114.82,118.69,121.75,127.60,\n", "     126.9044,131.30,132.905,137.34,138.91,\n", "     140.12,140.907,144.24,147.,150.35,151.98,157.25,158.924,162.50,\n", "     164.930,167.26,168.934,173.04,174.97,178.49,180.948,183.85,\n", "     186.2,190.2,192.2,195.08,196.987,200.59,204.37,207.19,208.980,\n", "     210.,210.,222.,223.,226.,227.,232.036,231.,238.03,237.,242.,\n", "     243.,247.,247.,248.,254.,253.\n", "    ]\n", "    lZ=np.arange(1,len(lA)+1)\n", "    if iPlot:\n", "        plt.plot(lZ,lA/lZ)\n", "        plt.xlabel('Z')\n", "        plt.ylabel('A/Z (Atomic mass/Z)')\n", "        plt.show()\n", "    return lA[iZ-1]\n", "\n", "def beta(ip,im): #gamma=1/sqrt(1-b^2)\n", "    g=gamma(ip,im)\n", "    return np.sqrt(1-1./g**2)\n", "\n", "def gamma(ip,im): #E^2=gamma^2m^2=p^2+m^2\n", "    return np.sqrt(1+(ip/im)**2)\n", "\n", "def I(iZ,iPlot=False):\n", "    #https://github.com/nrc-cnrc/EGSnrc/blob/master/HEN_HOUSE/pegs4/pegs4.mortran#L1354-L1391\n", "    lI=[19.2,41.8,40.,63.7,76.0,78.0,82.0,95.0,115.,137.,\n", "     149.,156.,166.,173.,173.,180.,174.,188.,190.,191.,216.,233.,245.,\n", "     257.,272.,286.,297.,311.,322.,330.,334.,350.,347.,348.,357.,352.,\n", "     363.,366.,379.,393.,417.,424.,428.,441.,449.,470.,470.,469.,488.,\n", "     488.,487.,485.,491.,482.,488.,491.,501.,523.,535.,546.,560.,574.,\n", "     580.,591.,614.,628.,650.,658.,674.,684.,694.,705.,718.,727.,736.,\n", "     746.,757.,790.,790.,800.,810.,823.,823.,830.,825.,794.,827.,826.,\n", "     841.,847.,878.,890.,902.,921.,934.,939.,952.,966.,980.,994.]\n", "    lZ=np.arange(1,len(lI)+1)\n", "    if iPlot:\n", "        plt.plot(lZ,lI/lZ)\n", "        plt.xlabel('Z')\n", "        plt.ylabel('I$_{adj}$/Z (eV/Z)')\n", "        plt.show()\n", "    return lI[iZ]*1e-6 #MeV not eV\n", "\n", "def eToP(iE,im):\n", "    return np.sqrt((iE+im)**2-im**2)\n", "\n", "def delta(ip,im):\n", "    C = 4.44\n", "    a = 0.1492\n", "    m = 3.25\n", "    X1 = 2.87\n", "    X0 = 0.2014\n", "    delta0 = 0.14\n", "    x = np.log10(ip/im)\n", "    #f1 = lambda x: delta0 * 10**(2*(x-X0)) # conductors pdg\n", "    f2 = 2 * x * np.log(10) - C + (a * np.maximum(0, (X1 - x))**m) #using np.maximum to prevent warning when x > X1\n", "    f3 = 2 * x * np.log(10) - C\n", "    delta_full = np.where(x < X0 , 0, f2)\n", "    delta_full = np.where(x < X1, delta_full, f3)\n", "    return delta_full\n", "\n", "m_e = 0.511 # Mass of electron in MeV\n", "\n", "def landauMPV(ip,im,iZ,irho=1,zpart=1):\n", "    K = 0.307075 # constant K in MeV cm mol^-1\n", "    const   = zpart**2 * (K * irho * iZ ) / (2 * A(iZ)) * (1./beta(ip,im)**2)\n", "    #logterm  = 2 * m_e * Tmax(ip,im) * ((ip/im)**2)/(I(iZ)**2)\n", "    logterm1 = 2 * m_e *               ((ip/im)**2)/(I(iZ))\n", "    logterm2 = const/I(iZ)\n", "    dEdxV    =  const * (np.log(logterm1) + np.log(logterm2) + 0.2     - (beta(ip,im))**2 - delta(ip,im))       #\n", "    return dEdxV,const\n", "\n", "def sumEstep(estep,xstep):\n", "    efront=np.zeros(xstep.shape[0])\n", "    eback =np.zeros(xstep.shape[0])\n", "    for i0 in range(xstep.shape[0]):\n", "        efront[i0] = np.sum(estep[i0,xstep[i0] < 3])/3.\n", "        #print(xstep[i0] < 3,xstep[i0] > xstep[i0,-1]-3,xstep[i0,-1]-3,xstep[i0],estep[i0])\n", "        eback[i0]  = np.sum(estep[i0,xstep[i0] > xstep[i0,-1]-3])/3.\n", "    return efront,eback"]}, {"cell_type": "markdown", "id": "63dbd481", "metadata": {"tags": ["learner", "lect_05"]}, "source": ["Now, we compute $X_{0}$ and $\\sigma_\\theta$ and finally the scatter. Lastly, we will plot some of these formula, to just see how they look. "]}, {"cell_type": "code", "execution_count": null, "id": "0fae259d", "metadata": {"tags": ["lect_05", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L20.5-runcell01\n", "\n", "def X0(iZ):\n", "    const=(716.408**-1)/A(iZ)\n", "    a = iZ/137.\n", "    Lrad =np.log(184.15*iZ**(-1./3.))\n", "    Lradp=np.log(1194*iZ**(-2./3.))\n", "    fZ = a**2*((1+a**2)**(-1)+0.20206-0.0369*a**2+0.0083*a**4-0.002*a**6)\n", "    val=const*(iZ**2*(Lrad-fZ)+iZ*Lradp)\n", "    return 1./val\n", "    \n", "def sigmaTheta(ip,im,iX0,idx=1.0,zpart=1):\n", "    C=13.6\n", "    X0=iX0\n", "    dx=idx/iX0\n", "    const=C/(beta(ip,im)*ip)*zpart*np.sqrt(dx)\n", "    logterm=1+0.038*np.log(dx*zpart**2/beta(ip,im)**2)\n", "    return const*logterm\n", "\n", "def thetaScatter(ip,im,iX0,idx,zpart=1):\n", "    z1=np.random.normal(0,1,ip.shape[0])\n", "    z2=np.random.normal(0,1,ip.shape[0])\n", "    stheta=sigmaTheta(ip,im,iX0,zpart)\n", "    dy    =z1*idx*stheta/np.sqrt(12.) + z2*idx*stheta/2 \n", "    dtheta=z2*stheta\n", "    return dtheta,dy\n", "\n", "lZ=np.arange(1,100,1)\n", "lX0=np.zeros(len(lZ))\n", "for pZ in lZ:\n", "    lX0[pZ-1] = X0(pZ)\n", "print(X0(82))\n", "plt.plot(lZ,lX0)\n", "plt.xlabel(\"Z\")\n", "plt.ylabel(\"$X_{0}$\")\n", "plt.ylim(0,100)\n", "plt.show()\n", "\n", "lP=np.arange(10,500,1)\n", "mproton=938  # Mass of proton in MeV\n", "lST = sigmaTheta(lP,mproton,X0(8))\n", "plt.plot(lP,lST)\n", "plt.yscale('log')\n", "plt.xlabel('P (MeV)')\n", "plt.ylabel('$\\sigma_{\\Theta}$')\n", "plt.show()"]}, {"cell_type": "markdown", "id": "479c2b6f", "metadata": {"tags": ["lect_05", "learner"]}, "source": ["What we see above is that we have very large scattering angles $\\sigma_{\\theta}$ when we get to low momenta. Basically, the proton can go anywhere and this can spread out our beam. If we are using this for cancer therapy, it can cause more extensive damage than we intend.\n", "\n", "One important thing to consider is that we need to make sure our angular scatter is physical, that means we should make sure that our angles are OK. Note that the following code takes quite a while to run.\n"]}, {"cell_type": "code", "execution_count": null, "id": "0f777120", "metadata": {"scrolled": false, "tags": ["lect_05", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L20.5-runcell02\n", "\n", "def simNYParallelSample(iN, ie=500,im=935,idt=1e-10,iZ=8):\n", "    xstep  = np.empty((0,iN))\n", "    ystep  = np.empty((0,iN))\n", "    estep  = np.empty((0,iN))\n", "    pstep  = np.empty((0,iN))\n", "    theta=0\n", "    y=0\n", "    c=3e10\n", "    dist=np.zeros(iN)\n", "    e=np.ones(iN)*ie\n", "    lX0 = X0(iZ)\n", "    print(\"Scanning:\",ie)\n", "    while np.any(e > 5):\n", "        p = eToP(e,im)\n", "        lMPV,lWMPV  = landauMPV(p,im,iZ=iZ,irho=1.06)\n", "        dE = np.zeros(lMPV.shape)\n", "        ##Here we have to parallelize by hand, this is not good\n", "        for i0, (pMPV,pWMPV) in enumerate(zip(lMPV,lWMPV)):\n", "            dE[i0]     = landau.sample(pMPV, pWMPV,1)\n", "        dx     = beta(p,im)*c*idt#speed of light\n", "        dTheta,dy = thetaScatter(p,im,lX0,idx=dx,zpart=1)\n", "        pdEdX  = np.minimum(dE*dx,e-0.1)\n", "        e      -= pdEdX\n", "        dist   += dx*np.cos(theta)\n", "        y      += dy + np.sin(theta)*dx\n", "        theta  += dTheta\n", "        xstep  = np.vstack((xstep,dist))\n", "        ystep  = np.vstack((ystep,y))\n", "        estep  = np.vstack((estep,pdEdX))\n", "        pstep  = np.vstack((pstep,e))        \n", "    xstep = xstep.T\n", "    estep = estep.T\n", "    pstep = pstep.T\n", "    ystep = ystep.T\n", "    return xstep,pstep,estep,ystep\n", "\n", "xstep150,pstep150,estep150,ystep150=simNYParallelSample(ie=150,im=mproton,iN=1000,idt=1e-10,iZ=8)\n", "xstep200,pstep200,estep200,ystep200=simNYParallelSample(ie=200,im=mproton,iN=1000,idt=1e-10,iZ=8)\n", "xstep250,pstep250,estep250,ystep250=simNYParallelSample(ie=250,im=mproton,iN=1000,idt=1e-10,iZ=8)\n", "xstep300,pstep300,estep300,ystep300=simNYParallelSample(ie=300,im=mproton,iN=1000,idt=1e-10,iZ=8)\n", "\n", "xrange=np.arange(0,60,2)\n", "plt.hist(xstep150[:,-1],bins=xrange,alpha=0.5,label='E=150 MeV')\n", "plt.hist(xstep200[:,-1],bins=xrange,alpha=0.5,label='E=200 MeV')\n", "plt.hist(xstep250[:,-1],bins=xrange,alpha=0.5,label='E=250 MeV')\n", "plt.hist(xstep300[:,-1],bins=xrange,alpha=0.5,label='E=300 MeV')\n", "plt.xlabel('x-Distance')\n", "plt.ylabel('N')\n", "plt.legend()\n", "plt.show()\n", "\n", "xrange=np.arange(-10,10,0.25)\n", "plt.hist(ystep150[:,-1],bins=xrange,alpha=0.5,label='E=150 MeV')\n", "plt.hist(ystep200[:,-1],bins=xrange,alpha=0.5,label='E=200 MeV')\n", "plt.hist(ystep250[:,-1],bins=xrange,alpha=0.5,label='E=250 MeV')\n", "plt.hist(ystep300[:,-1],bins=xrange,alpha=0.5,label='E=300 MeV')\n", "plt.xlabel('y-Distance')\n", "plt.ylabel('N')\n", "plt.legend()\n", "plt.show()\n", "\n", "ef150,eb150=sumEstep(estep150,xstep150)\n", "ef200,eb200=sumEstep(estep200,xstep200)\n", "ef250,eb250=sumEstep(estep250,xstep250)\n", "ef300,eb300=sumEstep(estep300,xstep300)\n", "\n", "xrange=np.arange(0,15,0.5)\n", "plt.hist(ef150,bins=xrange,alpha=0.5,label='E=150 MeV (dE/dx Front)')\n", "plt.hist(ef200,bins=xrange,alpha=0.5,label='E=200 MeV (dE/dx Front)')\n", "plt.hist(ef250,bins=xrange,alpha=0.5,label='E=250 MeV (dE/dx Front)')\n", "plt.hist(ef300,bins=xrange,alpha=0.5,label='E=300 MeV (dE/dx Front)')\n", "plt.xlabel('E-Deposit Front')\n", "plt.ylabel('N)')\n", "plt.legend()\n", "plt.show()\n", "\n", "xrange=np.arange(0,60,2)\n", "plt.hist(eb150,bins=xrange,alpha=0.5,label='E=150 MeV (dE/dx Back)')\n", "plt.hist(eb200,bins=xrange,alpha=0.5,label='E=200 MeV (dE/dx Back)')\n", "plt.hist(eb250,bins=xrange,alpha=0.5,label='E=250 MeV (dE/dx Back)')\n", "plt.hist(eb300,bins=xrange,alpha=0.5,label='E=300 MeV (dE/dx Back)')\n", "plt.xlabel('E-Deposit Back')\n", "plt.ylabel('N)')\n", "plt.legend()\n", "plt.show()\n"]}, {"cell_type": "markdown", "id": "5e690074", "metadata": {"tags": ["lect_05", "learner"]}, "source": ["<h3>Making a Spatial Map</h3>\n", "\n", "Now, this is where things become really interesting. The simulation we made above models a very specific process, to which we have added more and more elements of realism. However, these additions make the code more complicated and slower. That being said, we see in the end that the distributions we model are surprisingly smooth given that we have only been running hte code for a few minutes. Sometimes, it takes hours or days to generate events to make nice smooth interpretable distributions. \n", "\n", "However, in the interest of being fast, what we can do to speed things up is to build a parametric model for the behavior of what is going. This is often how we try to characterize simulations. In the next lecture, we will do this by using deep learning to auto generate these profiles. What we will is something that is reasonably accurate, but almost 1000 times faster. "]}, {"cell_type": "code", "execution_count": null, "id": "947e92b5", "metadata": {"tags": ["lect_05", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L20.5-runcell03\n", "\n", "def plotImage(iId,ixstep,iestep,iystep):\n", "    #plt.plot(ixstep[iId],iystep[iId])#,iestep[iId])\n", "    #plt.show()\n", "    #Now let's make a regular image \n", "    xbin = np.arange(-1,55, 2)\n", "    ybin = np.arange(-3.75, 3.75, 0.25)\n", "    #xbin = np.arange(-0.5,60.5, 1)\n", "    #ybin = np.arange(-5.125, 5.125, 0.25)\n", "    print(\"A:\",len(ixstep.flatten()),len(iystep.flatten()),len(iestep.flatten()))\n", "    H, xedges, yedges = np.histogram2d(ixstep.flatten(), iystep.flatten(), bins=(xbin, ybin),weights=iestep.flatten())  \n", "    plt.imshow(H.T,extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]])  \n", "    plt.show()\n", "    #X, Y = np.meshgrid(xedges, yedges)\n", "    #plt.pcolormesh(X,Y,H.T)  \n", "    #plt.show()\n", "\n", "plotImage(-1,xstep150,estep150,ystep150)\n", "plotImage(-1,xstep200,estep200,ystep200)\n", "plotImage(-1,xstep250,estep250,ystep250)\n", "plotImage(-1,xstep300,estep300,ystep300)"]}, {"cell_type": "markdown", "id": "3c0de76f", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='exercises_21_5'></a>     \n", "\n", "| [Top](#section_21_0) | [Restart Section](#section_21_5) | [Next Section](#section_21_6) |\n"]}, {"cell_type": "markdown", "id": "0b3326f6", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-20.5.1</span>\n", "\n", "Construct the same plot as in the exercise `Ex-20.4.3`, but now using this more realistic scattering model. Specifically, create a plot of beam energy vs Bragg peak location. Again, determine the approximate beam energy that is required to make a maximum energy deposit at a depth of 25 cm.\n", "\n", "How are the results of the more realistic model presented in this section different from those of the simplified model? Select ALL that apply:\n", "\n", "A) The Bragg peaks are shifted farther out in distance.\\\n", "B) The Bragg peaks are shifted closer in distance.\\\n", "C) The Bragg peak positions are approximately unchanged.\\\n", "D) The Bragg peaks are wider.\\\n", "E) The Bragg peaks are narrower.\\\n", "F) The width of the Bragg peaks are approximately unchanged.\n", "\n", "\n", "<br>"]}], "metadata": {"celltoolbar": "Tags", "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}