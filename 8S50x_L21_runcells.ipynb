{"cells": [{"cell_type": "markdown", "id": "b4997a0a", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<hr style=\"height: 1px;\">\n", "<i>This notebook was authored by the 8.S50x Course Team, Copyright 2022 MIT All Rights Reserved.</i>\n", "<hr style=\"height: 1px;\">\n", "<br>\n", "\n", "<h1>Lesson 21: Monte Carlo II - Advances with AI</h1>"]}, {"cell_type": "markdown", "id": "100dd6f6", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='section_22_0'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L21.0 Overview</h2>\n"]}, {"cell_type": "markdown", "id": "d8d25e2e", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<h3>Navigation</h3>\n", "\n", "<table style=\"width:100%\">\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_22_1\">L21.1 Variational Autoencoders for Monte Carlo based Event Generation</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_22_1\">L21.1 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_22_2\">L21.2 Generating Bragg Scattering with Variational Autoencoders</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_22_2\">L21.2 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_22_3\">L21.3 Generating Full Bragg Scattering Details</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_22_3\">L21.3 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_22_4\">L21.4 Conditional VAEs Allowing for Energy Based Generation</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_22_4\">L21.4 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_22_5\">L21.5 Bootstrapping</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_22_5\">L21.5 Exercises</a></td>\n", "    </tr>\n", "     <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_22_6\">L21.6 Bootstrapping For Neural Networks</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\">No Exercises</td>\n", "    </tr>\n", "</table>"]}, {"cell_type": "code", "execution_count": null, "id": "c4046d2f", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.0-runcell00\n", "\n", "!git init\n", "!git remote add -f origin https://github.com/mitx-8s50/nb_LEARNER/\n", "!git config core.sparseCheckout true\n", "!echo 'data/L22' >> .git/info/sparse-checkout\n", "!git pull origin main"]}, {"cell_type": "code", "execution_count": null, "id": "7f843412", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.0-runcell01\n", "\n", "!pip install corner\n", "!pip install torchvision\n", "!pip install pylandau #from here: https://pypi.org/project/pylandau/\n", "!pip install git+https://github.com/SengerM/landaupy\n", "\n", "#from here: https://github.com/SengerM/landaupy\n", "#https://github.com/SengerM/landaupy/blob/main/LICENSE"]}, {"cell_type": "code", "execution_count": null, "id": "92e910f7", "metadata": {"tags": ["py", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.0-runcell02\n", "\n", "import imageio\n", "from PIL import Image\n", "\n", "import numpy as np\n", "import torch\n", "import torch.nn as nn\n", "import matplotlib.pyplot as plt\n", "import csv\n", "import math\n", "from scipy import optimize as opt \n", "\n", "import pandas as pd \n", "import torchvision\n", "from torchvision import transforms\n", "from torch.utils.data import DataLoader,random_split\n", "import torch.nn.functional as F\n", "import torch.optim as optim\n", "import corner\n", "\n", "from landaupy import landau"]}, {"cell_type": "code", "execution_count": null, "id": "6e40a219", "metadata": {"tags": ["py", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.0-runcell03\n", "\n", "#set plot resolution\n", "%config InlineBackend.figure_format = 'retina'\n", "\n", "#set default figure parameters\n", "plt.rcParams['figure.figsize'] = (9,6)\n", "\n", "medium_size = 12\n", "large_size = 15\n", "\n", "plt.rc('font', size=medium_size)          # default text sizes\n", "plt.rc('xtick', labelsize=medium_size)    # xtick labels\n", "plt.rc('ytick', labelsize=medium_size)    # ytick labels\n", "plt.rc('legend', fontsize=medium_size)    # legend\n", "plt.rc('axes', titlesize=large_size)      # axes title\n", "plt.rc('axes', labelsize=large_size)      # x and y labels\n", "plt.rc('figure', titlesize=large_size)    # figure title"]}, {"cell_type": "markdown", "id": "75155c5f", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='section_22_1'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L21.1 Variational Autoencoders for Monte Carlo based Event Generation</h2>  \n", "\n", "\n", "| [Top](#section_22_0) | [Previous Section](#section_22_0) | [Exercises](#exercises_22_1) | [Next Section](#section_22_2) |\n"]}, {"cell_type": "code", "execution_count": null, "id": "b8228e0d", "metadata": {"tags": ["lect_01", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.1-runcell01\n", "\n", "# Set random seed for reproducibility\n", "torch.manual_seed(0)\n", "\n", "data_dir = 'data/L22/dataset'\n", "\n", "train_dataset = torchvision.datasets.MNIST(data_dir, train=True, download=True)\n", "test_dataset  = torchvision.datasets.MNIST(data_dir, train=False, download=True)\n", "\n", "train_transform = transforms.Compose([transforms.ToTensor(),])\n", "\n", "test_transform = transforms.Compose([transforms.ToTensor(),])\n", "\n", "train_dataset.transform = train_transform\n", "test_dataset.transform = test_transform\n", "\n", "m=len(train_dataset)\n", "\n", "train_data, val_data = random_split(train_dataset, [int(m-m*0.2), int(m*0.2)])\n", "batch_size=256\n", "\n", "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n", "valid_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)\n", "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,shuffle=True)\n", "\n", "#train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n", "#valid_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n", "#test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"]}, {"cell_type": "code", "execution_count": null, "id": "02692699", "metadata": {"tags": ["lect_01", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.1-runcell02\n", "\n", "class VariationalEncoder(nn.Module):\n", "    def __init__(self, latent_dims):  \n", "        super(VariationalEncoder, self).__init__()\n", "        self.conv1 = nn.Conv2d(1, 8, 3, stride=2, padding=1)\n", "        self.conv2 = nn.Conv2d(8, 16, 3, stride=2, padding=1)\n", "        self.batch2 = nn.BatchNorm2d(16)\n", "        self.conv3 = nn.Conv2d(16, 32, 3, stride=2, padding=0)  \n", "        self.linear1 = nn.Linear(3*3*32, 128)\n", "        self.linear2 = nn.Linear(128, latent_dims)\n", "        self.linear3 = nn.Linear(128, latent_dims)\n", "\n", "        #Now we need sample in phase space \n", "        self.N       = torch.distributions.Normal(0, 1)\n", "        self.N.loc   = self.N.loc \n", "        self.N.scale = self.N.scale\n", "        self.kl = 0\n", "\n", "    def forward(self, x):\n", "        #print(x.shape)\n", "        x = F.relu(self.conv1(x))\n", "        x = F.relu(self.batch2(self.conv2(x)))\n", "        x = F.relu(self.conv3(x))\n", "        x = torch.flatten(x, start_dim=1)\n", "        x = F.relu(self.linear1(x))\n", "        mu =  self.linear2(x) #Mean in the gaussian space\n", "        sigma = torch.exp(self.linear3(x)) #sigma in the space\n", "        z = mu + sigma*self.N.sample(mu.shape) #smear \n", "        self.kl = (sigma**2 + mu**2 - torch.log(sigma) - 1/2).sum() #Now compute the KL divergence\n", "        return z      "]}, {"cell_type": "code", "execution_count": null, "id": "b2374b20", "metadata": {"tags": ["lect_01", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.1-runcell03\n", "\n", "class Decoder(nn.Module):\n", "    \n", "    def __init__(self, latent_dims):\n", "        super().__init__()\n", "\n", "        self.decoder_lin = nn.Sequential(\n", "            nn.Linear(latent_dims, 128),\n", "            nn.ReLU(True),\n", "            nn.Linear(128, 3 * 3 * 32),\n", "            nn.ReLU(True)\n", "        )\n", "\n", "        self.unflatten = nn.Unflatten(dim=1, unflattened_size=(32, 3, 3))\n", "\n", "        self.decoder_conv = nn.Sequential(\n", "            nn.ConvTranspose2d(32, 16, 3, stride=2, output_padding=0),\n", "            nn.BatchNorm2d(16),\n", "            nn.ReLU(True),\n", "            nn.ConvTranspose2d(16, 8, 3, stride=2, padding=1, output_padding=1),\n", "            nn.BatchNorm2d(8),\n", "            nn.ReLU(True),\n", "            nn.ConvTranspose2d(8, 1, 3, stride=2, padding=1, output_padding=1)\n", "        )\n", "        \n", "    def forward(self, x):\n", "        x = self.decoder_lin(x)\n", "        x = self.unflatten(x)\n", "        x = self.decoder_conv(x)\n", "        x = torch.sigmoid(x)\n", "        return x"]}, {"cell_type": "code", "execution_count": null, "id": "f0845a7e", "metadata": {"tags": ["lect_01", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.1-runcell04\n", "\n", "class VariationalAutoencoder(nn.Module):\n", "    def __init__(self, latent_dims):\n", "        super(VariationalAutoencoder, self).__init__()\n", "        self.encoder = VariationalEncoder(latent_dims)\n", "        self.decoder = Decoder(latent_dims)\n", "        self.kl      = 0\n", "        \n", "    def forward(self, x):\n", "        z = self.encoder(x)\n", "        kl = self.encoder.kl\n", "        return self.decoder(z)"]}, {"cell_type": "code", "execution_count": null, "id": "9587c9f9", "metadata": {"tags": ["lect_01", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.1-runcell05\n", "\n", "### Set the random seed for reproducible results\n", "### If restarting the training, must run this part again\n", "torch.manual_seed(0)\n", "d = 2\n", "vae = VariationalAutoencoder(latent_dims=d)\n", "lr = 1e-3 \n", "optim = torch.optim.Adam(vae.parameters(), lr=lr, weight_decay=1e-5)\n", "\n", "### Training function\n", "def train_epoch(vae, dataloader, optimizer):\n", "    # Set train mode for both the encoder and the decoder\n", "    vae.train()\n", "    train_loss = 0.0\n", "    # Iterate the dataloader (we do not need the label values, this is unsupervised learning)\n", "    for x, _ in dataloader: \n", "        # Move tensor to the proper device\n", "        x_hat = vae(x)\n", "        # Evaluate loss\n", "        loss = ((x - x_hat)**2).sum() + vae.kl\n", "        # Backward pass\n", "        optimizer.zero_grad()\n", "        loss.backward()\n", "        optimizer.step()\n", "        # Print batch loss\n", "        #print('\\t partial train loss (single batch): %f' % (loss.item()))\n", "        train_loss+=loss.item()\n", "\n", "    return train_loss / len(dataloader.dataset)\n", "\n", "### Testing function\n", "def test_epoch(vae, dataloader):\n", "    # Set evaluation mode for encoder and decoder\n", "    vae.eval()\n", "    val_loss = 0.0\n", "    with torch.no_grad(): # No need to track the gradients\n", "        for x, _ in dataloader:\n", "            # Encode data\n", "            encoded_data = vae.encoder(x)\n", "            # Decode data\n", "            x_hat = vae(x)\n", "            loss = ((x - x_hat)**2).sum() + vae.kl\n", "            val_loss += loss.item()\n", "\n", "    return val_loss / len(dataloader.dataset)\n", "\n", "def plot_ae_outputs(encoder,decoder,n=10):\n", "    plt.figure(figsize=(16,4.5))\n", "    targets = test_dataset.targets.numpy()\n", "    t_idx = {i:np.where(targets==i)[0][0] for i in range(n)}\n", "    for i in range(n):\n", "      ax = plt.subplot(2,n,i+1)\n", "      img = test_dataset[t_idx[i]][0].unsqueeze(0)\n", "      encoder.eval()\n", "      decoder.eval()\n", "      with torch.no_grad():\n", "         rec_img  = decoder(encoder(img))\n", "      plt.imshow(img.cpu().squeeze().numpy(), cmap='gist_gray')\n", "      ax.get_xaxis().set_visible(False)\n", "      ax.get_yaxis().set_visible(False)  \n", "      if i == n//2:\n", "        ax.set_title('Original images')\n", "      ax = plt.subplot(2, n, i + 1 + n)\n", "      plt.imshow(rec_img.cpu().squeeze().numpy(), cmap='gist_gray')  \n", "      ax.get_xaxis().set_visible(False)\n", "      ax.get_yaxis().set_visible(False)  \n", "      if i == n//2:\n", "         ax.set_title('Reconstructed images')\n", "    plt.show()  "]}, {"cell_type": "code", "execution_count": null, "id": "0b5de372", "metadata": {"tags": ["lect_01", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.1-runcell06\n", "\n", "### NOTE: If restarting the training, must run lines below\n", "\"\"\"\n", "torch.manual_seed(0)\n", "d = 2\n", "vae = VariationalAutoencoder(latent_dims=d)\n", "lr = 1e-3 \n", "optim = torch.optim.Adam(vae.parameters(), lr=lr, weight_decay=1e-5)\n", "\"\"\"\n", "\n", "num_epochs = 10\n", "\n", "for epoch in range(num_epochs):\n", "    train_loss = train_epoch(vae,train_loader,optim)\n", "    val_loss = test_epoch(vae,valid_loader)\n", "    print('\\n EPOCH {}/{} \\t train loss {:.3f} \\t val loss {:.3f}'.format(epoch + 1, num_epochs,train_loss,val_loss))\n", "    plot_ae_outputs(vae.encoder,vae.decoder,n=10)"]}, {"cell_type": "code", "execution_count": null, "id": "5fcd63b7", "metadata": {"tags": ["lect_01", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.1-runcell07\n", "\n", "def plot_reconstructed(autoencoder, r0=(-2, 2), r1=(-2, 2), n=12):\n", "    w = 28\n", "    img = np.zeros((n*w, n*w))\n", "    for i, y in enumerate(np.linspace(*r1, n)):\n", "        for j, x in enumerate(np.linspace(*r0, n)):\n", "            z = torch.Tensor([[x, y]])\n", "            x_hat = autoencoder.decoder(z)\n", "            x_hat = x_hat.reshape(28, 28).to('cpu').detach().numpy()\n", "            img[(n-1-i)*w:(n-1-i+1)*w, j*w:(j+1)*w] = x_hat\n", "    plt.imshow(img, extent=[*r0, *r1])\n", "    \n", "plot_reconstructed(vae)"]}, {"cell_type": "markdown", "id": "35afb9d8", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='exercises_22_1'></a>     \n", "\n", "| [Top](#section_22_0) | [Restart Section](#section_22_1) | [Next Section](#section_22_2) |\n"]}, {"cell_type": "markdown", "id": "6ad682d8", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 21.1.1</span>\n", "\n", "What is the primary function of the latent space in a Variational Autoencoder (VAE)?\n", "\n", "A) To provide a discrete set of vectors that uniquely represent all possible input data.\\\n", "B) To serve as a lower-dimensional, continuous representation of the input data, capturing its essential features.\\\n", "C) To act as a set of orthogonal vectors used to span the vector space of the input data.\\\n", "D) To directly output the reconstructed data from the input.\n", "\n", "<br>"]}, {"cell_type": "markdown", "id": "f549b9df", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 21.1.2</span>\n", "\n", "When comparing the inputs with the outputs found by sampling the results of the training, we see that it still has difficulty reproducing some numbers (in particular the 3 and 8, although admittedly that's a very odd looking 5). What can we do to make it better? Select ALL that apply, then try all of these for yourself!\n", "\n", "A) Decrease the latent space dimension\\\n", "B) Increase the latent space dimension\\\n", "C) Decrease the number of training epochs\\\n", "D) Increase the number of training epochs\\\n", "E) Decrease the standard deviation\\\n", "F) Increase the standard deviation\n", "\n", "\n", "<br>"]}, {"cell_type": "markdown", "id": "1568a6cb", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 21.1.3</span>\n", "\n", "Adjust the code in `L21.1-runcell05` to use a 3-dimensional latent space. How does this change the training and validation losses compared to using 2 dimensions? Report both numbers as a list `[train_loss, val_loss]` with single-digit precision.\n", "\n", "\n", "<br>"]}, {"cell_type": "markdown", "id": "1f3bdac7", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 21.1.4</span>\n", "\n", "\n", "Why are variational autoencoders better or more flexible than regular autoencoders? Select ALL that apply:\n", "\n", "A) VAEs model the latent space as a probability distribution, which allows VAEs to generate new data points by sampling from the learned latent space.\n", "\n", "B) VAEs force the latent space to be continuous and smooth, which facilitates meaningful interpolations between data points in the latent space.\n", "\n", "C) VAEs allow for more flexibility in designing the latent space, such as controlling the dimensionality and imposing specific distributional assumptions (e.g., Gaussian distribution).\n", "\n", "\n", "<br>"]}, {"cell_type": "markdown", "id": "949f706a", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='section_22_2'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L21.2 Generating Bragg Scattering with Variational Autoencoders </h2>  \n", "\n", "| [Top](#section_22_0) | [Previous Section](#section_22_1) | [Exercises](#exercises_22_2) | [Next Section](#section_22_3) |"]}, {"cell_type": "code", "execution_count": null, "id": "ff9f8954", "metadata": {"tags": ["lect_02", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.2-runcell01\n", "\n", "import pylandau\n", "from landaupy import landau\n", "\n", "#values\n", "def I(iZ,iPlot=False):\n", "    #https://github.com/nrc-cnrc/EGSnrc/blob/master/HEN_HOUSE/pegs4/pegs4.mortran#L1354-L1391\n", "    lI=[19.2,41.8,40.,63.7,76.0,78.0,82.0,95.0,115.,137.,\n", "     149.,156.,166.,173.,173.,180.,174.,188.,190.,191.,216.,233.,245.,\n", "     257.,272.,286.,297.,311.,322.,330.,334.,350.,347.,348.,357.,352.,\n", "     363.,366.,379.,393.,417.,424.,428.,441.,449.,470.,470.,469.,488.,\n", "     488.,487.,485.,491.,482.,488.,491.,501.,523.,535.,546.,560.,574.,\n", "     580.,591.,614.,628.,650.,658.,674.,684.,694.,705.,718.,727.,736.,\n", "     746.,757.,790.,790.,800.,810.,823.,823.,830.,825.,794.,827.,826.,\n", "     841.,847.,878.,890.,902.,921.,934.,939.,952.,966.,980.,994.]\n", "    lZ=np.arange(1,len(lI)+1)\n", "    if iPlot:\n", "        plt.plot(lZ,lI/lZ)\n", "        plt.xlabel('Z')\n", "        plt.ylabel('I$_{adj}$/Z (eV/Z)')\n", "        plt.show()\n", "    return lI[iZ]*1e-6 #MeV not eV\n", "\n", "def A(iZ,iPlot=False):\n", "    #https://github.com/nrc-cnrc/EGSnrc/blob/master/HEN_HOUSE/pegs4/pegs4.mortran#L1354-L1391\n", "    lA=[1.00797,4.0026,6.939,9.0122,10.811,12.01115,14.0067,\n", "     15.9994,18.9984,20.183,22.9898,24.312,26.9815,28.088,30.9738,\n", "     32.064,35.453,39.948,39.102,40.08,44.956,47.90,50.942,51.998,\n", "     54.9380,55.847,58.9332,58.71,63.54,65.37,69.72,72.59,74.9216,\n", "     78.96,79.808,83.80,85.47,87.62,88.905,91.22,92.906,95.94,99.0,\n", "     101.07,102.905,106.4,107.87,112.4,114.82,118.69,121.75,127.60,\n", "     126.9044,131.30,132.905,137.34,138.91,\n", "     140.12,140.907,144.24,147.,150.35,151.98,157.25,158.924,162.50,\n", "     164.930,167.26,168.934,173.04,174.97,178.49,180.948,183.85,\n", "     186.2,190.2,192.2,195.08,196.987,200.59,204.37,207.19,208.980,\n", "     210.,210.,222.,223.,226.,227.,232.036,231.,238.03,237.,242.,\n", "     243.,247.,247.,248.,254.,253.   \n", "    ]\n", "    lZ=np.arange(1,len(lA)+1)\n", "    if iPlot:\n", "        plt.plot(lZ,lA/lZ)\n", "        plt.xlabel('Z')\n", "        plt.ylabel('A/Z (Atomic mass/Z)')\n", "        plt.show()\n", "    return lA[iZ-1]\n", "\n", "\n", "m_e = 0.511 # Mass of electron in MeV\n", "\n", "def gamma(ip,im): #E^2=gamma^2m^2=p^2+m^2\n", "    return np.sqrt(1+(ip/im)**2)\n", "\n", "def beta(ip,im): #gamma=1/sqrt(1-b^2)\n", "    g=gamma(ip,im)\n", "    return np.sqrt(1-1./g**2)\n", "\n", "def betagamma(ip,im):#p=bgm\n", "    return ip/im\n", "\n", "def Tmax(ip,im): # Maximum energy transfer in one collision in MeV\n", "    return 2*m_e*(ip/im)**2/(1+2*gamma(ip,im)*m_e/im+(m_e/im)**2)\n", "\n", "def TKinheavy(ip,im): #(T+M)^2=sqrt(p)+sqrt(m)\n", "    return np.sqrt(np.sqrt(ip)+np.sqrt(um))-im\n", "\n", "def delta(ip,im):\n", "    C = 4.44\n", "    a = 0.1492\n", "    m = 3.25\n", "    X1 = 2.87\n", "    X0 = 0.2014\n", "    delta0 = 0.14\n", "    x = np.log10(ip/im)\n", "    #f1 = lambda x: delta0 * 10**(2*(x-X0)) # conductors pdg\n", "    f2 = 2 * x * np.log(10) - C + (a * np.maximum(0, (X1 - x))**m) #using np.maximum to prevent warning when x > X1\n", "    f3 = 2 * x * np.log(10) - C\n", "    delta_full = np.where(x < X0 , 0, f2)\n", "    delta_full = np.where(x < X1, delta_full, f3)\n", "    return delta_full\n", "        \n", "def dEdxF(ip,im,iZ,zpart=1,rho=1.0,nodelta=False): #Bethe-Bloch equation\n", "    K = 0.307075 # constant K in MeV cm mol^-1\n", "    #rho = 2.336 # Density of material in g cm^-3 (here: silicon density)\n", "    const   = zpart**2 * (K * rho * iZ ) / (2 * A(iZ)) * (1./beta(ip,im)**2)\n", "    logterm = 2 * m_e * Tmax(ip,im) * ((ip/im)**2)/(I(iZ)**2) \n", "    dEdxV   =  const * (np.log(logterm)  - 2*(beta(ip,im))**2 - delta(ip,im))              \n", "    if nodelta:\n", "        print(\"delta:\",delta(ip,im),dEdxV)\n", "        dEdxV    =  const * (np.log(logterm) - 2*(beta(ip,im))**2)\n", "    return dEdxV\n", "    \n", "mproton=938\n", "mpion=135.4\n", "mmuon=105.4\n", "\n", "def X0(iZ):\n", "    const=(716.408**-1)/A(iZ)\n", "    a = iZ/137.\n", "    Lrad =np.log(184.15*iZ**(-1./3.))\n", "    Lradp=np.log(1194*iZ**(-2./3.))\n", "    fZ = a**2*((1+a**2)**(-1)+0.20206-0.0369*a**2+0.0083*a**4-0.002*a**6)\n", "    val=const*(iZ**2*(Lrad-fZ)+iZ*Lradp)\n", "    return 1./val\n", "\n", "def sigmaTheta(ip,im,iX0,idx=1.0,zpart=1):\n", "    C=13.6\n", "    X0=iX0\n", "    dx=idx/iX0\n", "    const=C/(beta(ip,im)*ip)*zpart*np.sqrt(dx)\n", "    logterm=1+0.038*np.log(dx*zpart**2/beta(ip,im)**2)\n", "    return const*logterm\n", "\n", "def thetaScatter(ip,im,iX0,idx,zpart=1):\n", "    z1=np.random.normal(0,1,ip.shape[0])\n", "    z2=np.random.normal(0,1,ip.shape[0])\n", "    stheta=sigmaTheta(ip,im,iX0,zpart)\n", "    dy    =z1*idx*stheta/np.sqrt(12.) + z2*idx*stheta/2 \n", "    dtheta=z2*stheta\n", "    return dtheta,dy\n", "    \n", "def eToP(iE,im):\n", "    return np.sqrt((iE+im)**2-im**2)\n", "\n", "def landauMPV(ip,im,iZ,irho=1,zpart=1):\n", "    K = 0.307075 # constant K in MeV cm mol^-1\n", "    const   = zpart**2 * (K * irho * iZ ) / (2 * A(iZ)) * (1./beta(ip,im)**2)\n", "    #logterm  = 2 * m_e * Tmax(ip,im) * ((ip/im)**2)/(I(iZ)**2) \n", "    logterm1 = 2 * m_e *               ((ip/im)**2)/(I(iZ)) \n", "    logterm2 = const/I(iZ)\n", "    dEdxV    =  const * (np.log(logterm1) + np.log(logterm2) + 0.2     - (beta(ip,im))**2 - delta(ip,im))       # \n", "    return dEdxV,const\n", "\n", "\n", "def simNYParallelSample(iN, ie=500,im=935,idt=1e-10,iZ=8):\n", "    xstep  = np.empty((0,iN))\n", "    ystep  = np.empty((0,iN))\n", "    estep  = np.empty((0,iN))\n", "    pstep  = np.empty((0,iN))\n", "    theta=0\n", "    y=0\n", "    c=3e10\n", "    dist=np.zeros(iN)\n", "    e=np.ones(iN)*ie\n", "    lX0 = X0(iZ)\n", "    print(\"Scanning:\",ie)\n", "    while np.any(e > 5):\n", "        p = eToP(e,im)\n", "        lMPV,lWMPV  = landauMPV(p,im,iZ=iZ,irho=1.06)\n", "        dE = np.zeros(lMPV.shape)\n", "        ##Here we have to parallelize by hand, this is not good\n", "        for i0, (pMPV,pWMPV) in enumerate(zip(lMPV,lWMPV)):\n", "            dE[i0]     = landau.sample(pMPV, pWMPV,1)\n", "        dx     = beta(p,im)*c*idt#speed of light\n", "        dTheta,dy = thetaScatter(p,im,lX0,idx=dx,zpart=1)\n", "        pdEdX  = np.minimum(dE*dx,e-0.1)\n", "        e      -= pdEdX\n", "        dist   += dx*np.cos(theta)\n", "        y      += dy + np.sin(theta)*dx\n", "        theta  += dTheta\n", "        xstep  = np.vstack((xstep,dist))\n", "        ystep  = np.vstack((ystep,y))\n", "        estep  = np.vstack((estep,pdEdX))\n", "        pstep  = np.vstack((pstep,e))        \n", "    xstep = xstep.T\n", "    estep = estep.T\n", "    pstep = pstep.T\n", "    ystep = ystep.T\n", "    return xstep,pstep,estep,ystep\n", "\n", "#uncomment and run the simulation to generate the data, if desired\n", "\"\"\"\n", "xstep150,pstep150,estep150,ystep150=simNYParallelSample(ie=150,im=mproton,iN=1000,idt=1e-10,iZ=8)\n", "xstep200,pstep200,estep200,ystep200=simNYParallelSample(ie=200,im=mproton,iN=1000,idt=1e-10,iZ=8)\n", "xstep250,pstep250,estep250,ystep250=simNYParallelSample(ie=250,im=mproton,iN=1000,idt=1e-10,iZ=8)\n", "xstep300,pstep300,estep300,ystep300=simNYParallelSample(ie=300,im=mproton,iN=1000,idt=1e-10,iZ=8)\n", "\"\"\""]}, {"cell_type": "code", "execution_count": null, "id": "cb815828", "metadata": {"tags": ["lect_02", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.2-runcell02\n", "\n", "#load the data from the repository (equivalent to running the simulation above)\n", "\n", "#energy 150\n", "xstep150 = np.load('data/L22/xstep150.npy')\n", "pstep150 = np.load('data/L22/pstep150.npy')\n", "estep150 = np.load('data/L22/estep150.npy')\n", "ystep150 = np.load('data/L22/ystep150.npy')\n", "\n", "#energy 200\n", "xstep200 = np.load('data/L22/xstep200.npy')\n", "pstep200 = np.load('data/L22/pstep200.npy')\n", "estep200 = np.load('data/L22/estep200.npy')\n", "ystep200 = np.load('data/L22/ystep200.npy')\n", "\n", "#energy 250\n", "xstep250 = np.load('data/L22/xstep250.npy')\n", "pstep250 = np.load('data/L22/pstep250.npy')\n", "estep250 = np.load('data/L22/estep250.npy')\n", "ystep250 = np.load('data/L22/ystep250.npy')\n", "\n", "#energy 300\n", "xstep300 = np.load('data/L22/xstep300.npy')\n", "pstep300 = np.load('data/L22/pstep300.npy')\n", "estep300 = np.load('data/L22/estep300.npy')\n", "ystep300 = np.load('data/L22/ystep300.npy')"]}, {"cell_type": "code", "execution_count": null, "id": "57498cc3", "metadata": {"tags": ["lect_02", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.2-runcell03\n", "\n", "import torch\n", "import torch.nn as nn\n", "from torch.utils.data import Dataset\n", "from torch.autograd import Variable\n", "\n", "def sumEstep(estep,xstep):\n", "    efront=np.zeros(xstep.shape[0])\n", "    eback =np.zeros(xstep.shape[0])\n", "    for i0 in range(xstep.shape[0]):\n", "        efront[i0] = np.sum(estep[i0,xstep[i0] < 3])/3.\n", "        #print(xstep[i0] < 3,xstep[i0] > xstep[i0,-1]-3,xstep[i0,-1]-3,xstep[i0],estep[i0])\n", "        eback[i0]  = np.sum(estep[i0,xstep[i0] > xstep[i0,-1]-3])/3.\n", "    return efront,eback\n", "\n", "def createData(ixstep,ipstep,iestep,iystep):\n", "    length=ixstep[:,-1]\n", "    width =iystep[:,-1]\n", "    efront=np.zeros(ixstep.shape[0])\n", "    eback =np.zeros(ixstep.shape[0])\n", "    for i0 in range(ixstep.shape[0]):\n", "        efront[i0] = np.sum(iestep[i0,ixstep[i0] < 3])/3.\n", "        eback[i0]  = np.sum(iestep[i0,ixstep[i0] > ixstep[i0,-1]-1])\n", "    processed_data = np.vstack((length,width,efront,eback))\n", "    trainset       = torch.tensor(processed_data).float()\n", "    return trainset\n", "\n", "indataset150=createData(xstep150,pstep150,estep150,ystep150)\n", "indataset150=indataset150.T\n", "\n", "indataset200=createData(xstep200,pstep200,estep200,ystep200)\n", "indataset200=indataset200.T\n", "\n", "indataset250=createData(xstep250,pstep250,estep250,ystep250)\n", "indataset250=indataset250.T\n", "\n", "indataset300=createData(xstep300,pstep300,estep300,ystep300)\n", "indataset300=indataset300.T\n", "\n", "indataset   = np.vstack((indataset150,indataset200,indataset250,indataset300))\n", "print(indataset.shape)"]}, {"cell_type": "code", "execution_count": null, "id": "73f90ee8", "metadata": {"tags": ["lect_02", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.2-runcell04\n", "\n", "class DataSet(Dataset):\n", "    def __init__(self, samples, labels):\n", "        self.labels  = labels\n", "        self.samples = samples\n", "        if len(samples) != len(labels):\n", "            raise ValueError(\n", "                f\"should have the same number of samples({len(samples)}) as there are labels({len(labels)})\")\n", "\n", "    def __len__(self):\n", "        return len(self.labels)\n", "\n", "    def nfeatures(self):\n", "        return self.samples.shape[1]\n", "    \n", "    def __getitem__(self, index):\n", "        y = self.labels[index]\n", "        x = self.samples[index]\n", "        return x, y\n", "    \n", "dataset150=DataSet(samples=indataset150,labels=np.ones(indataset150.shape[0])*150)\n", "dataset=DataSet(samples=indataset,labels=np.ones(indataset.shape[0])*150)"]}, {"cell_type": "code", "execution_count": null, "id": "916d461f", "metadata": {"tags": ["lect_02", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.2-runcell05\n", "\n", "class VariationalAutoEncoder(nn.Module):\n", "    def __init__(self, input_dims,latent_dims):  \n", "        super(VariationalAutoEncoder, self).__init__()\n", "        self.linear1 = nn.Linear(input_dims, 10*input_dims)\n", "        self.batch = nn.BatchNorm1d(10*input_dims)\n", "        self.linear2 = nn.Linear(10*input_dims, 10*input_dims)\n", "        self.linear3 = nn.Linear(10*input_dims, latent_dims)\n", "        self.linear4 = nn.Linear(10*input_dims, latent_dims)\n", "\n", "        #Now we need sample in phase space \n", "        self.N       = torch.distributions.Normal(0, 1)\n", "        self.N.loc   = self.N.loc \n", "        self.N.scale = self.N.scale\n", "        self.kl = 0\n", "        \n", "        self.decoder_lin = nn.Sequential(\n", "            nn.Linear(latent_dims, 25*input_dims),\n", "            nn.ReLU(True),\n", "            nn.Linear(25*input_dims, 25*input_dims),\n", "            nn.ReLU(True),\n", "            nn.Linear(25*input_dims, input_dims),\n", "        )\n", "\n", "    def encoder(self, x):\n", "        x = F.relu(self.linear1(x))\n", "        x = F.relu(self.batch(self.linear2(x)))\n", "        x = torch.flatten(x, start_dim=1)\n", "        mu =  self.linear3(x) #Mean in the gaussian space\n", "        sigma = torch.exp(self.linear4(x)) #sigma in the space\n", "        z = mu + sigma*self.N.sample(mu.shape) #smear \n", "        self.kl = (sigma**2 + mu**2 - torch.log(sigma) - 1/2).sum() #Now compute the KL divergence\n", "        return z\n", "            \n", "    def encoder_nosmear(self, x):\n", "        x = F.relu(self.linear1(x))\n", "        x = F.relu(self.batch(self.linear2(x)))\n", "        x = torch.flatten(x, start_dim=1)\n", "        mu =  self.linear3(x) #Mean in the gaussian space\n", "        sigma = torch.exp(self.linear4(x)) #sigma in the space\n", "        return mu,sigma\n", "    \n", "    def decoder(self, x):\n", "        x = self.decoder_lin(x)\n", "        return x\n", "    \n", "    def forward(self, x):\n", "        z = self.encoder(x)\n", "        return self.decoder(z)\n", "    \n", "torch.manual_seed(0)\n", "d = 2\n", "vae = VariationalAutoEncoder(input_dims=dataset.nfeatures(),latent_dims=d)\n", "lr = 1e-3 \n", "optim = torch.optim.Adam(vae.parameters(), lr=lr, weight_decay=1e-5)\n", "train_loader = torch.utils.data.DataLoader(dataset150, batch_size=500)\n", "#valid_loader = torch.utils.data.DataLoader(dataset150, batch_size=500)\n", "#test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,shuffle=True)\n"]}, {"cell_type": "code", "execution_count": null, "id": "3ccb84ac", "metadata": {"tags": ["lect_02", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.2-runcell06\n", "\n", "#redefine functions from the previous section (if you have not run L21.1)\n", "\n", "### Training function\n", "def train_epoch(vae, dataloader, optimizer):\n", "    # Set train mode for both the encoder and the decoder\n", "    vae.train()\n", "    train_loss = 0.0\n", "    # Iterate the dataloader (we do not need the label values, this is unsupervised learning)\n", "    for x, _ in dataloader:\n", "        # Move tensor to the proper device\n", "        x_hat = vae(x)\n", "        # Evaluate loss\n", "        loss = ((x - x_hat)**2).sum() + vae.kl\n", "        # Backward pass\n", "        optimizer.zero_grad()\n", "        loss.backward()\n", "        optimizer.step()\n", "        # Print batch loss\n", "        #print('\\t partial train loss (single batch): %f' % (loss.item()))\n", "        train_loss+=loss.item()\n", "\n", "    return train_loss / len(dataloader.dataset)\n", "\n", "### Testing function\n", "def test_epoch(vae, dataloader):\n", "    # Set evaluation mode for encoder and decoder\n", "    vae.eval()\n", "    val_loss = 0.0\n", "    with torch.no_grad(): # No need to track the gradients\n", "        for x, _ in dataloader:\n", "            # Encode data\n", "            encoded_data = vae.encoder(x)\n", "            # Decode data\n", "            x_hat = vae(x)\n", "            loss = ((x - x_hat)**2).sum() + vae.kl\n", "            val_loss += loss.item()\n", "\n", "    return val_loss / len(dataloader.dataset)"]}, {"cell_type": "code", "execution_count": null, "id": "e6db8bc8", "metadata": {"tags": ["lect_02", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.2-runcell07\n", "\n", "num_epochs = 5001\n", "\n", "for epoch in range(num_epochs):\n", "    train_loss = train_epoch(vae,train_loader,optim)\n", "    #val_loss = test_epoch(vae,valid_loader)\n", "    if epoch % 500 == 0:\n", "        print('EPOCH {}/{} \\t train loss {:.3f} \\t'.format(epoch + 1, num_epochs,train_loss))\n"]}, {"cell_type": "code", "execution_count": null, "id": "7439bd9d", "metadata": {"tags": ["lect_02", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.2-runcell08\n", "\n", "def plotVAEOutputs(iLatentDim,iDataSet):\n", "    #generate events assuming a random normal with latent dimension given the the latent space\n", "    testlatent=torch.randn(iDataSet.shape[0],iLatentDim)\n", "    testlatent=testlatent.reshape(iDataSet.shape[0],iLatentDim)\n", "    #now decode thme into observables\n", "    outputvars=vae.decoder(testlatent)\n", "\n", "    xrange=np.arange(0,60,2)\n", "    plt.title('Deposition Length: 150 MeV')\n", "    plt.xlabel('Distance [cm]')\n", "    plt.ylabel('N')\n", "    plt.hist(iDataSet[:,0],label='input',alpha=0.5,bins=xrange)\n", "    plt.hist(outputvars[:,0].detach().numpy(),label='output',alpha=0.5,bins=xrange)\n", "    plt.legend()\n", "    plt.show()\n", "\n", "    xrange=np.arange(-10,10,0.5)\n", "    plt.title('Width: 150 MeV')\n", "    plt.xlabel('Width [cm]')\n", "    plt.ylabel('N')\n", "    plt.hist(iDataSet[:,1],label='input',alpha=0.5,bins=xrange)\n", "    plt.hist(outputvars[:,1].detach().numpy(),label='output',alpha=0.5,bins=xrange)\n", "    plt.legend()\n", "    plt.show()\n", "\n", "    xrange=np.arange(0,10,0.05)\n", "    plt.title('E-Deposit Front: 150 MeV')\n", "    plt.xlabel('E-Deposit Front')\n", "    plt.ylabel('N)')\n", "    plt.hist(iDataSet[:,2],label='input',alpha=0.5,bins=xrange)\n", "    plt.hist(outputvars[:,2].detach().numpy(),label='output',alpha=0.5,bins=xrange)\n", "    plt.legend()\n", "    plt.show()\n", "\n", "    xrange=np.arange(0,60,2)\n", "    plt.title('E-Deposit Back: 150 MeV')\n", "    plt.xlabel('E-Deposit Back')\n", "    plt.ylabel('N)')\n", "    plt.hist(iDataSet[:,3],label='input',alpha=0.5,bins=xrange)\n", "    plt.hist(outputvars[:,3].detach().numpy(),label='output',alpha=0.5,bins=xrange)\n", "    plt.legend()\n", "    plt.show()\n", "\n", "plotVAEOutputs(d,indataset150)"]}, {"cell_type": "markdown", "id": "023f7c2c", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='exercises_22_2'></a>     \n", "\n", "| [Top](#section_22_0) | [Restart Section](#section_22_2) | [Next Section](#section_22_3) |\n"]}, {"cell_type": "markdown", "id": "b1db6962", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 21.2.1</span>\n", "\n", "Let's test the fidelity of the network. Plot the encoding of our setup using the `corner` plot function, which we will use many times in future lessons. A corner plot shows the posterior distributions of fit parameters, with 2D plots revealing any correlations between parameters. Thus, with a corner plot, we will learn the best estimates for the parameters of the latent space: $\\mu_{1}$, $\\mu_{2}$, $\\sigma_{1}$,  and $\\sigma_{2}$.\n", "\n", "Run the code below, where use the `encoder_nosmear` function to output $\\mu$ and $\\sigma$ of the VAE latent space for each event. Are these values consistent with our expectation, that $\\mu_{1}$, $\\mu_{2}$ are 0 and $\\sigma_{1}$,  and $\\sigma_{2}$ are 1? \n", "\n", "Report the values as a list of numbers `[mu1, mu2, sigma1, sigma2]` with precision `1e-2`. Since it may be the case that your code defines `mu1` and `mu2` oppositely from us (the order is arbitraty), let's explicitly define the `mu` values with `mu1` as the smallest and `mu2` as the largest. So, if you found the following set of parameters: `mu1=0.5`, `mu2=0.1`, `sigma1=0.01`, `sigma2=0.02`, then you should submit this as: `[0.1, 0.5, 0.02, 0.01]`.\n", "\n", "<br>"]}, {"cell_type": "code", "execution_count": null, "id": "5caf1ace", "metadata": {"tags": ["py", "draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L21.2.1\n", "\n", "mu,sigma=vae.encoder_nosmear(indataset150)\n", "allvars=np.hstack((mu.detach().numpy(),sigma.detach().numpy()))\n", "corner.corner(allvars,show_titles=True,labels=['$\\mu_{1}$','$\\mu_{2}$','$\\sigma_{1}$','$\\sigma_{2}$'],plot_datapoints=True,quantiles=[0.16, 0.5, 0.84])\n", "plt.show()\n"]}, {"cell_type": "markdown", "id": "6c092ce3", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 21.2.2</span>\n", "\n", "Now we will modify the `plotVAEOutputs` function from `L21.2-runcell08` above, by giving it the values for the latent space, `mu` and `sigma`, that were found by the encoder.  We can then have it sample a normal distribution with these parameters, generate outputs, and compare to the inputs (i.e., true distributions). Run the code below and determine which one of the following characteristics has the most improved agreement between the inputs and outputs of the VAE. \n", "\n", "A) Deposition Length\\\n", "B) Width\\\n", "C) E-Deposit Front\\\n", "D) E-Deposit Back\n", "\n", "<br>"]}, {"cell_type": "code", "execution_count": null, "id": "4a163b88", "metadata": {"tags": ["py", "draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L21.2.2\n", "\n", "def plotVAEOutputs_Real(iMu,iSigma,iLatentDim,iDataSet):\n", "    #generate events assuming a random normal, based on the latent space values iMu and iSigma\n", "    testlatent=torch.randn(iMu.shape)\n", "    testlatent=testlatent*iSigma+iMu\n", "    #now decode thme into observables\n", "    outputvars = vae.decoder(testlatent)\n", "    #now because we can, lets ust generate 5 times as many events\n", "    for i in range(0,5):\n", "        testlatent=torch.randn(iMu.shape)\n", "        testlatent=testlatent*iSigma+iMu\n", "        outputvars=torch.cat((outputvars,vae.decoder(testlatent)))\n", "\n", "    xrange=np.arange(0,60,2)\n", "    plt.title('Deposition Length: 150 MeV')\n", "    plt.xlabel('Distance [cm]')\n", "    plt.ylabel('N')\n", "    plt.hist(iDataSet[:,0],label='input',alpha=0.5,bins=xrange,density=True)\n", "    plt.hist(outputvars[:,0].detach().numpy(),label='output',alpha=0.5,bins=xrange,density=True)\n", "    plt.legend()\n", "    plt.show()\n", "\n", "    xrange=np.arange(-10,10,0.5)\n", "    plt.title('Width: 150 MeV')\n", "    plt.xlabel('Width [cm]')\n", "    plt.ylabel('N')\n", "    plt.hist(iDataSet[:,1],label='input',alpha=0.5,bins=xrange,density=True)\n", "    plt.hist(outputvars[:,1].detach().numpy(),label='output',alpha=0.5,bins=xrange,density=True)\n", "    plt.legend()\n", "    plt.show()\n", "\n", "    xrange=np.arange(0,10,0.05)\n", "    plt.title('E-Deposit Front: 150 MeV')\n", "    plt.xlabel('E-Deposit Front')\n", "    plt.ylabel('N)')\n", "    plt.hist(iDataSet[:,2],label='input',alpha=0.5,bins=xrange,density=True)\n", "    plt.hist(outputvars[:,2].detach().numpy(),label='output',alpha=0.5,bins=xrange,density=True)\n", "    plt.legend()\n", "    plt.show()\n", "\n", "    xrange=np.arange(0,60,2)\n", "    plt.title('E-Deposit Back: 150 MeV')\n", "    plt.xlabel('E-Deposit Back')\n", "    plt.ylabel('N)')\n", "    plt.hist(iDataSet[:,3],label='input',alpha=0.5,bins=xrange,density=True)\n", "    plt.hist(outputvars[:,3].detach().numpy(),label='output',alpha=0.5,bins=xrange,density=True)\n", "    plt.legend()\n", "    plt.show()\n", "\n", "mu,sigma=vae.encoder_nosmear(indataset150)\n", "plotVAEOutputs_Real(mu,sigma,d,indataset150)"]}, {"cell_type": "markdown", "id": "c199f252", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='section_22_3'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L21.3 Generating Full Bragg Scattering Details </h2>  \n", "\n", "| [Top](#section_22_0) | [Previous Section](#section_22_2) | [Exercises](#exercises_22_3) | [Next Section](#section_22_4) |"]}, {"cell_type": "code", "execution_count": null, "id": "fec0b41f", "metadata": {"scrolled": false, "tags": ["lect_03", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.3-runcell01\n", "\n", "def plotImage(iId,ixstep,iestep,iystep):\n", "    #plt.plot(ixstep[iId],iystep[iId])#,iestep[iId])\n", "    #plt.show()\n", "    #Now let's make a regular image \n", "    xbin = np.arange(-1,55, 2)\n", "    ybin = np.arange(-3.75, 3.75, 0.25)\n", "    #xbin = np.arange(-0.5,60.5, 1)\n", "    #ybin = np.arange(-5.125, 5.125, 0.25)\n", "    H, xedges, yedges = np.histogram2d(ixstep.flatten(), iystep.flatten(), bins=(xbin, ybin),weights=iestep.flatten())  \n", "    plt.imshow(H.T,extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]])  \n", "    plt.show()\n", "    #X, Y = np.meshgrid(xedges, yedges)\n", "    #plt.pcolormesh(X,Y,H.T)  \n", "    #plt.show()\n", "\n", "plotImage(-1,xstep150,estep150,ystep150)\n", "plotImage(-1,xstep200,estep200,ystep200)\n", "plotImage(-1,xstep250,estep250,ystep250)\n", "plotImage(-1,xstep300,estep300,ystep300)\n", "\n", "\n", "def makeImageDataSet(iE,ixstep,iestep,iystep):\n", "    dataset=np.empty((0,1,28,28))\n", "    for pX,pE,pY in zip(ixstep,iestep,iystep):\n", "        xbin = np.arange(-1,57, 2)\n", "        ybin = np.arange(-3.625, 3.625, 0.25)\n", "        H, xedges, yedges = np.histogram2d(pX.flatten(), pY.flatten(), bins=(xbin, ybin),weights=pE.flatten())  \n", "        #H, xedges, yedges = np.histogram2d(ixstep.flatten(), iystep.flatten(), bins=(xbin, ybin),weights=iestep.flatten())  \n", "        #plt.imshow(H.T,extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]])  \n", "        #plt.show()\n", "        H = np.reshape(H.T,(1,1,28,28))\n", "        dataset = np.vstack((dataset,H))\n", "    #print(dataset.shape)\n", "    Tdataset = torch.tensor(dataset).float()\n", "    datasetout=DataSet(samples=Tdataset,labels=np.ones(dataset.shape[0])*iE)\n", "    return datasetout,dataset\n", "\n", "image150,dimage150=makeImageDataSet(1.50,xstep150,estep150,ystep150)\n", "image200,dimage200=makeImageDataSet(2.00,xstep200,estep200,ystep200)\n", "image250,dimage250=makeImageDataSet(2.50,xstep250,estep250,ystep250)\n", "image300,dimage300=makeImageDataSet(3.00,xstep300,estep300,ystep300)"]}, {"cell_type": "code", "execution_count": null, "id": "12f3671f", "metadata": {"tags": ["lect_03", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.3-runcell02\n", "\n", "class VariationalAutoEncoder(nn.Module):\n", "    def __init__(self, latent_dims):  \n", "        super(VariationalAutoEncoder, self).__init__()\n", "        self.conv1 = nn.Conv2d(1, 8, 3, stride=2, padding=1)\n", "        self.conv2 = nn.Conv2d(8, 16, 3, stride=2, padding=1)\n", "        self.batch2 = nn.BatchNorm2d(16)\n", "        self.conv3 = nn.Conv2d(16, 32, 3, stride=2, padding=0)  \n", "        self.linear1 = nn.Linear(3*3*32, 128)\n", "        self.linear2 = nn.Linear(128, latent_dims)\n", "        self.linear3 = nn.Linear(128, latent_dims)\n", "\n", "        #Now we need sample in phase space \n", "        self.N       = torch.distributions.Normal(0, 1)\n", "        self.N.loc   = self.N.loc \n", "        self.N.scale = self.N.scale\n", "        self.kl = 0\n", "        \n", "        self.unflatten = nn.Unflatten(dim=1, unflattened_size=(32, 3, 3))\n", "\n", "        self.decoder_conv = nn.Sequential(\n", "            nn.ConvTranspose2d(32, 16, 3, stride=2, output_padding=0),\n", "            nn.BatchNorm2d(16),\n", "            nn.ReLU(True),\n", "            nn.ConvTranspose2d(16, 8, 3, stride=2, padding=1, output_padding=1),\n", "            nn.BatchNorm2d(8),\n", "            nn.ReLU(True),\n", "            nn.ConvTranspose2d(8, 1, 3, stride=2, padding=1, output_padding=1)\n", "        )\n", "\n", "        self.decoder_lin = nn.Sequential(\n", "            nn.Linear(latent_dims, 128),\n", "            nn.ReLU(True),\n", "            nn.Linear(128, 3 * 3 * 32),\n", "            nn.ReLU(True)\n", "        )\n", "\n", "\n", "    def encoder(self, x):\n", "        x = F.relu(self.conv1(x))\n", "        x = F.relu(self.batch2(self.conv2(x)))\n", "        x = F.relu(self.conv3(x))\n", "        x = torch.flatten(x, start_dim=1)\n", "        x = F.relu(self.linear1(x))\n", "        mu =  self.linear2(x) #Mean in the gaussian space\n", "        sigma = torch.exp(self.linear3(x)) #sigma in the space\n", "        z = mu + sigma*self.N.sample(mu.shape) #smear \n", "        self.kl = (sigma**2 + mu**2 - torch.log(sigma) - 1/2).sum() #Now compute the KL divergence\n", "        return z\n", "\n", "    def encoder_nosmear(self, x):\n", "        x = F.relu(self.conv1(x))\n", "        x = F.relu(self.batch2(self.conv2(x)))\n", "        x = F.relu(self.conv3(x))\n", "        x = torch.flatten(x, start_dim=1)\n", "        x = F.relu(self.linear1(x))\n", "        mu =  self.linear2(x) #Mean in the gaussian space\n", "        sigma = torch.exp(self.linear3(x)) #sigma in the space\n", "        return mu,sigma\n", "    \n", "    def decoder(self, x):\n", "        x = self.decoder_lin(x)\n", "        x = self.unflatten(x)\n", "        x = self.decoder_conv(x)\n", "        return x\n", "\n", "        \n", "    def forward(self, x):\n", "        z = self.encoder(x)\n", "        return self.decoder(z)\n", "    \n", "torch.manual_seed(0)\n", "d = 4\n", "vae = VariationalAutoEncoder(latent_dims=d)\n", "lr = 1e-2 \n", "optim = torch.optim.Adam(vae.parameters(), lr=lr, weight_decay=1e-5)\n", "train_loader = torch.utils.data.DataLoader(image150, batch_size=500)"]}, {"cell_type": "code", "execution_count": null, "id": "43d539af", "metadata": {"tags": ["lect_03", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.3-runcell03\n", "\n", "def plot_ae_outputs(idataset,ivae,n=10):\n", "    plt.figure(figsize=(16,4.5))\n", "    t_idx = np.random.randint(10,size=10)\n", "    for i in range(n):\n", "      ax = plt.subplot(2,n,i+1)\n", "      img = idataset[t_idx[i]][0].unsqueeze(0)\n", "      vae.eval()\n", "      #encoder.eval()\n", "      #decoder.eval()\n", "      with torch.no_grad():\n", "         rec_img  = vae.decoder(vae.encoder(img))\n", "      plt.imshow(img.cpu().squeeze().numpy())#, cmap='gist_gray')\n", "      ax.get_xaxis().set_visible(False)\n", "      ax.get_yaxis().set_visible(False)  \n", "      if i == n//2:\n", "        ax.set_title('Original images')\n", "      ax = plt.subplot(2, n, i + 1 + n)\n", "      plt.imshow(rec_img.cpu().squeeze().numpy())#, cmap='gist_gray')  \n", "      ax.get_xaxis().set_visible(False)\n", "      ax.get_yaxis().set_visible(False)  \n", "      if i == n//2:\n", "         ax.set_title('Reconstructed images')\n", "    plt.show()  \n", "    "]}, {"cell_type": "code", "execution_count": null, "id": "7763453a", "metadata": {"scrolled": true, "tags": ["lect_03", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.3-runcell04\n", "\n", "#Note: this will take some time\n", "\n", "num_epochs = 2500\n", "\n", "for epoch in range(num_epochs):\n", "    train_loss = train_epoch(vae,train_loader,optim)\n", "    val_loss=0\n", "    if epoch % 500 == 0:\n", "        print('\\n EPOCH {}/{} \\t train loss {:.3f} \\t val loss {:.3f}'.format(epoch + 1, num_epochs,train_loss,val_loss))\n", "        plot_ae_outputs(image150,vae,n=10)\n", "        \n", "\n", "print(\"final loss\", train_loss)"]}, {"cell_type": "code", "execution_count": null, "id": "b835fcbf", "metadata": {"tags": ["lect_03", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.3-runcell05\n", "\n", "def plotVAEImageOutputs(iLatentDim,iDataSet):\n", "    testlatent=torch.randn(iDataSet.shape[0],iLatentDim)\n", "    testlatent=testlatent.reshape(iDataSet.shape[0],iLatentDim)\n", "    rec_img  = vae.decoder(testlatent)\n", "    rec_img  = rec_img.detach().numpy()\n", "\n", "    xbin = np.arange(-0.5,27.5, 1)\n", "    ybin = np.arange(-3.5, 3.5, 0.25)\n", "    plt.plot(xbin,np.mean(np.sum(iDataSet,axis=2),axis=0).flatten(),drawstyle='steps-mid',label='MC')\n", "    plt.plot(xbin,np.mean(np.sum(rec_img,axis=2),axis=0).flatten(),drawstyle='steps-mid',label='NN')\n", "    plt.xlabel('x-distance(cm)')\n", "    plt.show()\n", "    \n", "\n", "    plt.plot(ybin,np.mean(np.sum(iDataSet,axis=3),axis=0).flatten(),drawstyle='steps-mid',label='MC')\n", "    plt.plot(ybin,np.mean(np.sum(rec_img,axis=3),axis=0).flatten(),drawstyle='steps-mid',label='NN')\n", "    plt.xlabel('y-distance(cm)')\n", "    plt.show()\n", "\n", "    xrange=np.arange(0,10,0.5)\n", "    plt.hist(np.sum(iDataSet,axis=2)[0:10].flatten(),label='input',alpha=0.5,bins=xrange,density=True)\n", "    plt.hist(np.sum(rec_img ,axis=2)[0:10].flatten(),label='output',alpha=0.5,bins=xrange,density=True)\n", "    plt.xlabel(\"E-deposit(0-10 pixels)\")\n", "    plt.legend()\n", "    plt.show()\n", "\n", "    xrange=np.arange(0,60,2)\n", "    plt.hist(np.sum(iDataSet,axis=2)[10:20].flatten(),label='input',alpha=0.5,bins=xrange,density=True)\n", "    plt.hist(np.sum(rec_img ,axis=2)[10:20].flatten(),label='output',alpha=0.5,bins=xrange,density=True)\n", "    plt.legend()\n", "    plt.xlabel(\"E-deposit(10-20 pixels)\")\n", "    plt.show()\n", "    \n", "    dimage150_avg = np.mean(iDataSet,axis=0)\n", "    plt.imshow(dimage150_avg[0])\n", "    plt.show()\n", "\n", "    rec_img_avg = np.mean(rec_img,axis=0)\n", "    plt.imshow(rec_img_avg[0])\n", "    plt.show()\n", "\n", "#dimage150_avg = np.mean(dimage150,axis=0)\n", "#plt.imshow(dimage150_avg[0])\n", "#plt.show()\n", "#dimage150_tmp = np.mean(dimage150,axis=0)\n", "#plt.imshow(dimage150[0][0])\n", "#plt.show()\n", "#test=np.mean(np.sum(dimage150,axis=3),axis=0)\n", "plotVAEImageOutputs(d,dimage150)\n", "torch.save(vae.state_dict(), 'data/L22/vae_150.pt')"]}, {"cell_type": "markdown", "id": "4f86b9d5", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["Now, we can see that we get bettet agreement for our VAE in terms of modelling the effects, when compared to just trying to model the high-level observables. However, we need to a little careful. In the previous, we were modelling high levle obserrables tha tare precise. Here we are trying to capture a quantized(pixelated) image, which we do. Really, we have taken a problem with complex inputs and outputs and replaced the training to take simple images and produced output images. While there are more inputs and outputs, the actual obserables are quite simple. We are just taking in images of particle showers, simplifying them, and reproducing hte same particle showers. The shower is a continuous object with a characteristic shape. This is much more physically meaningful than high level observable. We can explore this more in the problems below. \n"]}, {"cell_type": "markdown", "id": "3a9d93d2", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='exercises_22_3'></a>     \n", "\n", "| [Top](#section_22_0) | [Restart Section](#section_22_3) | [Next Section](#section_22_4) |\n"]}, {"cell_type": "markdown", "id": "104570ae", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 21.3.1</span>\n", "\n", "As we did in the last section, let's look at the latent space. Run the code below, where we again use the `encoder_nosmear` function to output $\\mu$ and $\\sigma$ of the VAE latent space for each event, and then make a corner plot. Does it look more regular than before?\n", "\n", "What are the mus and sigmas for all 4 dimensions? Report the values as a list of numbers `[mu1,mu2,mu3,mu4,sigma1,sigma2,sigma3,sigma4]` with precision `1e-2`. Again, since it may be the case that your code defines the `mu` values oppositely from us (the order is arbitraty), let's explicitly define the `mu` values with `mu1` as the smallest, in ascending order. Note some `mu` values could be negative, so they should occur first in your list!\n", "\n", "<br>"]}, {"cell_type": "code", "execution_count": null, "id": "28f8913e", "metadata": {"tags": ["py", "draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L21.3.1\n", "\n", "mu,sigma=vae.encoder_nosmear(torch.tensor(dimage150).float())\n", "allvars=np.hstack((mu.detach().numpy(),sigma.detach().numpy()))\n", "corner.corner(allvars,show_titles=True,labels=['$\\mu_{1}$','$\\mu_{2}$','$\\mu_{3}$','$\\mu_{4}$','$\\sigma_{1}$','$\\sigma_{2}$','$\\sigma_{3}$','$\\sigma_{4}$'],plot_datapoints=True,quantiles=[0.16, 0.5, 0.84])\n"]}, {"cell_type": "markdown", "id": "558bc58a", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 22.3.2</span>\n", "\n", "Again, lets generate events off the latent space found from our encoder. Run the code below, where we have given it the $\\mu$ and $\\sigma$ values found above, and compare the inputs and outputs of the VAE for various characteristics.\n", "\n", "Does the agreement between inputs and outputs improve, compared to the results of cell `L21.3-runcell05`?\n", "\n", "A) Yes\\\n", "B) No\\\n", "C) Maybe?\n"]}, {"cell_type": "code", "execution_count": null, "id": "409d855a", "metadata": {"tags": ["py", "draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L21.3.2\n", "\n", "def plotVAEImageOutputs_real(iMu,iSigma,iLatentDim,iDataSet):    \n", "    testlatent=torch.randn(iMu.shape)\n", "    testlatent=testlatent*iSigma+iMu\n", "    rec_img  = vae.decoder(testlatent)\n", "    rec_img  = rec_img.detach().numpy()\n", "\n", "    xbin = np.arange(-0.5,27.5, 1)\n", "    ybin = np.arange(-3.5, 3.5, 0.25)\n", "    plt.plot(xbin,np.mean(np.sum(iDataSet,axis=2),axis=0).flatten(),drawstyle='steps-mid',label='MC')\n", "    plt.plot(xbin,np.mean(np.sum(rec_img,axis=2),axis=0).flatten(),drawstyle='steps-mid',label='NN')\n", "    plt.xlabel('x-distance(cm)')\n", "    plt.show()\n", "\n", "\n", "    plt.plot(ybin,np.mean(np.sum(iDataSet,axis=3),axis=0).flatten(),drawstyle='steps-mid',label='MC')\n", "    plt.plot(ybin,np.mean(np.sum(rec_img,axis=3),axis=0).flatten(),drawstyle='steps-mid',label='NN')\n", "    plt.xlabel('y-distance(cm)')\n", "    plt.show()\n", "\n", "    xrange=np.arange(0,10,0.5)\n", "    plt.hist(np.sum(iDataSet,axis=2)[0:10].flatten(),label='input',alpha=0.5,bins=xrange,density=True)\n", "    plt.hist(np.sum(rec_img ,axis=2)[0:10].flatten(),label='output',alpha=0.5,bins=xrange,density=True)\n", "    plt.xlabel(\"E-deposit(0-10 pixels)\")\n", "    plt.legend()\n", "    plt.show()\n", "\n", "    xrange=np.arange(0,60,2)\n", "    plt.hist(np.sum(iDataSet,axis=2)[10:20].flatten(),label='input',alpha=0.5,bins=xrange,density=True)\n", "    plt.hist(np.sum(rec_img ,axis=2)[10:20].flatten(),label='output',alpha=0.5,bins=xrange,density=True)\n", "    plt.legend()\n", "    plt.xlabel(\"E-deposit(10-20 pixels)\")\n", "    plt.show()\n", "\n", "    dimage150_avg = np.mean(iDataSet,axis=0)\n", "    plt.imshow(dimage150_avg[0])\n", "    plt.show()\n", "\n", "    rec_img_avg = np.mean(rec_img,axis=0)\n", "    plt.imshow(rec_img_avg[0])\n", "    plt.show()\n", "    \n", "mu,sigma=vae.encoder_nosmear(torch.tensor(dimage150).float())\n", "plotVAEImageOutputs_real(mu,sigma,d,dimage150)"]}, {"cell_type": "markdown", "id": "5af1f000", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 21.3.3</span>\n", "\n", "Now, let's generate similar plots at another energy. Try repeating the training procedure in this section using the `dimage300` dataset. What qualitative differences do you observe? Select ALL options that apply:\n", "\n", "\n", "A) The tracks are spread out more spatially.\\\n", "B) The VAE has a higher loss.\\\n", "C) The VAE does a comparable job at matching the histograms compared to the case with the 150 Mev dataset.\n", "\n", "\n", "Ultimately, we do not want to be required to create a new simulation for every energy. Rather, we want to condition the output of the decoder on the energy that is given. We will discuss this in the next section!\n", "\n", "<br>"]}, {"cell_type": "markdown", "id": "5ff41edd", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='section_22_4'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L21.4 Conditional VAEs allowing for energy based generation </h2>  \n", "\n", "\n", "\n", "| [Top](#section_22_0) | [Previous Section](#section_22_3) | [Exercises](#exercises_22_4) | [Next Section](#section_22_5) |"]}, {"cell_type": "code", "execution_count": null, "id": "c3961b18", "metadata": {"tags": ["lect_04", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.4-runcell01\n", "\n", "class CondVariationalAutoEncoder(nn.Module):\n", "    def __init__(self, latent_dims):  \n", "        super(CondVariationalAutoEncoder, self).__init__()\n", "        self.conv1 = nn.Conv2d(1, 8, 3, stride=2, padding=1)\n", "        self.conv2 = nn.Conv2d(8, 16, 3, stride=2, padding=1)\n", "        self.batch2 = nn.BatchNorm2d(16)\n", "        self.conv3 = nn.Conv2d(16, 32, 3, stride=2, padding=0)  \n", "        self.linear1  = nn.Linear(3*3*32, 64)\n", "        self.linear1a = nn.Linear(64, 8)\n", "        self.linear1b = nn.Linear(9,  8)\n", "        self.linear2 = nn.Linear(8, latent_dims)\n", "        self.linear3 = nn.Linear(8, latent_dims)\n", "\n", "        #Now we need sample in phase space \n", "        self.N       = torch.distributions.Normal(0, 1)\n", "        self.N.loc   = self.N.loc \n", "        self.N.scale = self.N.scale\n", "        self.kl = 0\n", "        \n", "        self.unflatten = nn.Unflatten(dim=1, unflattened_size=(32, 3, 3))\n", "\n", "        self.decoder_conv = nn.Sequential(\n", "            nn.ConvTranspose2d(32, 16, 3, stride=2, output_padding=0),\n", "            #nn.BatchNorm2d(16),\n", "            nn.ReLU(True),\n", "            nn.ConvTranspose2d(16, 8, 3, stride=2, padding=1, output_padding=1),\n", "            nn.BatchNorm2d(8),\n", "            nn.ReLU(True),\n", "            nn.ConvTranspose2d(8, 1, 3, stride=2, padding=1, output_padding=1)\n", "        )\n", "\n", "        self.decoder_lin = nn.Sequential(\n", "            nn.Linear(latent_dims+1, 64),\n", "            nn.ReLU(True),\n", "            nn.Linear(64, 3 * 3 * 32),\n", "            nn.ReLU(True)\n", "        )\n", "\n", "\n", "    def encoder(self, x, c): #c is our condition\n", "        x = F.relu(self.conv1(x))\n", "        #x = F.relu(self.batch2(self.conv2(x)))\n", "        x = F.relu(self.conv2(x))\n", "        x = F.relu(self.conv3(x))\n", "        x = torch.flatten(x, start_dim=1)\n", "        x = F.relu(self.linear1(x))\n", "        x = F.relu(self.linear1a(x))\n", "        x = torch.hstack((x,c))\n", "        x = F.relu(self.linear1b(x))\n", "        mu =  self.linear2(x) #Mean in the gaussian space with the condition\n", "        sigma = torch.exp(self.linear3(x)) #sigma in the space with the condition\n", "        z = mu + sigma*self.N.sample(mu.shape) #smear \n", "        self.kl = (sigma**2 + mu**2 - torch.log(sigma) - 1/2).sum() #Now compute the KL divergence\n", "        return z\n", "\n", "            \n", "    def decoder(self, x, c):\n", "        x = torch.hstack((x,c))\n", "        x = self.decoder_lin(x)\n", "        x = self.unflatten(x)\n", "        x = self.decoder_conv(x)\n", "        return x\n", "\n", "        \n", "    def forward(self, x, c):\n", "        z = self.encoder(x, c)\n", "        return self.decoder(z, c)\n", "    \n", "torch.manual_seed(0)\n", "d = 6\n", "cvae_proton_image = CondVariationalAutoEncoder(latent_dims=d)\n", "lr = 1e-2 \n", "optim = torch.optim.Adam(cvae_proton_image.parameters(), lr=lr, weight_decay=1e-5)\n", "from torch.utils.data import ConcatDataset\n", "megeimage=ConcatDataset([image150, image200,image250,image300])\n", "train_loader = torch.utils.data.DataLoader(megeimage, batch_size=500)\n", "#from torchsummary import summary\n", "#summary(cvae_proton_image, ((1, 28, 28),1))"]}, {"cell_type": "code", "execution_count": null, "id": "d94e0f5b", "metadata": {"tags": ["lect_04", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.4-runcell02\n", "\n", "def plot_ae_outputs(idataset,ivae,n=10):\n", "    plt.figure(figsize=(16,4.5))\n", "    t_idx = np.random.randint(10,size=10)\n", "    for i in range(n):\n", "      ax = plt.subplot(2,n,i+1)\n", "      img = idataset[t_idx[i]][0].unsqueeze(0)\n", "      ivae.eval()\n", "      #encoder.eval()\n", "      #decoder.eval()\n", "      npones=np.ones((1,1))*1.50\n", "      beam=torch.tensor(npones).float()\n", "      with torch.no_grad():\n", "         rec_img  = ivae.decoder(ivae.encoder(img,beam),beam)\n", "      plt.imshow(img.cpu().squeeze().numpy())#, cmap='gist_gray')\n", "      ax.get_xaxis().set_visible(False)\n", "      ax.get_yaxis().set_visible(False)  \n", "      if i == n//2:\n", "        ax.set_title('Original images')\n", "      ax = plt.subplot(2, n, i + 1 + n)\n", "      plt.imshow(rec_img.cpu().squeeze().numpy())#, cmap='gist_gray')  \n", "      ax.get_xaxis().set_visible(False)\n", "      ax.get_yaxis().set_visible(False)  \n", "      if i == n//2:\n", "         ax.set_title('Reconstructed images')\n", "    plt.show()  \n", "\n", "### Training function\n", "def train_epoch(vae, dataloader, optimizer):\n", "    # Set train mode for both the encoder and the decoder\n", "    vae.train()\n", "    train_loss = 0.0\n", "    # Iterate the dataloader (we do not need the label values, this is unsupervised learning)\n", "    for x, c in dataloader: \n", "        # Move tensor to the proper device\n", "        c=c.reshape(len(c),1).float()\n", "        x_hat = vae(x,c)\n", "        # Evaluate loss\n", "        loss = ((x - x_hat)**2).sum() + vae.kl\n", "        # Backward pass\n", "        optimizer.zero_grad()\n", "        loss.backward()\n", "        optimizer.step()\n", "        # Print batch loss\n", "        #print('\\t partial train loss (single batch): %f' % (loss.item()))\n", "        train_loss+=loss.item()\n", "\n", "    return train_loss / len(dataloader.dataset)\n", "\n", "lr = 1e-3\n", "optim = torch.optim.Adam(cvae_proton_image.parameters(), lr=lr, weight_decay=1e-5)\n", "\n", "num_epochs = 500\n", "\n", "for epoch in range(num_epochs):\n", "    train_loss = train_epoch(cvae_proton_image,train_loader,optim)\n", "    val_loss=0\n", "    if epoch % 500 == 0 or epoch == num_epochs-1:\n", "        print('\\n EPOCH {}/{} \\t train loss {:.3f} \\t val loss {:.3f}'.format(epoch + 1, num_epochs,train_loss,val_loss))\n", "        plot_ae_outputs(image150,cvae_proton_image,n=10)"]}, {"cell_type": "code", "execution_count": null, "id": "b86574ca", "metadata": {"scrolled": false, "tags": ["lect_04", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.4-runcell03\n", "\n", "def plotCondVAEImageOutputs(iE,iLatentDim,iDataSet,iCVAE):\n", "    testlatent=torch.randn(iDataSet.shape[0],iLatentDim)\n", "    testlatent=testlatent.reshape(iDataSet.shape[0],iLatentDim)\n", "    beamenergy = torch.ones(iDataSet.shape[0],1)*iE\n", "    rec_img  = iCVAE.decoder(testlatent,beamenergy)\n", "    rec_img  = rec_img.detach().numpy()\n", "\n", "    xbin = np.arange(-0.5,27.5, 1)\n", "    ybin = np.arange(-3.5, 3.5, 0.25)\n", "    plt.plot(xbin,np.mean(np.sum(iDataSet,axis=2),axis=0).flatten(),drawstyle='steps-mid',label='MC')\n", "    plt.plot(xbin,np.mean(np.sum(rec_img,axis=2),axis=0).flatten(),drawstyle='steps-mid',label='NN')\n", "    plt.xlabel('x-distance(cm)')\n", "    plt.show()\n", "    \n", "\n", "    plt.plot(ybin,np.mean(np.sum(iDataSet,axis=3),axis=0).flatten(),drawstyle='steps-mid',label='MC')\n", "    plt.plot(ybin,np.mean(np.sum(rec_img,axis=3),axis=0).flatten(),drawstyle='steps-mid',label='NN')\n", "    plt.xlabel('y-distance(cm)')\n", "    plt.show()\n", "\n", "    xrange=np.arange(0,20,1)\n", "    plt.hist(np.sum(iDataSet,axis=2)[0:10].flatten(),label='input',alpha=0.5,bins=xrange,density=True)\n", "    plt.hist(np.sum(rec_img ,axis=2)[0:10].flatten(),label='output',alpha=0.5,bins=xrange,density=True)\n", "    plt.legend()\n", "    plt.show()\n", "\n", "    xrange=np.arange(0,60,2)\n", "    plt.hist(np.sum(iDataSet,axis=2)[12:20].flatten(),label='input',alpha=0.5,bins=xrange,density=True)\n", "    plt.hist(np.sum(rec_img ,axis=2)[12:20].flatten(),label='output',alpha=0.5,bins=xrange,density=True)\n", "    plt.legend()\n", "    plt.show()\n", "    \n", "    dimage150_avg = np.mean(iDataSet,axis=0)\n", "    plt.imshow(dimage150_avg[0])\n", "    plt.show()\n", "\n", "    rec_img_avg = np.mean(rec_img,axis=0)\n", "    plt.imshow(rec_img_avg[0])\n", "    plt.show()\n", "\n", "plotCondVAEImageOutputs(1.50,d,dimage150,cvae_proton_image)\n", "#plotCondVAEImageOutputs(2.00,d,dimage200,cvae_proton_image)\n", "#plotCondVAEImageOutputs(2.25,d,dimage200,cvae_proton_image)\n", "plotCondVAEImageOutputs(2.50,d,dimage250,cvae_proton_image)\n", "#plotCondVAEImageOutputs(3.00,d,dimage300,cvae_proton_image)\n", "#torch.save(cvae_proton_image.state_dict(), 'cvae_test.pt')"]}, {"cell_type": "code", "execution_count": null, "id": "69563505", "metadata": {"tags": ["lect_04", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.4-runcell04\n", "\n", "import time\n", "\n", "def generate(iLatentDim,iN,iCVAE,iE):\n", "    testlatent=torch.randn(iN,iLatentDim)\n", "    testlatent=testlatent.reshape(iN,iLatentDim)\n", "    beamenergy = torch.ones(testlatent.shape[0],1)*iE\n", "    rec_img  = iCVAE.decoder(testlatent,beamenergy)\n", "    rec_img  = rec_img.detach().numpy()\n", "    return rec_img\n", "\n", "N=250\n", "start=time.time()\n", "generate(d,N,cvae_proton_image,1.5)\n", "stop=time.time()\n", "print(\"Time to generate 250 events:\",(stop-start))\n", "timeNN=(stop-start)\n", "\n", "start=time.time()\n", "simNYParallelSample(ie=150,im=mproton,iN=N,idt=1e-10,iZ=8)\n", "stop=time.time()\n", "print(\"Time to generate 250 events:\",(stop-start))\n", "timeGen=(stop-start)\n", "\n", "print(\"===> speed up\",timeGen/timeNN)"]}, {"cell_type": "markdown", "id": "11a64cc5", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='exercises_22_4'></a>     \n", "\n", "| [Top](#section_22_0) | [Restart Section](#section_22_4) | [Next Section](#section_22_5) |\n"]}, {"cell_type": "markdown", "id": "eed0163e", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 21.4.1</span>\n", "\n", "Rerun the training done in code cell `L21.4-runcell02` for 2500 epochs instead of only 500 (note that this will take some time!). Then use code cell `L21.4-runcell03` to look at the comparison of input and reconstructed distributions. Do the features of the decoded output improve? What is the approximate value of the training loss that you achieve at the end of this expanded training? Report your answer as a number with precision `1e1`.\n", "\n", "<br>"]}, {"cell_type": "markdown", "id": "2e4f40f0", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 21.4.2</span>\n", "\n", "With this new data (trained for 2500 epochs), use `plotCondVAEImageOutputs` to model the shower shape for a beam of initial energy 225 MeV, which is not one of the values that we used to train, but falls within the range of the training data. Also try 400 MeV, which falls outside the range of the training data. How does these look?\n", "\n", "Which do you think the VAE is more capable of modeling, based on the training? Enter your answer for which energy would be modeled better, as number in units of MeV.\n", "\n", "<br>"]}, {"cell_type": "markdown", "id": "e06eac65", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='section_22_5'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L21.5 Bootstrapping </h2>  \n", "\n", "\n", "| [Top](#section_22_0) | [Previous Section](#section_22_4) | [Exercises](#exercises_22_5) | [Next Section](#section_22_6) |"]}, {"cell_type": "code", "execution_count": null, "id": "d686c921", "metadata": {"tags": ["lect_05", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.5-runcell01\n", "\n", "np.random.seed(0)\n", "\n", "samples = np.random.uniform(100,300,500)\n", "plt.hist(samples)\n", "plt.show()\n", "\n", "print(\"Mean:\",np.mean(samples))\n", "print(\"RMS:\",np.std(samples))"]}, {"cell_type": "code", "execution_count": null, "id": "9f1a5970", "metadata": {"tags": ["lect_05", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.5-runcell02\n", "\n", "arr=np.arange(10)\n", "test=np.random.choice(arr,size=5)\n", "print(test)\n", "test=np.random.choice(arr,size=10)\n", "print(test)\n", "plt.hist(test)\n", "test=np.random.choice(arr,size=20)\n", "print(test)"]}, {"cell_type": "code", "execution_count": null, "id": "0fe2b8e7", "metadata": {"tags": ["lect_05", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.5-runcell03\n", "\n", "sample=np.random.choice(samples, size = 500)\n", "print(\"Mean:\",np.mean(sample))\n", "print(\"RMS:\",np.std(sample))\n", "\n", "boot_means = []\n", "boot_stds  = []\n", "for _ in range(10000):\n", "    boot_sample = np.random.choice(samples,replace = True, size = 500) # take a random sample each iteration\n", "    boot_means.append(np.mean(boot_sample)) # append the mean to boot_means\n", "    boot_stds.append(np.std(boot_sample)) # append the mean to boot_means\n", "boot_means_np = np.array(boot_means) # transform it into a numpy array for calculation\n", "boot_stds_np = np.array(boot_stds)\n", "\n", "plt.hist(boot_means_np)\n", "plt.show()\n", "\n", "print(\"Mean of samples:\",np.mean(boot_means_np))\n", "print(\"Std of mean of samples:\",np.std(boot_means_np))\n", "\n", "plt.hist(boot_stds_np)\n", "plt.show()\n", "\n", "print(\"Mean of samples:\",np.mean(boot_stds_np))\n", "print(\"Std of mean of samples:\",np.std(boot_stds_np))"]}, {"cell_type": "code", "execution_count": null, "id": "ab824c13", "metadata": {"tags": ["lect_05", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.5-runcell04\n", "\n", "analytic         = (300.+100.)/2.\n", "analytic_std     = (300.-100.)/np.sqrt(12.) \n", "analytic_err     = analytic_std/np.sqrt(500.)\n", "analytic_std_err = analytic_std/np.sqrt(500.)/2.\n", "print(\"Mean of samples:\",np.mean(boot_means_np),\"+/-\",np.std(boot_means_np)\n", "      ,\"\\nAnalytic:\",analytic,\"+/-\",analytic_err)\n", "\n", "print(\"Std of samples:\",np.mean(boot_stds_np),\"+/-\",np.std(boot_stds_np)\n", "      ,\"\\nAnalytic:\",analytic_std,\"+/-\",analytic_std_err)\n"]}, {"cell_type": "code", "execution_count": null, "id": "1fe3defa", "metadata": {"tags": ["lect_05", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.5-runcell05\n", "\n", "samp_means = []\n", "samp_stds  = []\n", "for _ in range(10000):\n", "    samp_sample = np.random.uniform(100,300,500)\n", "    samp_means.append(np.mean(samp_sample)) # append the mean to boot_means\n", "    samp_stds.append(np.std(samp_sample)) # append the mean to boot_means\n", "samp_means_np = np.array(samp_means) # transform it into a numpy array for calculation\n", "samp_stds_np = np.array(samp_stds)\n", "\n", "print(\"Mean of samples:\",np.mean(samp_means_np),\"+/-\",np.std(samp_means_np)\n", "      ,\"\\nBoot:\",np.mean(boot_means_np),\"+/-\",np.std(boot_means_np))\n", "\n", "print(\"Std of samples:\",np.mean(samp_stds_np),\"+/-\",np.std(samp_stds_np)\n", "      ,\"\\nBoot:\",np.mean(boot_stds_np),\"+/-\",np.std(boot_stds_np))\n"]}, {"cell_type": "code", "execution_count": null, "id": "0c00c28f", "metadata": {"tags": ["lect_05", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.5-runcell06\n", "\n", "from scipy.stats import bootstrap\n", "import numpy as np\n", "\n", "test_samples = (samples,)\n", "bootstrap_ci = bootstrap(test_samples, np.std, confidence_level=0.68,random_state=1, method='percentile')\n", "print(bootstrap_ci.confidence_interval,(bootstrap_ci.confidence_interval.high-bootstrap_ci.confidence_interval.low)/2.)\n", "print(bootstrap_ci.standard_error)"]}, {"cell_type": "code", "execution_count": null, "id": "f3383277", "metadata": {"tags": ["lect_05", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.5-runcell07\n", "\n", "def func(x):\n", "    x_sort = np.sort(x,axis=1)\n", "    print(x_sort.shape)\n", "    return (np.vstack((x_sort[:,0] + x_sort[:,-1],x_sort[:,1] + x_sort[:,-1] ))).T\n", "\n", "rand_data = np.random.uniform(0,100,5000).reshape(500,10)\n", "out_data = func(rand_data)\n", "plt.plot(out_data[:,0],out_data[:,1],\".\")\n", "plt.show()\n", "print(\"correlation:\",np.corrcoef(out_data[:,0],out_data[:,1]))\n", "\n", "plt.hist(out_data[:,0]+out_data[:,1])"]}, {"cell_type": "code", "execution_count": null, "id": "b96a9619", "metadata": {"tags": ["lect_05", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.5-runcell08\n", "\n", "boot_sum   = []\n", "boot_corr  = []\n", "for _ in range(10000):\n", "    #boot_sample = np.random.choice(out_data,replace = True, size = 500) # take a random sample each iteration\n", "    boot_sample = out_data[np.random.choice(out_data.shape[0], 500, replace=True)]\n", "    boot_sum.append(np.mean(boot_sample[:,0]+boot_sample[:,1]))\n", "    boot_corr.append(np.corrcoef(boot_sample[:,0],boot_sample[:,1])[1,0])\n", "boot_sum_np = np.array(boot_sum) # transform it into a numpy array for calculation\n", "boot_corr_np = np.array(boot_corr)\n", "print(\"Sum of Boot:\",np.mean(boot_sum_np),\"+/-\",np.std(boot_sum_np),\"-For Comparison sqrt(N) unc-\",np.sqrt(np.mean(boot_sum_np)/500))\n", "print(\"Corr of samples:\",np.mean(boot_corr_np),\"+/-\",np.std(boot_corr_np))\n", "print(boot_sum_np.shape)\n", "\n", "plt.hist(boot_sum_np,density=True)\n", "plt.xlabel(\"$x_{1}+x_{2}$\")\n", "plt.ylabel(\"pdf\")\n", "plt.show()\n", "\n", "plt.hist(boot_corr_np,density=True)\n", "plt.xlabel(\"Corr($x_{1},x_{2}$)\")\n", "plt.ylabel(\"pdf\")\n", "plt.show()"]}, {"cell_type": "markdown", "id": "2d0c24fc", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='exercises_22_5'></a>     \n", "\n", "| [Top](#section_22_0) | [Restart Section](#section_22_5) | [Next Section](#section_22_6) |\n"]}, {"cell_type": "markdown", "id": "bc957108", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 21.5.1</span>\n", "\n", "Which of the following statements best describes the purpose of bootstrapping?\n", "\n", "A) Bootstrapping is a technique for selecting a representative subset of the data to improve model training.\\\n", "B) Bootstrapping involves generating random datasets with subsets of the full input dataset in order to estimate the sampling distribution of a statistic.\\\n", "C) Bootstrapping is a method for normalizing the distribution of a dataset to ensure statistical validity.\\\n", "D) Bootstrapping is a process for identifying outliers in a dataset by iteratively removing extreme values.\n", "\n", "\n", "<br>"]}, {"cell_type": "markdown", "id": "5db3600f", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 21.5.2</span>\n", "\n", "Let's test a different distribution and compare the uncertainties on the mean and standard deviation with a boostrapping approach. In the code below, we first sample 1000 data points from a Landau distribution, plot the histogram, and calculate the mean and standard deviation, just for show.\n", "\n", "In the code that you must complete, repeat the direct sampling 50 times to estimate the overall mean and standard deviation, including their uncertainties. Then perform a 10,000-iteration bootstrap on the initial sample `vals` to estimate the mean and standard deviation with their uncertainties, and compare these results to those obtained from multiple sampling.\n", "\n", "Report the mean and uncertainty from direct sampling and the mean and uncertainty with bootstrapping as a list `[mu1, mu1_unc, mu2, mu2_unc]` with the precision of one significant digit.\n", "\n", "<br>"]}, {"cell_type": "code", "execution_count": null, "id": "077abce9", "metadata": {"tags": ["py", "draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L21.5.2\n", "\n", "from landaupy import landau\n", "\n", "# Sample the Landau distribution once and plot\n", "vals = landau.sample(10, 5, 1000)\n", "plt.hist(vals, bins=np.arange(0, 100, 2))\n", "plt.xlabel(\"x\")\n", "plt.ylabel(\"N\")\n", "plt.show()\n", "\n", "# Calculate the mean and standard deviation\n", "print(\"One Sample\")\n", "print(\"Mean:\", np.mean(vals), \" Std:\", np.std(vals))\n", "print(\"\")\n", "\n", "# Loop 50 times and compute the mean and uncertainty\n", "# of the sample mean and sample std\n", "samplemean = []\n", "samplestd = []\n", "for i in range(50):\n", "    #sample 1000 pts from a Landau distribution for each run\n", "    #append the lists with the mean and std from each run\n", "    #YOUR CODE HERE\n", "    \n", "print(\"Multiple Samples\")\n", "print(\"Mean from multiple samples:\", np.mean(samplemean), \"+/-\", np.std(samplemean))\n", "print(\"Std from multiple samples:\", np.mean(samplestd), \"+/-\", np.std(samplestd))\n", "print(\"\")\n", "\n", "\n", "# Bootstrap to get the uncertainty on the mean and standard deviation\n", "boot_means = []\n", "boot_stds = []\n", "for _ in range(10000):\n", "    boot_sample = # YOUR CODE HERE: Take a random sample each iteration\n", "    # YOUR CODE HERE: Append the mean to boot_means\n", "    # YOUR CODE HERE: Append the std to boot_stds\n", "\n", "print(\"Bootstrap\")  \n", "print(\"Bootstrap Mean:\", np.mean(boot_means), \"+/-\", np.std(boot_means))\n", "print(\"Bootstrap Std:\", np.mean(boot_stds), \"+/-\", np.std(boot_stds))\n", "\n", "\n"]}, {"cell_type": "markdown", "id": "813af5e1", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='section_22_6'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L21.6 Bootstrapping For Neural Networks</h2>  \n", "\n", "| [Top](#section_22_0) | [Previous Section](#section_22_5) |"]}, {"cell_type": "code", "execution_count": null, "id": "b39f95a6", "metadata": {"tags": ["lect_06", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.6-runcell01\n", "\n", "def makeDataet(iId,ixstep,iestep,iystep):\n", "    print(ixstep.shape,iestep.shape,iystep.shape)\n", "    outdata = np.hstack((ixstep,iystep,iestep))\n", "    outdata = outdata.reshape(1000,3,ixstep.shape[1])\n", "    return outdata\n", "\n", "def profile(iInput):\n", "    profile_out=np.sum(iInput,axis=3)\n", "    return profile_out\n", "\n", "out_profile150=profile(dimage150)\n", "out_profile200=profile(dimage200)\n", "out_profile250=profile(dimage250)\n", "out_profile300=profile(dimage300)\n", "\n", "test_150 = np.mean(out_profile150,axis=0)\n", "test_200 = np.mean(out_profile200,axis=0)\n", "test_250 = np.mean(out_profile250,axis=0)\n", "test_300 = np.mean(out_profile300,axis=0)\n", "\n", "test_150_std = np.std(out_profile150,axis=0)\n", "test_200_std = np.std(out_profile200,axis=0)\n", "test_250_std = np.std(out_profile250,axis=0)\n", "test_300_std = np.std(out_profile300,axis=0)\n", "\n", "test_150_stderr = np.std(out_profile150,axis=0)/np.sqrt(dimage150.shape[0])\n", "test_200_stderr = np.std(out_profile200,axis=0)/np.sqrt(dimage200.shape[0])\n", "test_250_stderr = np.std(out_profile250,axis=0)/np.sqrt(dimage250.shape[0])\n", "test_300_stderr = np.std(out_profile300,axis=0)/np.sqrt(dimage300.shape[0])\n", "\n", "plt.errorbar(np.arange(28),test_150.flatten(),yerr=test_150_std,fmt='o',label='150')\n", "plt.errorbar(np.arange(28),test_200.flatten(),yerr=test_200_std,fmt='o',label='200')\n", "plt.errorbar(np.arange(28),test_250.flatten(),yerr=test_250_std,fmt='o',label='250')\n", "plt.errorbar(np.arange(28),test_300.flatten(),yerr=test_300_std,fmt='o',label='300')\n", "plt.legend()\n", "plt.xlabel('distance(pixel)')\n", "plt.ylabel('Energy(MeV) standard deviation error')\n", "plt.show()\n", "\n", "plt.errorbar(np.arange(28),test_150.flatten(),yerr=test_150_stderr,fmt='o',label='150')\n", "plt.errorbar(np.arange(28),test_200.flatten(),yerr=test_200_stderr,fmt='o',label='200')\n", "plt.errorbar(np.arange(28),test_250.flatten(),yerr=test_250_stderr,fmt='o',label='250')\n", "plt.errorbar(np.arange(28),test_300.flatten(),yerr=test_300_stderr,fmt='o',label='300')\n", "plt.legend()\n", "plt.xlabel('distance(pixel)')\n", "plt.ylabel('Energy(MeV) standard devaition/$\\sqrt{N}$ error')\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "id": "98038f21", "metadata": {"tags": ["lect_06", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.6-runcell02\n", "\n", "def profileVar(iData,iNSample):\n", "    boot_profile = []\n", "    for _ in range(iNSample):\n", "        boot_sample = iData[np.random.choice(out_data.shape[0], 1000, replace=True)]\n", "        boot_prof   = np.mean(profile(boot_sample),axis=0)\n", "        boot_profile.append(boot_prof)\n", "    boot_profile = np.array(boot_profile) # transform it into a numpy array for calculation\n", "    return np.mean(boot_profile,axis=0),np.std(boot_profile,axis=0)\n", "\n", "Nsamps=1000\n", "dimage150_boot,dimage150_boot_err = profileVar(dimage150,Nsamps)\n", "dimage200_boot,dimage200_boot_err = profileVar(dimage200,Nsamps)\n", "dimage250_boot,dimage250_boot_err = profileVar(dimage250,Nsamps)\n", "dimage300_boot,dimage300_boot_err = profileVar(dimage300,Nsamps)\n", "\n", "#Uncomment to show all\n", "#plt.errorbar(np.arange(28),dimage150_boot.flatten(),yerr=dimage150_boot_err,fmt='o',label='150 boot')\n", "plt.errorbar(np.arange(28),dimage200_boot.flatten(),yerr=dimage200_boot_err,fmt='o',label='200 boot')\n", "#plt.errorbar(np.arange(28),dimage250_boot.flatten(),yerr=dimage250_boot_err,fmt='o',label='250 boot')\n", "#plt.errorbar(np.arange(28),dimage300_boot.flatten(),yerr=dimage300_boot_err,fmt='o',label='300 boot')\n", "\n", "#Uncomment to show all\n", "#plt.errorbar(np.arange(28),test_150.flatten(),yerr=test_150_stderr,fmt='o',label='150',alpha=0.5)\n", "plt.errorbar(np.arange(28),test_200.flatten(),yerr=test_200_stderr,fmt='o',label='200',alpha=0.5)\n", "#plt.errorbar(np.arange(28),test_250.flatten(),yerr=test_250_stderr,fmt='o',label='250',alpha=0.5)\n", "#plt.errorbar(np.arange(28),test_300.flatten(),yerr=test_300_stderr,fmt='o',label='300',alpha=0.5)\n", "\n", "plt.legend()\n", "plt.xlabel('distance(pixel)')\n", "plt.ylabel('Energy(MeV)')\n", "plt.show()\n", "\n", "print(\"errors from boostrap:\",dimage200_boot_err)\n", "print(\"errors from sqrt(N):\",test_200_stderr)"]}, {"cell_type": "code", "execution_count": null, "id": "bbcc99b3", "metadata": {"tags": ["lect_06", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.6-runcell03\n", "\n", "#Compute our variable\n", "def xmaxprofilecheck(iInput):\n", "    profile_out=np.sum(iInput,axis=2)\n", "    profile_out=np.reshape(profile_out,(iInput.shape[0],28))\n", "    #maxbin=np.argmax(profile_out,axis=1)\n", "    maxbin=np.unravel_index(np.argmax(profile_out, axis=1), profile_out.shape)\n", "    Ein=np.sum(profile_out[:,0:2],axis=1)\n", "    Eout=profile_out[maxbin]#+profile_out[:,maxbin+1]+profile_out[:,maxbin-1]\n", "    ratio=Eout/Ein\n", "    #print(Ein[0],Eout[0],Eout.shape)\n", "    return ratio\n", "\n", "#compute the mean and standard deviation\n", "def xmaxprofile(iInput):\n", "    ratio=xmaxprofilecheck(iInput)\n", "    return np.mean(ratio),np.std(ratio)\n", "\n", "#now bootstracp the profile and compute the meean and standar deviation\n", "def xmaxprofileVar(iData,iNSample):\n", "    boot_profile = []\n", "    for _ in range(iNSample):\n", "        boot_sample          = iData[np.random.choice(out_data.shape[0], 1000, replace=True)]\n", "        boot_prof,boot_std   = xmaxprofile(boot_sample)\n", "        boot_profile.append(boot_prof)\n", "    boot_profile = np.array(boot_profile) # transform it into a numpy array for calculation\n", "    #return np.mean(boot_profile,axis=0),np.std(boot_profile,axis=0)\n", "    return boot_profile\n", "\n", "xtest_150,xtest_150_std=xmaxprofile(dimage150)\n", "xtest_200,xtest_200_std=xmaxprofile(dimage200)\n", "xtest_250,xtest_250_std=xmaxprofile(dimage250)\n", "xtest_300,xtest_300_std=xmaxprofile(dimage300)\n", "print(xtest_200,xtest_200_std)\n", "\n", "xtest_150_stderr = xtest_150_std/np.sqrt(dimage150.shape[0])\n", "xtest_200_stderr = xtest_200_std/np.sqrt(dimage200.shape[0])\n", "xtest_250_stderr = xtest_250_std/np.sqrt(dimage250.shape[0])\n", "xtest_300_stderr = xtest_300_std/np.sqrt(dimage300.shape[0])\n", "\n", "Nsamps=1000\n", "dimage150_boot = xmaxprofileVar(dimage150,Nsamps)\n", "dimage200_boot = xmaxprofileVar(dimage200,Nsamps)\n", "dimage250_boot = xmaxprofileVar(dimage250,Nsamps)\n", "dimage300_boot = xmaxprofileVar(dimage300,Nsamps)\n", "\n", "#plt.hist(dimage150_boot.flatten(),density=True,label='150 boot',alpha=0.5)\n", "plt.hist(dimage200_boot.flatten(),density=True,label='200 bootstrap',alpha=0.5,bins=np.arange(0,15,0.5))\n", "#plt.hist(dimage250_boot.flatten(),density=True,label='250 boot',alpha=0.5,bins=np.arange(0,15,0.5))\n", "#plt.hist(dimage300_boot.flatten(),density=True,label='300 boot',alpha=0.5,bins=np.arange(0,15,0.5))\n", "\n", "#plt.hist(xtest_150.flatten(),label='150',alpha=0.5)\n", "plt.hist(xtest_200.flatten(),label='200 mean(single number)',alpha=0.5,bins=np.arange(0,15,0.5))\n", "#plt.hist(xtest_250.flatten(),label='250',alpha=0.5)\n", "#plt.hist(xtest_300.flatten(),label='300',alpha=0.5)\n", "\n", "\n", "xtest_200_check=xmaxprofilecheck(dimage200)\n", "plt.hist(xtest_200_check.flatten(),density=True,label='200 distribution',alpha=0.5,bins=np.arange(0,15,0.5))\n", "\n", "plt.legend()\n", "plt.xlabel('distance(pixel)')\n", "plt.ylabel('Energy(MeV)')\n", "plt.show()\n", "\n", "def printStats(ilabel,ival,ierr,iboot):\n", "    print(ilabel,\"Val:\",ival,\"+/-\",ierr,\"boot\",np.mean(iboot),\"+/-\",np.std(iboot))\n", "\n", "printStats(\"150 \",xtest_150,xtest_150_stderr,dimage150_boot)\n", "printStats(\"200 \",xtest_200,xtest_200_stderr,dimage200_boot)\n", "printStats(\"250 \",xtest_250,xtest_250_stderr,dimage250_boot)\n", "printStats(\"300 \",xtest_300,xtest_300_stderr,dimage300_boot)"]}, {"cell_type": "code", "execution_count": null, "id": "3b057226", "metadata": {"tags": ["lect_06", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.6-runcell04\n", "\n", "N=1000\n", "dlimage150 = generate(d,N,cvae_proton_image,1.5)\n", "dlimage200 = generate(d,N,cvae_proton_image,2.0)\n", "dlimage250 = generate(d,N,cvae_proton_image,2.5)\n", "dlimage300 = generate(d,N,cvae_proton_image,3.0)\n", "\n", "Nsamps=1000\n", "dlimage150_boot,dlimage150_boot_err = xmaxprofileVar(dlimage150,Nsamps)\n", "dlimage200_boot,dlimage200_boot_err = xmaxprofileVar(dlimage200,Nsamps)\n", "dlimage250_boot,dlimage250_boot_err = xmaxprofileVar(dlimage250,Nsamps)\n", "dlimage300_boot,dlimage300_boot_err = xmaxprofileVar(dlimage300,Nsamps)\n", "\n", "print(\"err:\",dlimage150_boot_err)\n", "\n", "#plt.errorbar(np.arange(28),dlimage150_boot.flatten(),yerr=dlimage150_boot_err,fmt='o',label='150')\n", "#plt.errorbar(np.arange(28),dlimage200_boot.flatten(),yerr=dlimage200_boot_err,fmt='o',label='200')\n", "#plt.errorbar(np.arange(28),dlimage250_boot.flatten(),yerr=dlimage250_boot_err,fmt='o',label='250')\n", "#plt.errorbar(np.arange(28),dlimage300_boot.flatten(),yerr=dlimage300_boot_err,fmt='o',label='300')\n", "\n", "#plt.errorbar(np.arange(28),test_150.flatten(),yerr=test_150_stderr,fmt='o',label='150',alpha=0.5)\n", "#plt.errorbar(np.arange(28),test_200.flatten(),yerr=test_200_stderr,fmt='o',label='200',alpha=0.5)\n", "#plt.errorbar(np.arange(28),test_250.flatten(),yerr=test_250_stderr,fmt='o',label='250',alpha=0.5)\n", "#plt.errorbar(np.arange(28),test_300.flatten(),yerr=test_300_stderr,fmt='o',label='300',alpha=0.5)\n", "\n", "plt.legend()\n", "plt.xlabel('distance(pixel)')\n", "plt.ylabel('Energy(MeV)')\n", "plt.show()\n"]}, {"cell_type": "code", "execution_count": null, "id": "7be2146f", "metadata": {"tags": ["lect_06", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.6-runcell05\n", "\n", "N=1000\n", "dlimage150 = generate_base(4,N,proton_vae_image)\n", "dlimage200 = generate(d,N,cvae_proton_image,2.0)\n", "#dlimage250 = generate(d,N,cvae_proton_image,2.5)\n", "#dlimage300 = generate(d,N,cvae_proton_image,3.0)\n", "\n", "Nsamps=1000\n", "xdlimage150_boot = xmaxprofileVar(dlimage150,Nsamps)\n", "xdlimage200_boot = xmaxprofileVar(dlimage200,Nsamps)\n", "#xdlimage250_boot = xmaxprofileVar(dlimage250,Nsamps)\n", "#xdlimage300_boot = xmaxprofileVar(dlimage300,Nsamps)\n", "\n", "print(\"err:\",dlimage150_boot_err)\n", "\n", "#plt.hist(xdlimage150_boot.flatten(),density=True,label='150 NN',alpha=0.5)\n", "#plt.hist(dimage150_boot.flatten(),density=True,label='150 MC',alpha=0.5)\n", "\n", "plt.hist(xdlimage200_boot.flatten(),density=True,label='200 NN',alpha=0.5)\n", "plt.hist(dimage200_boot.flatten(),density=True,label='200 MC',alpha=0.5)\n", "\n", "#plt.hist(xdlimage200_boot.flatten(),density=True,label='200',alpha=0.5)\n", "#plt.hist(xdlimage250_boot.flatten(),density=True,label='250',alpha=0.5)\n", "#plt.hist(xdlimage300_boot.flatten(),density=True,label='300',alpha=0.5)\n", "\n", "plt.hist(xtest_150.flatten(),label='150-avg',alpha=0.5)\n", "plt.hist(xtest_200.flatten(),label='200',alpha=0.5)\n", "plt.hist(xtest_250.flatten(),label='250',alpha=0.5)\n", "plt.hist(xtest_300.flatten(),label='300',alpha=0.5)\n", "\n", "plt.legend()\n", "plt.xlabel('distance(pixel)')\n", "plt.ylabel('Energy(MeV)')\n", "plt.show()\n"]}], "metadata": {"celltoolbar": "Tags", "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}