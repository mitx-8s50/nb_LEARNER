{"cells": [{"cell_type": "markdown", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<hr style=\"height: 1px;\">\n", "<i>This notebook was authored by the 8.S50x Course Team, Copyright 2022 MIT All Rights Reserved.</i>\n", "<hr style=\"height: 1px;\">\n", "<br>\n", "\n", "<h1>Lesson 22: Markov Chain Monte Carlo - Part I</h1>\n", "\n"]}, {"cell_type": "markdown", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='section_23_0'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L22.0 Overview</h2>\n"]}, {"cell_type": "markdown", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<h3>Navigation</h3>\n", "\n", "<table style=\"width:100%\">\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_23_1\">L22.1 Markov Chain MC</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_23_1\">L22.1 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_23_2\">L22.2 Understanding some details</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_23_2\">L22.2 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_23_3\">L22.3 A more realistic Markov Chain MC</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_23_3\">L22.3 Exercises</a></td>\n", "    </tr>\n", "</table>"]}, {"cell_type": "markdown", "metadata": {"tags": ["md", "catsoop_00", "learner"]}, "source": ["<h3>Learning Objectives</h3>\n", "\n", "Building upon our work with Monte-Carlo and simulation, we now look at the scenario when our simulation is not perfect. Nonetheless, we have ways to check whether it is perfect, and we will adjust the simulation on the fly to correct it. This approach is amenable to fitting data with complex models as well. This leads to the Markov-Chain Process that we will elaborate on in detail in this lecture. "]}, {"cell_type": "markdown", "metadata": {"tags": ["md", "catsoop_00", "learner"]}, "source": ["<h3>Slides</h3>\n", "\n", "You can access the slides related to this lecture at the following link: <a href=\"https://github.com/mitx-8s50/slides/raw/main/module3_slides/L23_slides.pdf\" target=\"_blank\">L23 Slides</a>"]}, {"cell_type": "markdown", "metadata": {"tags": ["md", "learner"]}, "source": ["<h3>Data</h3>\n", "\n", "Download the data from the following directory. Reference below:\n", "\n", ">description: EPICA Dome C Ice Core 800KYr Deuterium Data and Temperature Estimates.<br>\n", ">source:  https://www.ncei.noaa.gov/pub/data/paleo/icecore/antarctica/epica_domec/edc3deuttemp2007.txt<br>\n", ">attribution: Jouzel, J., et al.  2007.\n", "EPICA Dome C Ice Core 800KYr Deuterium Data and Temperature Estimates. \n", "IGBP PAGES/World Data Center for Paleoclimatology \n", "Data Contribution Series # 2007-091.\n", "NOAA/NCDC Paleoclimatology Program, Boulder CO, USA."]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["py", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L22.0-runcell00\n", "\n", "!git init\n", "!git remote add -f origin https://github.com/mitx-8s50/nb_LEARNER/\n", "!git config core.sparseCheckout true\n", "!echo 'data/L23' >> .git/info/sparse-checkout\n", "!git pull origin main\n"]}, {"cell_type": "markdown", "metadata": {"tags": ["md", "learner"]}, "source": ["<h3>Installing Tools</h3>\n", "\n", "Before we do anything, let's make sure we install the tools we need."]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["py", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L22.0-runcell01\n", "\n", "!pip install corner\n", "!pip install lmfit\n", "!pip install bilby\n", "!pip install gwpy lalsuite"]}, {"cell_type": "markdown", "metadata": {"tags": ["md", "learner"]}, "source": ["<h3>Importing Libraries</h3>\n", "\n", "Before beginning, run the cell below to import the relevant libraries for this notebook. "]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["py", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L22.0-runcell01\n", "\n", "import imageio\n", "from PIL import Image\n", "\n", "import lmfit\n", "import numpy as np\n", "import torch\n", "import torch.nn as nn\n", "import matplotlib.pyplot as plt\n", "import csv\n", "import math\n", "from scipy import optimize as opt\n", "from scipy import stats\n", "import matplotlib.cm as cm\n", "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n", "import corner\n", "\n", "import bilby\n", "import scipy.signal as sig\n", "from bilby.gw.source import lal_binary_black_hole\n", "from bilby.gw.conversion import convert_to_lal_binary_black_hole_parameters"]}, {"cell_type": "markdown", "metadata": {"tags": ["md", "learner"]}, "source": ["<h3>Setting Default Figure Parameters</h3>\n", "\n", "The following code cell sets default values for figure parameters.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["py", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L22.0-runcell02\n", "\n", "#set plot resolution\n", "%config InlineBackend.figure_format = 'retina'\n", "\n", "#set default figure parameters\n", "plt.rcParams['figure.figsize'] = (9,6)\n", "\n", "medium_size = 12\n", "large_size = 15\n", "\n", "plt.rc('font', size=medium_size)          # default text sizes\n", "plt.rc('xtick', labelsize=medium_size)    # xtick labels\n", "plt.rc('ytick', labelsize=medium_size)    # ytick labels\n", "plt.rc('legend', fontsize=medium_size)    # legend\n", "plt.rc('axes', titlesize=large_size)      # axes title\n", "plt.rc('axes', labelsize=large_size)      # x and y labels\n", "plt.rc('figure', titlesize=large_size)    # figure title"]}, {"cell_type": "markdown", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='section_23_1'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L22.1 Markov Chain Monte Carlo </h2>  \n", "\n", "| [Top](#section_23_0) | [Previous Section](#section_23_0) | [Exercises](#exercises_23_1) | [Next Section](#section_23_2) |\n"]}, {"cell_type": "markdown", "metadata": {"tags": ["md", "lect_01", "learner"]}, "source": ["*The material in this section is discussed in the videos **<a href=\"https://courses.mitxonline.mit.edu/learn/course/course-v1:MITxT+8.S50.3x+3T2023/block-v1:MITxT+8.S50.3x+3T2023+type@sequential+block@seq_LS22/block-v1:MITxT+8.S50.3x+3T2023+type@vertical+block@vert_LS22_vid1\" target=\"_blank\">HERE</a>.** You are encouraged to watch that video and use this notebook concurrently.*"]}, {"cell_type": "markdown", "metadata": {"tags": ["md", "lect_01", "learner"]}, "source": ["<h3>Overview</h3>\n", "\n", "Markov Chain Monte Carlo (MCMC) is a computational method used for sampling from complex probability distributions, especially when direct sampling or analytical methods are not feasible. Its key components include the following:\n", "\n", "1. A **Markov Chain** is a sequence of random variables where the probability distribution of each variable depends only on the state of the previous one. The \"Markov\" property means that the future state depends only on the current state, not on the sequence of events that preceded it.\n", "\n", "\n", "2. The key to MCMC's success is satisfying the **detailed balance** condition. In simple terms, the probability of transitioning from state A to state B must be the same as transitioning from state B to state A. This ensures that the Markov chain converges to the desired distribution.\n", "\n", "\n", "3. The MCMC method has an initial phase, known as the **burn-in** period, which allows the Markov chain to explore the state space and reach a region where the samples are representative of the target distribution. Samples obtained during the burn-in phase are typically discarded.\n", "\n", "\n", "4. Once the Markov Chain is considered to be in a stationary state, subsequent **samples are collected.** These samples can be used to approximate the desired distribution and estimate parameters of interest."]}, {"cell_type": "markdown", "metadata": {"tags": ["md", "lect_01", "learner"]}, "source": ["<h3>A simple example</h3>\n", "\n", "To understand Markov Chain Monte Carlo, we are going to sample a normal distribution, and then **we are going to use a Markov Chain MC to fit this normal distribution.** While this seems like a somewhat trivial example, the point here is to illustrate a basic example of how MCMC attempts to model parameters. \n", "\n", "Later on, we will see that, while MCMC somewhat painstakingly extracts parameters for fits, it can be used to perform modeling of complex processes that other approaches cannot do because they lack the same stability.\n", "\n", "We will start our Markov Chain MC by creating a toy dataset, sampling 1000 events from a Gaussian with a mean of 50 and width of 20."]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["py", "lect_01", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L22.1-runcell01\n", "\n", "nsample=1000\n", "values=np.random.normal(50,20,nsample)\n", "fig = plt.figure(figsize=(10,10))\n", "plt.hist(values,bins=50)\n", "plt.xlabel(\"x\")\n", "plt.ylabel(\"N\")\n"]}, {"cell_type": "markdown", "metadata": {"tags": ["lect_01", "learner"]}, "source": ["Normally, we would get the parameters describing this distribution by fitting a Gaussian. This would involve minimizing the loss:\n", "\n", "\\begin{eqnarray}\n", "\\log\\left(\\mathcal{L}\\right) & = & \\sum_{i} \\log\\left(\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}} e^{-\\dfrac{\\left(\\mu-x_{i}\\right)^2}{\\sigma^2}}\\right)\\\\\n", "& = & \\sum_{i}\\left(\\frac{x_{i}-\\mu}{\\sigma}\\right)^2 - \\frac{1}{2}\\log\\left(2\\pi\\sigma^2\\right)\n", "\\end{eqnarray}\n", "\n", "However, what if we don't know how to compute the gradient for the above loss function? In that case, we can just compute the Log Likelihood, $\\log(p_{i})$ for two randomly chosen sets of parameters, and keep the second set if $\\log(p_{i})$ increases. If it does not increase, we will resample the parameters with some sampling policy and try again.\n", "\n", "Now, what we are going to do is try to extract the mean and RMS of this distribution of data. The way we will do this is with a multi-step process, whereby we:\n", "\n", " * Define a Likelihood $p_{i}$ for the agreement between the prediction and the data\n", " * Define a proposal distribution from which to sample to get best fit parameters\n", "   * Note this proposal distribution can be anything (we'll play around with different options)\n", " * Sample the proposal distribution to get an initial guess of the parameters ($\\vec{\\theta}$)\n", " * Sample the proposal distribution again to get a second paramter set ($\\vec{\\theta^\\prime}$)\n", "   * Compute the ratio of the likelihoods of these two parameter sets to find a proposal weight $s_{\\rm check}$:\n", "$$\n", "s_{\\rm accept} = \\frac{p_{\\rm sampled} (\\vec{\\theta^\\prime})}{p_{\\rm current} (\\vec{\\theta})}\n", "$$\n", "  * If $s_{\\rm accept}\\gt 1$, accept $\\vec{\\theta^{\\prime}}$ as the new parameter set, otherwise\n", "    * Sample a uniform distribution between 0 and 1 $\\rightarrow s_{\\rm check}$\n", "    * If  $s_{\\rm accept} \\gt s_{\\rm check}$ accept $\\vec{\\theta^{\\prime}}$ as the new parameter set\n", "    * For example, if $s_{\\rm accept} = 0.5$, we would keep $\\vec{\\theta^{\\prime}}$ as the new \"best\" set of parameters 50\\% of the time.\n", "  * Repeat the above until the parameter set $\\vec{\\theta^{\\prime}}$ converges\n", "  * Once it equilibrates, use the final $\\vec{\\theta^{\\prime}}$ to generate a posterior\n", "  \n", "This allows us to get a best fit to data without doing any actual fitting. Note that our likelihood doesn't need to be a true likelihood. It could be solving a differential equation, or minimizing some other thing. Also, it doesn't need to be differentiable, we just need something that gives us an indication of a better fit."]}, {"cell_type": "markdown", "metadata": {"tags": ["lect_01", "learner"]}, "source": ["**Fitting the data**\n", "\n", "Ok, let's now step through and try to fit the random data that we generated. First, we will define the Log Likelihood function shown above as the probability that we wish to maximize."]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["lect_01", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L22.1-runcell02\n", "\n", "def log_like_normal(x,data):\n", "    #x[0]=mu, x[1]=sigma (new or current)\n", "    #data = the observation\n", "    return np.sum(np.log(stats.norm(x[0],x[1]).pdf(data)))\n"]}, {"cell_type": "markdown", "metadata": {"tags": ["lect_01", "learner"]}, "source": ["Now, what we want to do is choose a **Proposal Distribution** to sample $\\vec{\\theta^{\\prime}}$. The key here is to make sure our proposal distribution covers the possible values for $\\mu$ and $\\sigma$ that match our data, otherwise we will never converge. One way to do this is to make our **Proposal Distribution** a function of our inputs.\n", "\n", "As a first example, let's start with the current proposed values of the mean and width $\\vec{\\theta} = [\\mu,\\sigma]$ and generate $\\vec{\\theta^{\\prime}}$ by sampling a flat distribution between $x_{i} - \\sigma$ and  $x_{i} + \\sigma$, where $x_{i}$ is either the current proposed values of $\\mu$ or $\\sigma$.\n", "\n", "Try running the code cell below multiple times to see how the values of $\\vec{\\theta^{\\prime}}$ and its associated likelihood vary. Notice that values of $\\vec{\\theta^{\\prime}}$ closer to [50,20] haver larger (i.e. less negative) likelihoods."]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["lect_01", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L22.1-runcell03\n", "\n", "def proposal(x):\n", "    #x[0] = mu, x[1]=sigma (new or current)\n", "    x_new = np.array([0,0])\n", "    x_new = np.random.uniform(x-x[1]*np.ones(x.shape),x+x[1]*np.ones(x.shape))\n", "    return x_new\n", "\n", "#Let's run a quick test\n", "xinit=np.array([25,10])\n", "likeOld=log_like_normal(xinit,values)\n", "xtry=proposal(xinit)\n", "likeNew=log_like_normal(xtry,values)\n", "print(\"Init:\",xinit, \"Likelihood:\",likeOld)\n", "print(\"Try:\" ,xtry , \"Likelihood:\",likeNew)"]}, {"cell_type": "markdown", "metadata": {"tags": ["lect_01", "learner"]}, "source": ["Now, we need to translate our likelihood to a p-value and convert it to an accept block to define how our parameters will migrate over time. Let's go ahead and define an accept block. Given that we are using $\\log(\\mathcal{L})$, we need to translate this from $\\log(p)\\rightarrow p$, which we can do just by exponentiating.\n", "\n", "In other words (note, the notation below is different than what is presented in the corresponding video):\n", "\n", "$$\n", "s_{\\rm accept} = \\frac{p_{\\rm new} (\\vec{\\theta^\\prime})}{p_{\\rm old} (\\vec{\\theta})} \\\\\n", "s_{\\rm accept} = e^{\\large\\left(\\log\\left(\\mathcal{L}_{\\rm new}\\right) - \\log\\left(\\mathcal{L}_{\\rm old}\\right)\\right)}\n", "$$\n", "\n", "Finally, we can add constraints or priors to our sampled $\\vec{\\theta^{\\prime}}$ values. This leads to a modified acceptance probability, where we inject priors into our fit by:\n", "\n", "$$\n", "\\begin{align}\n", "s_{\\rm accept} &= \\frac{p_{\\rm new} (\\vec{\\theta^\\prime}){\\rm prior(\\vec{\\theta^\\prime}})}{p_{\\rm old} (\\vec{\\theta}){\\rm prior(\\vec{\\theta}})} \\\\\n", "&= e^{\\large\\left(\\log\\left(\\mathcal{L}_{\\rm new}\\right) - \\log\\left(\\mathcal{L}_{\\rm old}\\right)\\right)}\n", "\\end{align}\n", "$$\n", "\n", "Note that we get the same final equation as before. The difference is that we can use constraints from the prior to reject some of the  $\\vec{\\theta^{\\prime}}$ parameter sets that our sampling produces. As one example, code cell `L22.1-runcell04` rejects any samples which produce a negative value for sigma.\n", "\n", "Try running multiple instances of code cell `L22.1-runcell03` followed by `L22.1-runcell04` to see which sets $\\vec{\\theta^{\\prime}}$ are accepted."]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["lect_01", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L22.1-runcell04\n", "\n", "#note, the notation below is different than what is presented in the corresponding video\n", "\n", "\n", "#Defines whether to accept or reject the new sample\n", "def acceptance(likeOld, likeNew):\n", "    if likeNew>likeOld:\n", "        return True\n", "    else:\n", "        accept=np.random.uniform(0,1)\n", "        return (accept < (np.exp(likeNew-likeOld)))\n", "\n", "def prior(like,x):\n", "    #Adjust the likelihood by the prior\n", "    prior=1\n", "    if(x[1] <=0):\n", "        prior=0\n", "    return like+np.log(prior) #log(1)=0 so nothing gets added, log(0)=-infinity so this case always gets rejected\n", "\n", "print(\"Init Prior:\",prior(likeOld,xinit),\"Try Prior:\",prior(likeNew,xtry))\n", "print(\"Accept:\",acceptance(prior(likeOld,xinit),prior(likeNew,xtry)))"]}, {"cell_type": "markdown", "metadata": {"tags": ["lect_01", "learner"]}, "source": ["Ok, now let's set up the full Markov-Chain Monte Carlo chain. By the way, there are many different Markov Chain Monte Carlo procedures. The one that we will implement below is known as the <a href=\"https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm\" target=\"_blank\">Metropolis-Hastings algorithm</a>, named after Nicholas Metropolis and W.K. Hastings.\n", "\n", "Let's write it all out and see how it works. In this example, we run 15,000 iterations of finding and checking new parameter sets. Note that, as for the examples above, we are using starting values $\\vec{\\theta} = [25,10]$ which were deliberately chosen not to be too close or too far from the parameters used to generate the data. To see how sensitve the MCMC procedure is to this choice, try values that are farther away from the truth."]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["lect_01", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L22.1-runcell05\n", "\n", "def metropolis_hastings(iLikelihood,iPrior,iProposal,iAcceptance,xinit,data,niterations):\n", "    x = xinit\n", "    accepted = []\n", "    rejected = []\n", "    likelihood = []\n", "    for i in range(niterations):\n", "        x_new   =  iProposal(x)  \n", "        likeOld = iLikelihood(x,data)\n", "        likeNew = iLikelihood(x_new,data) \n", "        if (iAcceptance(iPrior(likeOld,x),iPrior(likeNew,x_new))):            \n", "            x = x_new\n", "            accepted.append(x_new)\n", "            likelihood.append(likeNew)\n", "        else:\n", "            rejected.append(x_new)\n", "    accepted = np.array(accepted)\n", "    rejected = np.array(rejected)\n", "    likelihood = np.array(likelihood)\n", "    return accepted, rejected, likelihood\n", "\n", "xinit = np.array([25,10])\n", "accepted, rejected, likelihood = metropolis_hastings(log_like_normal,prior,proposal,acceptance,xinit,values,15000)"]}, {"cell_type": "markdown", "metadata": {"tags": ["lect_01", "learner"]}, "source": ["Now, let's plot the results:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["lect_01", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L22.1-runcell06\n", "\n", "#PLOT SIGMA VALUES\n", "fig = plt.figure(figsize=(10,10))\n", "ax1 = fig.add_subplot(3,1,1)\n", "print(rejected[0:50][0])\n", "\n", "ax1.plot(rejected[0:50,1], 'rx', label='Rejected sigma',alpha=0.5)\n", "ax1.plot(accepted[0:50,1], 'b.', label='Accepted sigma',alpha=0.5)\n", "ax1.set_xlabel(\"Iteration\")\n", "ax1.set_ylabel(\"$\\sigma$\")\n", "ax1.grid()\n", "ax1.legend()\n", "\n", "\n", "ax2 = fig.add_subplot(3,1,2)\n", "#to_show=-accepted.shape[0]\n", "ax2.plot( rejected[:,1], 'rx', label='Rejected sigma',alpha=0.5)\n", "ax2.plot( accepted[:,1], 'b.', label='Accepted sigma',alpha=0.5)\n", "ax2.set_xlabel(\"Iteration\")\n", "ax2.set_ylabel(\"$\\sigma$\")\n", "ax2.grid()\n", "ax2.legend()\n", "\n", "ax3 = fig.add_subplot(3,1,3)\n", "ax3.plot( likelihood, 'rx', label='Likelihood',alpha=0.5)\n", "ax3.set_xlabel(\"Iteration\")\n", "ax3.set_ylabel(\"$\\mathcal{L}$\")\n", "\n", "fig.tight_layout()\n", "accepted.shape\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["lect_01", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L22.1-runcell07\n", "\n", "#PLOT MU VALUES\n", "fig = plt.figure(figsize=(10,10))\n", "ax1 = fig.add_subplot(3,1,1)\n", "print(rejected[0:50][0])\n", "\n", "ax1.plot(rejected[0:50,0], 'rx', label='Rejected mu',alpha=0.5)\n", "ax1.plot(accepted[0:50,0], 'b.', label='Accepted mu',alpha=0.5)\n", "ax1.set_xlabel(\"Iteration\")\n", "ax1.set_ylabel(\"$\\mu$\")\n", "ax1.grid()\n", "ax1.legend()\n", "\n", "\n", "ax2 = fig.add_subplot(3,1,2)\n", "ax2.plot( rejected[:,0], 'rx', label='Rejected mu',alpha=0.5)\n", "ax2.plot( accepted[:,0], 'b.', label='Accepted mu',alpha=0.5)\n", "ax2.set_xlabel(\"Iteration\")\n", "ax2.set_ylabel(\"$\\mu$\")\n", "ax2.grid()\n", "ax2.legend()\n", "\n", "ax3 = fig.add_subplot(3,1,3)\n", "ax3.plot( likelihood, 'rx', label='Likelihood',alpha=0.5)\n", "ax3.set_xlabel(\"Iteration\")\n", "ax3.set_ylabel(\"$\\mathcal{L}$\")\n", "\n", "fig.tight_layout()\n", "accepted.shape\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"tags": ["lect_01", "learner"]}, "source": ["As you can see, all of the samples tried after less than about 50 iterations get rejected (this seems incredibly inefficient). Let's look at our best fit parameters."]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["lect_01", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L22.1-runcell07\n", "\n", "_,bins,_ = plt.hist(rejected[:,1],bins=35,density=True,label='reject',alpha=0.5)\n", "_,bins,_ = plt.hist(accepted[:,1],bins=bins,density=True,label='accept',alpha=0.5)\n", "_,bins,_ = plt.hist(accepted[-20:,1],bins=bins,density=True,label='accept(last 20)',alpha=0.5)\n", "plt.xlabel(\"$\\sigma$\")\n", "plt.ylabel(\"pdf\")\n", "plt.legend()\n", "plt.show()\n", "\n", "_,bins,_ = plt.hist(rejected[:,0],bins=35,density=True,label='reject',alpha=0.5)\n", "_,bins,_ = plt.hist(accepted[:,0],bins=bins,density=True,label='accept',alpha=0.5)\n", "_,bins,_ = plt.hist(accepted[-20:,0],bins=bins,density=True,label='accept(last 20)',alpha=0.5)\n", "plt.xlabel(\"$\\mu$\")\n", "plt.ylabel(\"pdf\")\n", "plt.legend()\n", "plt.show()\n", "\n", "print(\"Average and stdev of all accepted mu:\",accepted[:,0].mean(),\"+/-\",accepted[:,0].std())\n", "print(\"Average and stdev of all accepted sigma:\",accepted[:,1].mean(),\"+/-\",accepted[:,1].std())\n", "\n", "print(\"Average and stdev of last 20 accepted mu:\",accepted[-20:,0].mean(),\"+/-\",accepted[-10:,0].std())\n", "print(\"Average and stdev of last 20 accepted sigma:\",accepted[-20:,1].mean(),\"+/-\",accepted[-10:,1].std())\n"]}, {"cell_type": "markdown", "metadata": {"tags": ["lect_01", "learner"]}, "source": ["Now, let's compare these results with those found using an analytic computation, as well as a regular fit."]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["lect_01", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L22.1-runcell09\n", "\n", "##Analytic\n", "print(\"Analytic results for mean and standard deviation of the data:\")\n", "print(\"Mu:\",values.mean(),\"+/-\",values.std()/np.sqrt(len(values)))\n", "print(\"Sigma:\",values.std(),\"+/-\",values.std()/np.sqrt(2.*len(values)))\n", "print()\n", "\n", "y,bin_edges=np.histogram(values,bins=35)\n", "bin_centers = 0.5*(bin_edges[1:] + bin_edges[:-1])\n", "#lmfit\n", "from lmfit.models import GaussianModel\n", "model = GaussianModel()\n", "params = model.make_params(center=25, amplitude=1, sigma=10)\n", "result = model.fit(y, params, x=bin_centers,weights=1./np.sqrt(y+1))\n", "result.plot()\n", "print(\"Fitted results for mean (\\\"center\\\") and standard deviation (\\\"sigma\\\") of the data:\")\n", "print(result.fit_report())"]}, {"cell_type": "markdown", "metadata": {"tags": ["lect_01", "learner"]}, "source": ["Note that the results shown above use 3 different ways of calculating the uncertainties. For the MCMC, the uncertainties are simply the standard deviations of the accepted values (for either all of them or only the last 10). For the analytic calculations, the theoretical uncertainties in the mean and standard deviation for a sample of size $n$ are listed:\n", "\n", "$$\n", "\\sigma_{mean}=\\sigma/\\sqrt{n}\\\\  \n", "\\sigma_{\\sigma}=\\sigma/\\sqrt{2n}\n", "$$\n", "\n", "Finally, for the fit, the variations are found as a part of the fitting process itself.\n", "\n", "Now, we can try to to improve the Markov Chain so that it doesn't take a ridiculous number of iterations to get to some level of convergence. The simplest approach to accomplish this is to change our sampling proposal. In the example above, we simply varied the parameters over a broad uniform distribution of values. In the example below, we will change the sampling to something much more optimal. Specifically, we will get new proposed means and sigmas by starting with the existing values and varying them by a small fraction of their uncertainties as listed above. We'll chose that fraction using a normal distribution of mean 0 and width 1. That way, we limit how far $\\vec{\\theta^\\prime}$ can deviate from $\\vec{\\theta}$. The small deviations will allow us to slowly crawl to the best fit solution.\n", "\n", "Once we are there, we will use this sampling procedure to build an uncertainty profile of the various parameters by continuing to vary the parameters and running the MCMC acceptance step. Parameters, for which the likelihood is better will always be accepted, and parameters where teh p-value is comparable, but worse to the previous set of parameters will be rejected following the MCMC sampling.   "]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["lect_01", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L22.1-runcell10\n", "\n", "def proposal(x,n=1000):\n", "    #x[0] = mu, x[1]=sigma (new or current)\n", "    x_new     = x.copy()\n", "    x_new[0]  = x[0] + np.random.randn()*x[1]/np.sqrt(n)\n", "    x_new[1]  = x[1] + np.random.randn()*x[1]/np.sqrt(2*n)\n", "    return x_new\n", "\n", "xinit = np.array([25.,10.])\n", "accepted, rejected,likelihood = metropolis_hastings(log_like_normal,prior,proposal,acceptance,xinit,values,15000)"]}, {"cell_type": "markdown", "metadata": {"tags": ["lect_01", "learner"]}, "source": ["Again, let's plot the behavior:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["lect_01", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L22.1-runcell11\n", "\n", "plt.plot(likelihood)\n", "plt.xlabel(\"Iteration\")\n", "plt.ylabel(\"Likelihood\")\n", "plt.ylim(-4500,-4300)\n", "plt.show()\n", "\n", "_,bins,_ = plt.hist(rejected[:,1],bins=35,density=True,label='reject',alpha=0.5)\n", "_,bins,_ = plt.hist(accepted[:,1],bins=bins,density=True,label='accept',alpha=0.5)\n", "_,bins,_ = plt.hist(accepted[-20:,1],bins=bins,density=True,label='accept(last 20)',alpha=0.5)\n", "plt.xlabel(\"$\\sigma$\")\n", "plt.ylabel(\"pdf\")\n", "plt.legend()\n", "plt.show()\n", "\n", "_,bins,_ = plt.hist(rejected[:,0],bins=35,density=True,label='reject',alpha=0.5)\n", "_,bins,_ = plt.hist(accepted[:,0],bins=bins,density=True,label='accept',alpha=0.5)\n", "_,bins,_ = plt.hist(accepted[-20:,0],bins=bins,density=True,label='accept(last 20)',alpha=0.5)\n", "plt.xlabel(\"$\\mu$\")\n", "plt.ylabel(\"pdf\")\n", "plt.legend()\n", "plt.show()\n", "\n", "print(\"Average and stdev of all accepted mu:\",accepted[:,0].mean(),\"+/-\",accepted[:,0].std())\n", "print(\"Average and stdev of all accepted sigma:\",accepted[:,1].mean(),\"+/-\",accepted[:,1].std())\n", "\n", "print(\"Average and stdev of last 1000 accepted mu:\",accepted[-1000:,0].mean(),\"+/-\",accepted[-1000:,0].std())\n", "print(\"Average and stdev of last 1000 accepted sigma:\",accepted[-1000:,1].mean(),\"+/-\",accepted[-1000:,1].std())\n", "\n", "\n", "fig = plt.figure(figsize=(10,10))\n", "ax = fig.add_subplot(2,1,1)\n", "ax.plot(rejected[0:150,1], 'rx', label='Rejected',alpha=0.5)\n", "ax.plot(accepted[0:150,1], 'b.', label='Accepted',alpha=0.5)\n", "ax.set_xlabel(\"Iteration\")\n", "ax.set_ylabel(\"$\\sigma$\")\n", "ax.grid()\n", "ax.legend()\n", "\n", "\n", "ax2 = fig.add_subplot(2,1,2)\n", "#to_show=-accepted.shape[0]\n", "ax2.plot( rejected[:,1], 'rx', label='Rejected',alpha=0.5)\n", "ax2.plot( accepted[:,1], 'b.', label='Accepted',alpha=0.5)\n", "ax2.set_xlabel(\"Iteration\")\n", "ax2.set_ylabel(\"$\\sigma$\")\n", "ax2.grid()\n", "ax2.legend()\n", "\n", "\n", "\n", "fig = plt.figure(figsize=(10,10))\n", "ax = fig.add_subplot(2,1,1)\n", "ax.plot(rejected[0:150,0], 'rx', label='Rejected',alpha=0.5)\n", "ax.plot(accepted[0:150,0], 'b.', label='Accepted',alpha=0.5)\n", "ax.set_xlabel(\"Iteration\")\n", "ax.set_ylabel(\"$\\mu$\")\n", "ax.grid()\n", "ax.legend()\n", "\n", "\n", "ax2 = fig.add_subplot(2,1,2)\n", "#to_show=-accepted.shape[0]\n", "ax2.plot( rejected[:,0], 'rx', label='Rejected',alpha=0.5)\n", "ax2.plot( accepted[:,0], 'b.', label='Accepted',alpha=0.5)\n", "ax2.set_xlabel(\"Iteration\")\n", "ax2.set_ylabel(\"$\\mu$\")\n", "ax2.grid()\n", "ax2.legend()\n", "\n"]}, {"cell_type": "markdown", "metadata": {"tags": ["lect_01", "learner"]}, "source": ["Now our best fit looks much better in the sense that we have many accepts. In fact we have so many accepts that we have more than our rejects, this is why we see the acceptance list is longer than the rejected list. Note that the iterations are counted separate for reject and accept, so we have a total of 15k iterations, which is the sum of the roughly 8k accepted iteartions and 7k rejects. Clearly, we see that our accepted rate is quite high. You can see that there is an early stage before we get to equilibration. This stage is typically referred to as the burn-in.\n"]}, {"cell_type": "markdown", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='exercises_23_1'></a>     \n", "\n", "| [Top](#section_23_0) | [Restart Section](#section_23_1) | [Next Section](#section_23_2) |\n"]}, {"cell_type": "markdown", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-22.1.1</span>\n", "\n", "What happens when your proposal function gets too narrow or too wide? Edit the function `proposal_1` in the starting code shown below to try the fit with a range for finding $\\vec{\\theta^{\\prime}}$ (called `x_new` in the code) that is a factor of 10 smaller than that used in code cell `L22.1-runcell09`, and edit `proposal_2` to try with a range 10X larger. Let's focus specifically on the uncertainties in the final values of the parameters as calculated using the standard deviation of the accepted parameter sets near the end of the iterations. What changes do you observe? You could also plot the distributions of accepted and rejected points vs. iteration, to gain further insight (as done above).\n", "\n", "Try several runs to check whether or not you see a clear trend.\n", "\n", "A) The uncertainties that are computed do not change at all.\\\n", "B) The uncertainties change from run to run, but do not seem to have a consistent dependence on the proposal that is used.\\\n", "C) The uncertainties depend on the proposal that is used, and seem to be positively correlated, meaning that the computed uncertainty increases when a wider proposal function is used.\\\n", "D) The uncertainties depend on the proposal that is used, and seem to be negatively correlated (anticorrelated), meaning that the computed uncertainty decreases when a wider proposal function is used.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["py", "draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L22.1.1\n", "\n", "def proposal_1(x,n=2000):\n", "    #YOUR CODE HERE\n", "    return x_new\n", "\n", "xinit = np.array([25.,10.])\n", "accepted_1, rejected_1, _ = metropolis_hastings(log_like_normal,prior,proposal_1,acceptance,xinit,values,5000)\n", "\n", "print(\"1/10 original uncertainty\")\n", "print(\"Length of last 1000 accepted:\",len(accepted_1[-1000:,1]))\n", "print(\"Average and stdev of last 1000 accepted mu:\",accepted_1[-1000:,0].mean(),\"+/-\",accepted_1[-1000:,0].std())\n", "print(\"Average and stdev of last 1000 accepted sigma:\",accepted_1[-1000:,1].mean(),\"+/-\",accepted_1[-1000:,1].std())\n", "print()\n", "\n", "def proposal_2(x,n=2000):\n", "    #YOUR CODE HERE\n", "    return x_new\n", "\n", "xinit = np.array([25.,10.])\n", "accepted_2, rejected_2, _ = metropolis_hastings(log_like_normal,prior,proposal_2,acceptance,xinit,values,5000)\n", "\n", "\n", "print(\"10X original uncertainty\")\n", "print(\"Length of last 1000 accepted:\",len(accepted_2[-1000:,1]))\n", "print(\"Average and stdev of last 1000 accepted mu:\",accepted_2[-1000:,0].mean(),\"+/-\",accepted_2[-1000:,0].std())\n", "print(\"(Average and stdev of last 1000 accepted sigma:\",accepted_2[-1000:,1].mean(),\"+/-\",accepted_2[-1000:,1].std())\n", "print()\n", "\n", "\n", "#PLOT REJECTED VS. ACCEPTED\n", "#YOUR CODE HERE (if you want)"]}, {"cell_type": "markdown", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-22.1.2</span>\n", "\n", "Let's now see what happens when we use a smaller number of events to calculate the parameters and uncertainties. Using your definitions for `proposal_1` and `proposal_2` that you had above, change the final number of events you sample to take just the last 100 events? Play with the results, which answer gives you the correct result (note the cramer-rao bound holds).\n", "\n", "A) The uncertainties on both are fine.\\\n", "B) Taking the larger range is good for a wide proposal, and the smaller range is good for a narrow proposal. \\\n", "C) Taking the larger range is good for a narrow proposal, and the smaller range is good for a wide proposal. \\\n", "D) A smaller range is needed for the wide proposal because of turn on, while the narrow proposal gives uncertainties that are too small (below the Cramer-Rao bound) because it is sampling parameters with too small a proposal distribution. \n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["py", "draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L22.1.2\n", "\n", "def proposal_1(x,n=2000):\n", "    #YOUR CODE HERE\n", "    return x_new\n", "\n", "xinit = np.array([25.,10.])\n", "accepted_1, rejected_1, _ = metropolis_hastings(log_like_normal,prior,proposal_1,acceptance,xinit,values,5000)\n", "\n", "print(\"1/10 original uncertainty\")\n", "print(\"Length of last 100 accepted:\",len(accepted_1[-###:,1]))\n", "print(\"Average and stdev of last 100 accepted mu:\",accepted_1[-###:,0].mean(),\"+/-\",accepted_1[-###:,0].std())\n", "print(\"Average and stdev of last 100 accepted sigma:\",accepted_1[-###:,1].mean(),\"+/-\",accepted_1[-###:,1].std())\n", "print()\n", "\n", "def proposal_2(x,n=2000):\n", "    #YOUR CODE HERE\n", "    return x_new\n", "\n", "xinit = np.array([25.,10.])\n", "accepted_2, rejected_2, _ = metropolis_hastings(log_like_normal,prior,proposal_2,acceptance,xinit,values,5000)\n", "\n", "print(\"10X original uncertainty\")\n", "print(\"Length of last 100 accepted:\",len(accepted_2[-###:,1]))\n", "print(\"Average and stdev of last 100 accepted mu:\",accepted_2[-###:,0].mean(),\"+/-\",accepted_2[-###:,0].std())\n", "print(\"(Average and stdev of last 100 accepted sigma:\",accepted_2[-###,1].mean(),\"+/-\",accepted_2[-###:,1].std()))\n", "                   \n", "                                                                  \n", "#PLOT REJECTED VS. ACCEPTED\n", "#YOUR CODE HERE (if you want)"]}, {"cell_type": "markdown", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='section_23_2'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L22.2 Understanding Some Details </h2>  \n", "\n", "| [Top](#section_23_0) | [Previous Section](#section_23_1) | [Exercises](#exercises_23_2) | [Next Section](#section_23_3) |"]}, {"cell_type": "markdown", "metadata": {"tags": ["lect_02", "learner"]}, "source": ["*The material in this section is discussed in the video **<a href=\"https://courses.mitxonline.mit.edu/learn/course/course-v1:MITxT+8.S50.3x+3T2023/block-v1:MITxT+8.S50.3x+3T2023+type@sequential+block@seq_LS22/block-v1:MITxT+8.S50.3x+3T2023+type@vertical+block@vert_LS22_vid2\" target=\"_blank\">HERE</a>.** You are encouraged to watch that video and use this notebook concurrently.*"]}, {"cell_type": "markdown", "metadata": {"tags": ["lect_02", "learner"]}, "source": ["<h3>Overview</h3>\n", "\n", "Now a big component of why Markov Chain Monte Carlo is so powerful when compared with traditional fitting is the fact that we get a sequence of Monte Carlo events that give lots of details about our best fit. As just one example, these MC events allow us to look at the correlation of the final parameters, and help us to understand the space of allowed convergence. This flexibility due to the nature of Monte Carlo makes this approach particularly compelling.\n", "\n", "For example, let's take our previous Gaussian fit and look at how the parameters start to converge to the best fit."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["lect_02", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L22.2-runcell01\n", "\n", "#This cell plots results from our original run, which produced the array `accepted`\n", "\n", "fig = plt.figure(figsize=(10,20))\n", "ax = fig.add_subplot(3,1,1)\n", "ax.plot(accepted[:50,0], accepted[:50,1], label=\"Path\")\n", "ax.plot(accepted[:50,0], accepted[:50,1], 'b.', label='Accepted(First 50)')\n", "ax.plot(rejected[:50,0], rejected[:50,1], 'rx', label='Rejected(First 50)')\n", "ax.set_xlabel(\"$\\mu$\")\n", "ax.set_ylabel(\"$\\sigma$\")\n", "ax.legend()\n", "\n", "\n", "ax = fig.add_subplot(3,1,2)\n", "ax.plot(accepted[:,0], accepted[:,1], label=\"Path\")\n", "ax.plot(accepted[:,0], accepted[:,1], 'b.', label='Accepted(Full)',alpha=0.3)\n", "ax.plot(rejected[:,0], rejected[:,1], 'rx', label='Rejected(Full)',alpha=0.3)\n", "ax.set_xlabel(\"$\\mu$\")\n", "ax.set_ylabel(\"$\\sigma$\")\n", "ax.legend()\n", "ax.set_title(\"\") \n", "\n", "to_show=50\n", "ax = fig.add_subplot(3,1,3)\n", "ax.plot(accepted[-to_show:,0], accepted[-to_show:,1], label=\"Path\")\n", "ax.plot(accepted[-to_show:,0], accepted[-to_show:,1], 'b.', label='Accepted(Final 50)',alpha=0.5)\n", "ax.plot(rejected[-to_show:,0], rejected[-to_show:,1], 'rx', label='Rejected(Final 50)',alpha=0.5)\n", "ax.set_xlabel(\"$\\mu$\")\n", "ax.set_ylabel(\"$\\sigma$\")\n", "ax.legend()\n"]}, {"cell_type": "markdown", "metadata": {"tags": ["lect_02", "learner"]}, "source": ["So, in the beginning (top plot), you see both the mean and sigma heading towards their optimal values, with some random-walk-like fluctuations along the way. The middle plot shows the entire evolution, with the initial jittery trajectory changing into a sort of circular orbit around the final parameters. Looking more closely at the end of the evolution in the bottom plot, we see apparently random fluctuations of both the accepted and rejected values, with the former more closely bunched around the best-fit point $[\\mu, \\sigma]=[50,20]$.\n"]}, {"cell_type": "markdown", "metadata": {"tags": ["lect_02", "learner"]}, "source": ["<h3>Autocorrelation</h3>\n", "\n", "Another critical diagnostic when running Markov Chain Monte Carlo is how we can measure the convergence of the parameters in the Markov Chain. The simplest way to do this is to look at the spread of the parameters compared to their final result. If the parameters are spread around randomly (as appears to be the case in the bottom plot above), then their correlation coefficient will be close to zero. If the parameters are biased to one side, i.e. the parameter updates are mostly going in one specific direction (as is clearly the case in the top plot above), then there will be a strong correlation in the trend of the parameters.\n", "\n", "To examine this quantitatively, we can define the autocorrelation for parmater $x_{i}$ in its i-th iteration as\n", "\n", "$$\n", "\\hat{C}_{i} = \\left(x_{i}-\\bar{x}\\right)\\left(x_{i+n}-\\bar{x}\\right)\n", "$$\n", "\n", "where $n$ is the step size, namely how far apart in iteration number the points we compare are (typical length can be 100). For all practical purposes, this is just the correlation of an event with a previous event that is separated by some number of steps. Moreover, in the ideal scenario we should see that the autocorrelation follows a falling exponential distribution\n", "\n", "$$\n", "\\hat{C}_{i} = e^{\\large -t/\\tau}\n", "$$\n", "\n", "with the approach to convergence indicated by an autocorrelation tending towards 0."]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["lect_02", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L22.2-runcell02\n", "\n", "mean_acc_mu=accepted[-100:,0].mean()\n", "mean_acc_sig=accepted[-100:,1].mean()\n", "print(mean_acc_mu,mean_acc_sig)\n", "\n", "def autocorr(accepted,lag):\n", "    num_mu=0\n", "    denom_mu=0\n", "    num_sig=0\n", "    denom_sig=0\n", "    rk_mu,rk_sig = 0, 0\n", "    for i in range(accepted.shape[0]-lag):\n", "        num_mu+=(accepted[i,0]-mean_acc_mu)*(accepted[i+lag,0]-mean_acc_mu)\n", "        num_sig+=(accepted[i,1]-mean_acc_sig)*(accepted[i+lag,1]-mean_acc_sig)\n", "        denom_mu+=(mean_acc_mu-accepted[i,0])**2\n", "        denom_sig+=(mean_acc_sig-accepted[i,1])**2\n", "    if denom_mu > 0 and denom_sig > 0:\n", "        rk_mu=num_mu/denom_mu\n", "        rk_sig=num_sig/denom_sig\n", "    return rk_mu, rk_sig\n", "\n", "\n", "lag=np.arange(1,100)\n", "result=np.zeros((2,lag.shape[0]))\n", "for l in lag:\n", "    result[:,l-1]=autocorr(accepted,l)\n", "\n", "\n", "fig, ax = plt.subplots()\n", "ax.plot(lag, result[1,:], label='Autocorrelation for $\\sigma$')\n", "ax.plot(lag, result[0,:], label='Autocorrelation for $\\mu$')\n", "ax.legend(loc=0)\n", "ax.set(xlabel='steps', ylabel='autocorrelation', ylim=(-1, 1))"]}, {"cell_type": "markdown", "metadata": {"tags": ["lect_02", "learner"]}, "source": ["This plot displays more quantitatively how $\\sigma$ converges a bit more quickly than $\\mu$, an effect which can be seen qualitatively in the plot we made above showing the entire evolution in 2D $\\mu\\sigma$ space.\n", "\n", "Finally, perhaps the most critical element of the Markov Chain MC is the ability to investigate the correlations in the posterior distribution, which reveals the detailed behavior of the fit variables. We looked at something like this previously by plotting contours of the Likelihood. However, when things are not differentiable or there are ambiguities in the fit. Markov Chain posteriors can help to resolve difficult ambiguities in the fit."]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["lect_02", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L22.2-runcell03\n", " \n", "labels = ['$\\mu$','$\\sigma$']\n", "print(accepted.shape)\n", "samples=accepted[-5000:-1,:]\n", "#samples=np.reshape(samples,(samples.shape[0]*samples.shape[1],samples.shape[2]))\n", "#print(samples.shape)\n", "fig = corner.corner(samples,show_titles=True,labels=labels,plot_datapoints=True,quantiles=[0.16, 0.5, 0.84])\n"]}, {"cell_type": "markdown", "metadata": {"tags": ["lect_02", "learner"]}, "source": ["In this so-called \"corner\" plot, we see both the distribution of the fit parameters, with the widths of the 1D histograms giving their uncertainties, and also whether or not the fit parameters have any correlation. In this case, the lack of any slope in the contours in the central figure indicates that $\\sigma$ and $\\mu$ are essentially totally uncorrelated."]}, {"cell_type": "markdown", "metadata": {"tags": ["md", "learner"]}, "source": ["<a name='exercises_23_2'></a>     \n", "\n", "| [Top](#section_23_0) | [Restart Section](#section_23_2) | [Next Section](#section_23_3) |\n"]}, {"cell_type": "markdown", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 22.2.1</span>\n", "\n", "Plot the corner plot for the first 100 steps of the fit. What do your parameters look like, and do you observe a correlation (why or why not)?\n", "\n", "A) The fitted parameters are similar to those in `L22.2-runcell03`, and can be used. There is no correlation. \\\n", "B) The equilibration stage is present in the corner plots, and you see parameters move to the best fit with a positive correltion. \\\n", "C) There is a negative correlation between the parameters.\n", "<br>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["py", "draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L22.2.1\n", "\n", "samples=#YOUR CODE HERE\n", "fig = corner.corner(samples,show_titles=True,labels=labels,plot_datapoints=True,quantiles=[0.16, 0.5, 0.84])"]}, {"cell_type": "markdown", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='section_23_3'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L22.3 A More Realistic Markov Chain MC</h2>  \n", "\n", "| [Top](#section_23_0) | [Previous Section](#section_23_2) | [Exercises](#exercises_23_3) | [Next Section](#section_23_4) |"]}, {"cell_type": "markdown", "metadata": {"tags": ["lect_03", "learner"]}, "source": ["*The material in this section is discussed in the videos **<a href=\"https://courses.mitxonline.mit.edu/learn/course/course-v1:MITxT+8.S50.3x+3T2023/block-v1:MITxT+8.S50.3x+3T2023+type@sequential+block@seq_LS22/block-v1:MITxT+8.S50.3x+3T2023+type@vertical+block@vert_LS22_vid3\" target=\"_blank\">HERE</a>.** You are encouraged to watch that video and use this notebook concurrently.*"]}, {"cell_type": "markdown", "metadata": {"tags": ["lect_03", "learner"]}, "source": ["<h3>Overview</h3>\n", "\n", "In this section, we are going to use an existing online dataset for the historical temperature of the earth over the past 800,000 years, but tweak it heavily to motivate MCMC. First, we need to load the data.\n", "\n", "The citation for this temperature record can be found in at the beginning of this notebook, and the full data can be found <a href=\"https://www.ncei.noaa.gov/pub/data/paleo/icecore/antarctica/epica_domec/edc3deuttemp2007.txt\" target=\"_blank\">here</a>.\n", "\n", "The horizontal axis is the age in years, with the zero at 1950."]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["lect_03", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L22.3-runcell01\n", "\n", "import csv \n", "\n", "def load(iFile='data/L23/ice_core_data.txt'):\n", "    times=np.array([])\n", "    amps =np.array([])\n", "    with open(iFile, newline='') as csvfile:\n", "        line = csv.reader(csvfile, delimiter='\\t')\n", "        for row in line:\n", "            arr=row[0].split()\n", "            #print(', '.join(row))\n", "            pT=float(arr[2])\n", "            pA=float(arr[4])\n", "            times=np.append(pT,times)\n", "            amps =np.append(pA,amps)\n", "    #amps  = (amps-amps.mean())/(2.*np.max(amps))\n", "    return times,amps\n", "\n", "times,amps=load()\n", "plt.plot(times,amps)\n", "plt.xlabel('time (years)')\n", "plt.ylabel('temp (C)')\n", "plt.show()\n", "\n", "data = np.vstack((times,amps))\n", "data = data.T"]}, {"cell_type": "markdown", "metadata": {"tags": ["lect_03", "learner"]}, "source": ["This data has lots of big variations which may or may not have some periodic features. What we are going to do is make an arbitrary guess that there are three different cycles present. To investigate that, we'll try to fit the data with the following function (note the offset $A_0$ which is needed because the data are not centered vertically around 0):\n", "\n", "$$\n", "T(t) = A_{1} \\sin \\left(\\omega_{1} t \\right) + A_{2} \\sin \\left(\\omega_{2} t \\right) + A_{3} \\sin \\left(\\omega_{3} t \\right) + A_{0}\n", "$$\n", "\n", "We can begin by simply writing out the likelihood and running the MCMC as we did before. Notice the additions of a prior which requires the three frequencies to be in order from smallest to largest.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["lect_03", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L22.3-runcell02\n", "\n", "def func(x,t):\n", "    return x[0]*np.sin(x[1]*t) +  x[2]*np.sin(x[3]*t) +  x[4]*np.sin(x[5]*t) + x[6]\n", "\n", "def log_like(x,data):\n", "    return -1.*np.sum((func(x,data[:,0])-data[:,1])**2)\n", "\n", "def prior(like,x):\n", "    #Adjust the likelihood by the prior\n", "    prior=0\n", "    if(x[1] < x[3]) or (x[3] < x[5]) or (x[1] < x[5]):\n", "        prior=1\n", "    return like+np.log(prior)\n", "\n", "def proposal(x,n=5000):\n", "    #x[0] = mu, x[1]=sigma (new or current)\n", "    x_new     = x.copy()\n", "    #x_new[0]  = x[0] + np.random.randn()*x[0]/np.sqrt(n)\n", "    #x_new[1]  = x[1] + np.random.randn()*x[1]/np.sqrt(n)\n", "    #x_new[2]  = x[2] + np.random.randn()*x[0]/np.sqrt(n)\n", "    #x_new[3]  = x[3] + np.random.randn()*x[1]/np.sqrt(n)\n", "    #x_new[4]  = x[4] + np.random.randn()*x[0]/np.sqrt(n)\n", "    #x_new[5]  = x[5] + np.random.randn()*x[1]/np.sqrt(n)\n", "    #x_new[5]  = x[6] + np.random.randn()*x[1]/np.sqrt(n)\n", "    x_new      = x + np.random.normal(x.shape[0])*(x*0.0001+1e-6)\n", "    #np.random.normal(loc=0,scale=1,size=x.shape[0])*(x+1.0*np.ones(x.shape[0]))\n", "    return x_new\n", "\n", "def metropolis_hastings(iLikelihood,iPrior,iProposal,iAcceptance,xinit,data,niterations):\n", "    x = xinit\n", "    accepted = []\n", "    rejected = []\n", "    likelihood = []\n", "    for i in range(niterations):\n", "        x_new   =  iProposal(x)  \n", "        likeOld = iLikelihood(x,data)\n", "        likeNew = iLikelihood(x_new,data) \n", "        if (iAcceptance(iPrior(likeOld,x),iPrior(likeNew,x_new))):            \n", "            x = x_new\n", "            accepted.append(x_new)\n", "            likelihood.append(likeNew)\n", "        else:\n", "            rejected.append(x_new)\n", "    accepted = np.array(accepted)\n", "    rejected = np.array(rejected)\n", "    likelihood = np.array(likelihood)\n", "    return accepted, rejected, likelihood\n", "\n", "xinit = np.array([5.,1./10000.,5.,1./5000.,-5.,1./1000.,-5.])\n", "accepted, rejected, likelihood = metropolis_hastings(log_like,prior,proposal,acceptance,xinit,data,15000)\n", "print(accepted)"]}, {"cell_type": "markdown", "metadata": {"tags": ["lect_03", "learner"]}, "source": ["The last line in the code above prints out the entire array of accepted parameter values. Running 15,000 iterations results in only one case which is accepted.\n", "\n", "Now, let's look at the likelihood \"convergence\" and what the fit looks zooming in on a small section of the date near the oldest samples."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["lect_03", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L22.3-runcell03\n", "\n", "plt.plot(likelihood)\n", "plt.xlabel(\"iteration\")\n", "plt.ylabel(\"$\\mathcal{L}$\")\n", "plt.show()\n", "\n", "#print(accepted[-1])\n", "plt.plot(times[0:400],amps[0:400])\n", "plt.plot(times[0:400],func(xinit,times)[0:400])\n", "plt.xlabel('time (years)')\n", "plt.ylabel('temp (C)')\n", "plt.show()\n"]}, {"cell_type": "markdown", "metadata": {"tags": ["lect_03", "learner"]}, "source": ["The \"convergence\" is meaningless when only one iteration is accepted and, as a result, it's not surprising that the \"fit\" looks nothing like the data. In the previous example, the proposal function to find new values of the parameters varies each parameter by a Gaussian with mean and sigma of 0 and 1, respectively, times the current parameter values divided by 10,000. that clearly didn't work at all, so let's instead vary each parameter by that same Gaussian times 0.001. Note that this example runs 150,000 iterations instead of 15,000, and prints out only the total number of accepted iterations."]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["lect_03", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L22.3-runcell04\n", "\n", "def proposal(x,n=5000):\n", "    return x + np.random.normal(x.shape[0])*1e-3\n", "\n", "def prior(like,x):\n", "    #Adjust the likelihood by the prior\n", "    prior=0\n", "    if(x[1] < x[3]) or (x[3] < x[5]) or (x[1] < x[5]):\n", "        prior=1\n", "    return like+np.log(prior)\n", "    \n", "def func(x,t):\n", "    return x[0]*np.sin(x[1]/10000.*t) +  x[2]*np.sin(x[3]/10000*t) +  x[4]*np.sin(x[5]/10000*t) + x[6]\n", "\n", "xinit = np.array([5.,1.,5.,2.,-5.,10.,-5.])\n", "accepted, rejected, likelihood = metropolis_hastings(log_like,prior,proposal,acceptance,xinit,data,150000)\n", "print(len(accepted))\n", "\n", "plt.plot(likelihood)\n", "plt.xlabel(\"iteration\")\n", "plt.ylabel(\"$\\mathcal{L}$\")\n", "plt.show()\n", "\n", "plt.plot(times[0:400],amps[0:400])\n", "plt.plot(times[0:400],func(xinit,times)[0:400])\n", "plt.xlabel('time (years)')\n", "plt.ylabel('temp (C)')\n", "plt.show()\n"]}, {"cell_type": "markdown", "metadata": {"tags": ["lect_03", "learner"]}, "source": ["Well, that looks a tiny bit better, with 18 accepted iterations (but out of 10 times more samples) and some evidence for a little bit of improvement in the likelihood. However, we are obviously not getting anywhere near to fitting the data."]}, {"cell_type": "markdown", "metadata": {"tags": ["lect_03", "learner"]}, "source": ["<h3>A More Professional MCMC Sampler</h3>\n", "\n", "This clearly is a very inefficient way to get to convergence. In light of that, let's see what the professional MCMC samplers actually do. Their strategy is to get closer to the traditional gradient descent methods that we typically perform when trying to fit data when things are differentiable.\n", "\n", "The strategy will be to make the minimum searching a little more organized. To do that we will :\n", "\n", "1. Search many directions in parallel (call each point a walker)\n", "    * Perform a randomized update on all of the directions\n", "\n", "2. Do a more organized stepping relying on the random gradient between two walkers\n", "    * In this case we randomly pair walkers and search along the line connecting them\n", "\n", "3. As more walkers converge to the best fit, the random selection pulls more walkers in\n", "  \n", "As a consequence of this, we will define the gradient update for this MCMC method using the existing points built with random selection. We can define this gradient as follows:\n", "\n", "  * Given points $X_{i} \\in X$, we pick randomly two points $X_{i}$ (our anchor) and $X_{j}$ (a second random point) and we define a random number $Z$, which is greater than 0.\n", "  * Use $Z$ to pick a new point which is along the line between $X_{i}$ and $X_{j}$ given by (for the $t$-th and $(t+1)$-th step):\n", "\n", "$$\n", "X_{i}^{t+1} = X_{j}^{t} + Z (X^{t}_{i}-X^{t}_{j})\n", "$$\n", "  * Note that $X_{i}^{t+1}$ could be between $X_{i}^{t}$ and $X_{j}^{t}$, but also could be on the same line but outside those two points.\n", "  * Now, we test the likelihood of $X_{i}^{t+1}$. If it's better that the likelihood of $X_{i}^{t}$, we throw out $X_{i}^{t}$ and keep $X_{i}^{t+1}$ as a new walker.\n", "  * With the points divided into fixed and floating points, we match all the pairs and continually update our fixed points to be locations with better likelihood."]}, {"cell_type": "markdown", "metadata": {"tags": ["lect_03", "learner"]}, "source": ["<h3>Example</h3>\n", "\n", "As an example, the following code generates a set of toy data randomly sampled from a Gaussian with a mean of 10 and width of 2. Then, we follow these steps:\n", "\n", " * Create 10 random parameters (the Walkers)\n", " * Compute the p-values for our 10 walkers\n", " * Split the walkers into two parts (`walkers` and `otherwalkers`):\n", "     * For each part we fixed `otherwalkers` and updated `walkers` by picking a random point along the line between a particular walker and a random otherwalker\n", "     * Once we updated, we ran our traditional MCMC sampling\n", " * Then, we repeat the above steps but now varying the `otherwalkers` while the `walkers` were held fixed\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["lect_03", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L22.3-runcell05\n", "\n", "def mc_update(walkers, otherwalkers, logp0, Npars, idata, ifunc, a=2.0,iPrint=False):\n", "    Nw = len(walkers)\n", "    No = len(otherwalkers)\n", "\n", "    # Calculates random gradient for the affine linear transformation \n", "    Z = (((a - 1.0) * np.random.rand(Nw) + 1.0) ** 2.0) / a\n", "    if iPrint:\n", "        print(\"Rand:\",Z)\n", "    \n", "    # gets random indices of the othe rwalkers\n", "    rint = np.random.randint(No, size=(Nw,))\n", "    if iPrint:\n", "        print(\"Rand Indx:\",rint)\n", "    \n", "    # Propose new positions from the linear transformation\n", "    qt1 = otherwalkers[rint] - Z[:, np.newaxis] * (otherwalkers[rint] - walkers)\n", "    if iPrint:\n", "        print(\"Rand Updates:\", qt1)\n", "    \n", "    # Calculate the posterior probability of the new position\n", "    logp1 = log_like(qt1, idata,ifunc)\n", "    #logp1 = prior(logp1,qt1)\n", "    \n", "    #Now do the usual Markov update\n", "    #p_diff = (Npars - 1) * np.log(Z) + logp - logp0\n", "    p_diff = logp1 - logp0\n", "\n", "    rshape=np.random.rand(p_diff.shape[0])\n", "    # Determine if the new positions are accepted\n", "    accept = p_diff > np.log(np.random.rand(p_diff.shape[0]))\n", "    return qt1, logp1, accept\n", "\n", "#now let's solve a 1 parameter problem\n", "#try to predict a gaussian centered at 10\n", "def tmpfunc(x,t):\n", "    out=[]\n", "    for pX in x:\n", "        val=pX*np.ones(t.shape)\n", "        out.append(val)\n", "    out = np.array(out)\n", "    return out\n", "\n", "def log_like(x,data,ifunc):\n", "    delta = ifunc(x,data[:,0])-data[:,1]*np.ones(x.shape)\n", "    return -1.*np.sum(delta**2,axis=1)\n", "\n", "Nwalkers=10\n", "Npars=1\n", "toydata  = np.random.normal(10,2,(10,2))\n", "allWalks = np.array([1 + np.random.randn(Npars) for i in range(Nwalkers)])\n", "logp0    = log_like(allWalks, toydata,tmpfunc)\n", "\n", "print(\"Inital Walks:\\n\",allWalks,\"\\nInitial p-vals:\\n\",logp0)\n", "print(\"Update first 5:\")\n", "newWalks, newlogp, accept = mc_update(allWalks[0:5], allWalks[5:10], logp0[0:5], Npars, toydata, tmpfunc,iPrint=True)\n", "print(\"Updated Walks:\\n\",newWalks,\"\\nUpdated p-vals:\\n\",newlogp)\n", "\n", "print(\"Update second 5:\")\n", "newWalks, newlogp, accept = mc_update(allWalks[5:10], allWalks[0:5], logp0[5:10], Npars, toydata, tmpfunc)\n", "print(\"Updated Walks:\\n\",newWalks,\"\\nUpdated p-vals:\\n\",newlogp)\n"]}, {"cell_type": "markdown", "metadata": {"tags": ["lect_03", "learner"]}, "source": ["In the printout, you see the initial parameters and their p-values. The list labeled `Rand` is the $Z$ values used to find new points along the line between two parameter values in the formula shown earlier, `Rand Indx` indicates which random `walker` each `otherwalker` is paired with, `Rand Updates` are the new parameter values, and finally these new `walkers` and their new p-values are printed out. In the second step where the role of the `walkers` and `otherwalkers` are reversed, only the updated parameter values and their p-values are printed out.\n", " "]}, {"cell_type": "markdown", "metadata": {"tags": ["lect_03", "learner"]}, "source": ["All in all, our strategy here is to just do parallel MCMC updates on a grid of points to progressively get closer to a match to the sample. Because we have many points, we can take advantage of them crawling all over our distribution to get to the minimum.\n", "\n", "Note that this walker strategy was developed fairly recently and has had its main use in astrophysics: see <a href=\"https://arxiv.org/abs/1710.06068\" target=\"_blank\">here</a>. The actual walker was developed by two statisticians (Goodman and Weare) who have worked closely with the astro community.  \n", "\n", "Now that we've shown a simple example of how this works, let's do this for our more complicated problem of fitting the temperature data with a sum of three cyclical functions. We will only need about 2.5k steps to get to convergence, so let's just do that. "]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["lect_03", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L22.3-runcell06\n", "\n", "def proposal(q, logp, data, Nwalk, Npars, iFunc):\n", "    half = int(Nwalk / 2)\n", "    first, second = slice(half), slice(half, Nwalk)\n", "\n", "    # Alternate slices of the data fixing and updating\n", "    for S0, S1 in [(first, second), (second, first)]:\n", "        # Use stretch move to calculate the proposal\n", "        q_new, logp_new, acc = mc_update(q[S0], q[S1], logp[S0], Npars, data, iFunc)\n", "\n", "        # Add accepted values into the chains\n", "        if np.any(acc):\n", "            logp[S0][acc] = logp_new[acc]\n", "            q[S0][acc]    = q_new[acc]\n", "\n", "    return q, logp\n", "\n", "#def metropolis_hastings(iLikelihood,iPrior,iProposal,iAcceptance,xinit,data,niterations):\n", "def metropolis_hastings_ensemble(xinit, logpinit, data, Npars, Nwalk, Nstep,iFunc):\n", "    samples = np.ndarray((Nwalk, Nstep, Npars))\n", "    samples[:, 0, :] = np.array(xinit)\n", "\n", "    lnprob = np.ndarray((Nwalk, Nstep))\n", "    lnprob[:, 0] = np.array(logpinit)\n", "\n", "    # Iterate over the Markov steps\n", "    for i in range(1, Nstep):\n", "        if (i % 500)==0:\n", "            print(\"Steps:\",i)\n", "        q, p = proposal(samples[:,i-1,:], lnprob[:,i-1], data, Nwalk, Npars, iFunc)\n", "        samples[:,i,:] = np.array(q)\n", "        lnprob[:,i] = np.array(p)\n", "    \n", "    return samples, lnprob\n", "\n", "# Set up MCMC parameters\n", "Npars = xinit.shape[0]\n", "Nwalk = 100\n", "Nstep = 2500 #larger Nstep used in related video\n", "\n", "def log_like(x,data,iFunc):\n", "    return -1.*np.sum((iFunc(x,data[:,0])-data[:,1])**2,axis=1)\n", "\n", "def func(x,t):\n", "    out=[]\n", "    for pX in x:\n", "        val=pX[0]*np.sin(pX[1]/10000.*t) +  pX[2]*np.sin(pX[3]/10000*t) +  pX[4]*np.sin(pX[5]/10000*t) + pX[6]\n", "        out.append(val)\n", "    out = np.array(out)\n", "    return out\n", "\n", "q0    = np.array([xinit + 1.0e-4*np.random.randn(Npars) for i in range(Nwalk)])\n", "logp0 = log_like(q0, data, func)\n", "accepted, likelihood = metropolis_hastings_ensemble(q0,logp0,data,Npars,Nwalk,Nstep,func)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["lect_03", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L22.3-runcell07\n", "\n", "lproj = np.max(likelihood,axis=0)\n", "plt.plot(lproj)\n", "plt.xlabel(\"iteration\")\n", "plt.ylabel(\"$\\mathcal{L}$\")\n", "plt.show()\n", "\n", "maxval=np.argmax(lproj)\n", "maxy=np.argmax(likelihood[:,maxval])\n", "bestpars=np.array([accepted[maxy,maxval]])\n", "output=func(bestpars,times)\n", "\n", "plt.plot(times[0:4000],amps[0:4000])\n", "plt.plot(times[0:4000],output.flatten()[0:4000])\n", "plt.xlabel('time (years)')\n", "plt.ylabel('temp (C)')\n", "plt.show()\n"]}, {"cell_type": "markdown", "metadata": {"tags": ["lect_03", "learner"]}, "source": ["This method works much better! The likelihood shows clear convergence to a maximum value and the fit to the data is much more reasonable. Clearly, this simple sum of three sinusoidal functions cannot capture every detail of this complicated data, but it does seem to accurately reproduce many of the features present.\n", "\n", "Just for fun, let's look at the best fit of the final walkers. We can see that many of the features in the data are picked up form these walkers. "]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["lect_03", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L22.3-runcell08\n", "\n", "def plotter(accepted,times,amps):\n", "    plt.ion()\n", "    plt.plot(times,amps,label='Ice Core Data')\n", "    output=func(accepted[:,-1],times)\n", "    for i0 in range(100):\n", "        plt.plot(times, output[i0], color=\"r\", alpha=0.1)\n", "    plt.ticklabel_format(style='sci', axis='x', scilimits=(0,0))\n", "    plt.xlabel('Years ago')\n", "    plt.ylabel(r'$\\Delta$ T (C)')\n", "    plt.legend()\n", "    plt.show()\n", "    \n", "plotter(accepted,times,amps)"]}, {"cell_type": "markdown", "metadata": {"tags": ["lect_03", "learner"]}, "source": ["Now, we can look in more detail at the parameters, which is really where the Markov Chain MC starts to show its stuff. Specifically, we'll plot the correlation of each parameter with all of the others. This will be done similarly to what we did previously, with \"corner\" plots showing 2D contours and 1D distributions."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["lect_03", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L22.3-runcell09\n", "\n", "import corner \n", "labels = ['$a_{1}$','$\\omega_{1}$','$a_{2}$','$\\omega_{2}$','$a_{3}$','$\\omega_{3}$','A']\n", "samples=accepted[:,-500:-1]\n", "samples=np.reshape(samples,(samples.shape[0]*samples.shape[1],samples.shape[2]))\n", "print(samples.shape)\n", "fig = corner.corner(samples,show_titles=True,labels=labels,plot_datapoints=True,quantiles=[0.16, 0.5, 0.84])\n"]}, {"cell_type": "markdown", "metadata": {"tags": ["lect_03", "learner"]}, "source": ["The contours and 1D plots show lots of ambiguity with multiple solutions for the various amplitudes and frequencies. Note that, unlike previously, this version didn't impose any prior constraint on the amplitudes. We can try again including the prior requirement."]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["lect_03", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L22.3-runcell10\n", "\n", "def prior(like,x):\n", "    #Adjust the likelihood by the prior\n", "    prior=np.ones(x.shape[0])\n", "    idx = np.where((x[:,1] < x[:,3]) | (x[:,3] < x[:,5]) | (x[:,1] < x[:,5]))\n", "    like[idx]+=np.log(prior[idx])\n", "    return like\n", "\n", "def mc_update(walkers, otherwalkers, logp0, Npars, idata, ifunc, a=2.0,iPrint=False):\n", "    Nw = len(walkers)\n", "    No = len(otherwalkers)\n", "\n", "    # Calculates random gradient for the affine linear transformation \n", "    Z = (((a - 1.0) * np.random.rand(Nw) + 1.0) ** 2.0) / a\n", "    rint = np.random.randint(No, size=(Nw,))\n", "    qt1 = otherwalkers[rint] - Z[:, np.newaxis] * (otherwalkers[rint] - walkers)    \n", "    # Calculate the posterior probability of the new position\n", "    logp1 = log_like(qt1, idata,ifunc)\n", "    logp1 = prior(logp1,qt1)\n", "    \n", "    #Now do the usual Markov update\n", "    #p_diff = (Npars - 1) * np.log(Z) + logp - logp0\n", "    p_diff = logp1 - logp0\n", "\n", "    rshape=np.random.rand(p_diff.shape[0])\n", "    accept = p_diff > np.log(np.random.rand(p_diff.shape[0]))\n", "    return qt1, logp1, accept\n", "\n", "Nwalk = 100\n", "Nstep = 2500 #larger Nstep used in related video\n", "q0    = np.array([xinit + 1.0e-4*np.random.randn(Npars) for i in range(Nwalk)])\n", "logp0 = log_like(q0, data, func)\n", "accepted, likelihood = metropolis_hastings_ensemble(q0,logp0,data,Npars,Nwalk,Nstep,func)"]}, {"cell_type": "markdown", "metadata": {"tags": ["lect_03", "learner"]}, "source": ["Let's see how the corner plots of correlations have changed with the prior included."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["lect_03", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L22.3-runcell11\n", "\n", "import corner \n", "labels = ['$a_{1}$','$\\omega_{1}$','$a_{2}$','$\\omega_{2}$','$a_{3}$','$\\omega_{3}$','A']\n", "samples=accepted[:,-500:-1]\n", "samples=np.reshape(samples,(samples.shape[0]*samples.shape[1],samples.shape[2]))\n", "print(samples.shape)\n", "fig = corner.corner(samples,show_titles=True,labels=labels,plot_datapoints=True,quantiles=[0.16, 0.5, 0.84])\n", "\n", "plotter(accepted,times,amps)\n", "\n", "lproj = np.max(likelihood,axis=0)\n", "plt.plot(lproj)\n", "plt.xlabel(\"iteration\")\n", "plt.ylabel(\"$\\mathcal{L}$\")\n", "plt.show()\n", "\n", "maxval=np.argmax(lproj)\n", "maxy=np.argmax(likelihood[:,maxval])\n", "bestpars=np.array([accepted[maxy,maxval]])\n", "output=func(bestpars,times)\n", "\n", "plt.plot(times[0:4000],amps[0:4000])\n", "plt.plot(times[0:4000],output.flatten()[0:4000])\n", "plt.xlabel('time (years)')\n", "plt.ylabel('temp (C)')\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"tags": ["lect_03", "learner"]}, "source": ["The corner plots show a lot of scatter of individual points, but the peaks indicated by the contours are quite distinct, something that is more evident in the projected 1D distributions. With the exception of `a3`, which has a small satellite peak, all of the parameters have a single clear peak. Even in the case of `a3`, that extra peak doesn't move the mean value very much, but instead only results is an increased uncertainty on the low side."]}, {"cell_type": "markdown", "metadata": {"tags": ["lect_03", "learner"]}, "source": ["In this particular case, the simple function we are using for the fit is differentiable, so we can compare the MCMC approach with a normal fitter. The time to convergence will be much faster, but this convergence will not be great... Well, we really don't even know how to characterize what's good and what's bad without a better notion of the uncertainty and correlation model in the data. Anyway let's take a look.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["lect_03", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L22.3-runcell12\n", "\n", "xinit = np.array([2.,1.6,1.76,2.16,-0.1,10.6,-5.])\n", "\n", "def lmfunc(x,p0,p1,p2,p3,p4,p5,p6):\n", "    #val=pX[0]*np.sin(pX[1]/10000.*t) +  pX[2]*np.sin(pX[3]/10000*t) +  pX[4]*np.sin(pX[5]/10000*t) + pX[6]\n", "    return p0*np.sin(p1/10000.*x) +  p2*np.sin(p3/10000.*x) +  p4*np.sin(p5/10000.*x) + p6\n", "\n", "model  = lmfit.Model(lmfunc)\n", "print(data[:,1],data[:,0])\n", "params = model.make_params(p0=xinit[0],p1=xinit[1],p2=xinit[2],p3=xinit[3],p4=xinit[4],p5=xinit[5],p6=xinit[6])\n", "result = model.fit(data=data[:,1], params=params, x=data[:,0])\n", "result.plot()\n", "lmfit.report_fit(result)"]}, {"cell_type": "markdown", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='exercises_23_3'></a>     \n", "\n", "| [Top](#section_23_0) | [Restart Section](#section_23_3) | [Next Section](#section_23_4) |\n"]}, {"cell_type": "markdown", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 22.3.1</span>\n", "\n", "Run the fit with only 6 walkers, but still 2500 steps. What is the value of the likelihood that the code converges to? Think about how this compares to the convergence of the earlier code, where 100 walkers were used. Is this doing a good enough job?\n", "\n", "Run several trials and report your answer for the typical maximum likelihood as a number (it will be negative) with precision `1e5`.\n", "\n", "\n", "<br>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["py", "draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L22.3.1\n", "\n", "Nwalk = ###YOUR CODE HERE\n", "Nstep = 2500\n", "xinit = np.array([5.,1.,5.,2.,-5.,10.,-5.])\n", "q0    = np.array([xinit + 1.0e-4*np.random.randn(Npars) for i in range(Nwalk)])\n", "logp0 = log_like(q0, data, func)\n", "accepted, likelihood = metropolis_hastings_ensemble(q0,logp0,data,Npars,Nwalk,Nstep,func)\n", "\n", "lproj = np.max(likelihood,axis=0)\n", "max_likelihood = ###YOUR CODE HERE\n", "\n", "print(\"Maximum Liikelihood:\", max_likelihood)\n", "plt.plot(lproj)\n", "plt.xlabel(\"iteration\")\n", "plt.ylabel(\"$\\mathcal{L}$\")\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 22.3.2</span>\n", "\n", "Let's run MCMC on some data that has discontinuities, and see if we can get a good fit using a step-function. There are several steps to understanding and implementing this. In this problem we will describe the data and fit function, with the goal of defining a prior.\n", "\n", "<h3>Step 1: Generate Data</h3>\n", "\n", "Generate three sets of random data, that will ultimately create a tiered box shape. Run the following code to visualize this shape:\n", "\n", "<pre>\n", "np.random.seed(40)\n", "vals=np.random.rand(1000)*10\n", "vals=np.append(vals,np.random.rand(1000)*5 + 2.5)\n", "vals=np.append(vals,np.random.rand(1000)*2+4.)\n", "hist,bin_edges=np.histogram(vals,bins=np.arange(0,10.5,0.25))\n", "bin_centers=0.5*(bin_edges[:-1]+bin_edges[1:])\n", "plt.errorbar(bin_centers,hist,np.sqrt(hist),fmt='o', color='k')\n", "plt.xlabel(\"x\")\n", "plt.ylabel(\"events\")\n", "plt.show()\n", "</pre>\n", "\n", "<h3>Step 2: Define a Fit Function</h3>\n", "\n", "The function we will try to fit is given by:\n", "\n", "<pre>\n", "def func(x,t):\n", "    out=[]\n", "    for pX in x:\n", "        val=pX[0]*np.heaviside(t-pX[4],1) + \\\n", "            pX[1]*np.heaviside(t-pX[5],1) + \\\n", "            pX[2]*np.heaviside(t-pX[6],1) + \\\n", "            pX[3]*np.heaviside(t-pX[7],1) + pX[8]\n", "        out.append(val)\n", "    out = np.array(out)\n", "    return out\n", "</pre>\n", "\n", "Optionally, plot the fit function for some random parameter choices, to see what it looks like:\n", "\n", "<pre>\n", "# Define a single set of parameters\n", "# Format: [height1, height2, height3, height4, position1, position2, position3, position4, offset]\n", "params = np.array([\n", "    [2, -1, 3, -2, 1, 3, 5, 7, 0]  # Example parameter set\n", "])\n", "\n", "# Define the t values\n", "t_values = np.linspace(0, 10, 1000)  # t goes from 0 to 10 with 1000 points\n", "\n", "# Calculate the output of the function for this single set of parameters\n", "output = func(params, t_values)\n", "\n", "# Plot the result\n", "plt.figure(figsize=(10, 6))\n", "plt.plot(t_values, output[0], label=\"Parameter Set\")\n", "plt.xlabel('t')\n", "plt.ylabel('Function Value')\n", "plt.title('Plot of func for a Single Parameter Set')\n", "plt.legend()\n", "plt.grid(True)\n", "plt.show()\n", "</pre>\n", "\n", "\n", "<h3>Step 3: Define a Prior</h3>\n", "\n", "The prior places constraints on the parameters of the model. It will have the following form:\n", "\n", "<pre>\n", "def prior(like,x):\n", "    #Adjust the likelihood by the prior\n", "    prior=np.zeros(x.shape[0])\n", "    idx = np.where(###YOUR CODE HERE: ENTER CONSTRAINTS)\n", "    like[idx]+=np.log(prior[idx])\n", "    \n", "    #ADD OTHER CONSTRAINTS\n", "    idx = np.where(###YOUR CODE HERE: ENTER CONSTRAINTS)\n", "    like[idx]+=np.log(prior[idx])\n", "    return like\n", "</pre>\n", "\n", "\n", "**Here is where the question comes in.** Consider the constraints below. Select ALL options that are beneficial to add to the prior, based on the form of the data and model we are trying to fit. Note: some options may seem useful, but are not ideal because\n", "\n", "A) The step positions should be strictly increasing (i.e., each step occurs at a farther position than the previous one):\\\n", "`idx = np.where((x[:,4] > x[:,5]) | (x[:,5] > x[:,6]) | (x[:,6] > x[:,7]))`\n", "\n", "B) The step heights should be non-negative, meaning the model should not have any downward steps:\\\n", "`idx = np.where((x[:,0] < 0) | (x[:,1] < 0) | (x[:,2] < 0) | (x[:,3] < 0))`\n", "\n", "C) The difference between consecutive step positions should be at least 1 to ensure that the steps are well-separated:\\\n", "`idx = np.where((x[:,5] - x[:,4] < 1.0) | (x[:,6] - x[:,5] < 1.0) | (x[:,7] - x[:,6] < 1.0))`\n", "\n", "D) The step positions should be non-negative, meaning all steps should occur at positive positions:\\\n", "`idx = np.where((x[:,4] < 0) | (x[:,5] < 0) | (x[:,6] < 0) | (x[:,7] < 0))`\n", "\n", "E) The sum of the step heights should be equal to a specific value (e.g., 10) to ensure the total height of the function is fixed:\\\n", "`idx = np.where(np.abs(x[:,0] + x[:,1] + x[:,2] + x[:,3] - 10) > 1e-6)`\n", "\n", "F) The step heights should alternate in sign, ensuring that each step is followed by a drop, creating an oscillating pattern:\n", "`idx = np.where((x[:,0] * x[:,1] > 0) | (x[:,1] * x[:,2] > 0) | (x[:,2] * x[:,3] > 0))`\n", "\n", "G) The step positions should be within a specific range (e.g., between 1 and 5) to limit the function\u2019s domain:\\\n", "`idx = np.where((x[:,4] < 1) | (x[:,4] > 5) | (x[:,5] < 1) | (x[:,5] > 5) | (x[:,6] < 1) | (x[:,6] > 5) | (x[:,7] < 1) | (x[:,7] > 5))`\n", "\n", "H) The constant offset should be non-negative to ensure that the function does not drop below a certain baseline:\\\n", "`idx = np.where(x[:,8] < 0)`\n", "\n", "\n", "<br>"]}, {"cell_type": "markdown", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 22.3.3</span>\n", "\n", "Now run MCMC to fit the step-function that we have defined, and compare with fitting performed by lmfit. You will need to define the `prior` in the code below, based on your answer to the previous question. Which does a better job? \n", "\n", "A) MCMC is better.\\\n", "B) lmfit is better.\\\n", "C) They both perform the same.\n", "\n", "<br>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["py", "draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L22.3.3\n", "\n", "#Generate the data -> just run this code if \n", "#you want to see what it looks like first\n", "#-----------------------------------------------\n", "np.random.seed(40)\n", "vals=np.random.rand(1000)*10\n", "vals=np.append(vals,np.random.rand(1000)*5 + 2.5)\n", "vals=np.append(vals,np.random.rand(1000)*2+4.)\n", "hist,bin_edges=np.histogram(vals,bins=np.arange(0,10.5,0.25))\n", "bin_centers=0.5*(bin_edges[:-1]+bin_edges[1:])\n", "plt.errorbar(bin_centers,hist,np.sqrt(hist),fmt='o', color='k')\n", "plt.xlabel(\"x\")\n", "plt.ylabel(\"events\")\n", "plt.show()\n", "\n", "\n", "#define the step-function used for fitting\n", "#-----------------------------------------------\n", "def func(x,t):\n", "    out=[]\n", "    for pX in x:\n", "        val=pX[0]*np.heaviside(t-pX[4],1) + \\\n", "            pX[1]*np.heaviside(t-pX[5],1) + \\\n", "            pX[2]*np.heaviside(t-pX[6],1) + \\\n", "            pX[3]*np.heaviside(t-pX[7],1) + pX[8]\n", "        out.append(val)\n", "    out = np.array(out)\n", "    return out\n", "\n", "def log_like(x,data,iFunc):\n", "    return -1.*np.sum((iFunc(x,data[:,0])-data[:,1])**2,axis=1)\n", "\n", "\n", "#define the prior\n", "#-----------------------------------------------\n", "def prior(like,x):\n", "    #Adjust the likelihood by the prior\n", "    prior=np.zeros(x.shape[0])\n", "    idx = np.where(###YOUR CODE HERE: ENTER CONSTRAINTS)\n", "    like[idx]+=np.log(prior[idx])\n", "    \n", "    #ADD OTHER CONSTRAINTS\n", "    idx = np.where(###YOUR CODE HERE: ENTER CONSTRAINTS)\n", "    like[idx]+=np.log(prior[idx])\n", "    return like\n", "\n", "\n", "#redefine some functions that we have used already\n", "#-----------------------------------------------\n", "def mc_update(walkers, otherwalkers, logp0, Npars, idata, ifunc, a=2.0,iPrint=False):\n", "    Nw = len(walkers)\n", "    No = len(otherwalkers)\n", "\n", "    # Calculates random gradient for the affine linear transformation\n", "    Z = (((a - 1.0) * np.random.rand(Nw) + 1.0) ** 2.0) / a\n", "    rint = np.random.randint(No, size=(Nw,))\n", "    qt1 = otherwalkers[rint] - Z[:, np.newaxis] * (otherwalkers[rint] - walkers)\n", "    # Calculate the posterior probability of the new position\n", "    logp1 = log_like(qt1, idata,ifunc)\n", "    logp1 = prior(logp1,qt1)\n", "\n", "    #Now do the usual Markov update\n", "    #p_diff = (Npars - 1) * np.log(Z) + logp - logp0\n", "    p_diff = logp1 - logp0\n", "\n", "    rshape=np.random.rand(p_diff.shape[0])\n", "    accept = p_diff > np.log(np.random.rand(p_diff.shape[0]))\n", "    return qt1, logp1, accept\n", "\n", "\n", "def log_like(x,data,iFunc):\n", "    return -1.*np.sum((iFunc(x,data[:,0])-data[:,1])**2,axis=1)\n", "\n", "\n", "#run MCMC\n", "#-----------------------------------------------\n", "Npars = 9\n", "Nwalk = 100\n", "Nstep = 5000\n", "xinit = np.array([100,100,-100,-100,1,2,3,4,100])\n", "q0    = np.array([xinit + 1.0e-4*np.random.randn(Npars) for i in range(Nwalk)])\n", "data = np.vstack((bin_centers,hist))\n", "data = data.T\n", "logp0 = log_like(q0, data, func)\n", "accepted, likelihood = metropolis_hastings_ensemble(q0,logp0,data,Npars,Nwalk,Nstep,func)\n", "\n", "lproj = np.max(likelihood,axis=0)\n", "plt.plot(lproj)\n", "plt.xlabel(\"iteration\")\n", "plt.ylabel(\"$\\mathcal{L}$\")\n", "plt.show()\n", "\n", "maxval=np.argmax(lproj)\n", "maxy=np.argmax(likelihood[:,maxval])\n", "bestpars=np.array([accepted[maxy,maxval]])\n", "print(bestpars)\n", "output=func(bestpars,bin_centers)\n", "\n", "plt.errorbar(bin_centers,hist,np.sqrt(hist),fmt='o', color='k')\n", "plt.plot(bin_centers,output.flatten(),color='red')\n", "plt.xlabel(\"x\")\n", "plt.ylabel(\"events\")\n", "plt.show()\n", "\n", "\n", "#fit with lmfit\n", "#-----------------------------------------------\n", "def lmfunc(x,p0,p1,p2,p3,p4,p5,p6,p7,p8):\n", "    return p0*np.heaviside(x-p4,1) + p1*np.heaviside(x-p5,1) + p2*np.heaviside(x-p6,1) + p3*np.heaviside(x-p7,1)+p8\n", "\n", "model  = lmfit.Model(lmfunc)\n", "print(data[:,1],data[:,0])\n", "params = model.make_params(p0=xinit[0],p1=xinit[1],p2=xinit[2],p3=xinit[3],p4=xinit[4],p5=xinit[5],p6=xinit[6],p7=xinit[7],p8=xinit[8])\n", "result = model.fit(data=data[:,1], params=params, x=data[:,0])\n", "result.plot()\n", "lmfit.report_fit(result)"]}], "metadata": {"celltoolbar": "Tags", "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}