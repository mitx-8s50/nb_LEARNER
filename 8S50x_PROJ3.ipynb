{"cells": [{"cell_type": "markdown", "id": "758d2e10", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<hr style=\"height: 1px;\">\n", "<i>This notebook was authored by the 8.S50x Course Team, Copyright 2022 MIT All Rights Reserved.</i>\n", "<hr style=\"height: 1px;\">\n", "<br>\n", "\n", "<h1>Project 3 - Deep Learning and the Ising Model</h1>\n"]}, {"cell_type": "markdown", "id": "qWAmspvYNNrF", "metadata": {"id": "qWAmspvYNNrF", "tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_3_0'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">PROJ3.0 Overview</h2>\n"]}, {"cell_type": "markdown", "id": "07a8238a", "metadata": {"id": "qWAmspvYNNrF", "tags": ["learner", "md", "learner_chopped"]}, "source": ["<h3>Navigation</h3>\n", "\n", "<table style=\"width:100%\">\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_3_1\">PROJ3.1 The Lattice Ising Model</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#problems_3_1\">PROJ3.1 Checkpoints</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_3_2\">PROJ3.2 Modeling the Phase Transition</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#problems_3_2\">PROJ3.2 Checkpoints</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_3_3\">PROJ3.3 Constructing Ising Model Simulation</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#problems_3_3\">PROJ3.3 Checkpoints</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_3_4\">PROJ3.4 NN Application on Triangle Ising Model</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\">Open-Ended Submission</td>\n", "    </tr>\n", "</table>"]}, {"cell_type": "markdown", "id": "18c8ef8e", "metadata": {"id": "qWAmspvYNNrF", "tags": ["learner", "md", "catsoop_00"]}, "source": ["<h3>Learning Objectives</h3>\n", "\n", "In this Project we will explore the following objectives:\n", "\n", "- Setting up the canonical 2D Ising Model on a square lattice\n", "- Using a Markov Chain Monte-Carlo Proposal strategy to perform spin-flips\n", "- Simulating a phase transition of the system as a function of temperature\n", "- Implementing a neural network to learn characteristics of the phase transition\n", "- (Open-ended part) Applying the neural network to a triangular lattice and predicting the phase transition\n", "\n", "\n"]}, {"cell_type": "markdown", "id": "00a67cca", "metadata": {"id": "qWAmspvYNNrF", "tags": ["learner", "md"]}, "source": ["<h3>Importing Libraries</h3>\n", "\n", "Before beginning, run the code cells below to import the relevant libraries for this notebook."]}, {"cell_type": "code", "execution_count": null, "id": "wXFVR2cpOPCt", "metadata": {"id": "wXFVR2cpOPCt", "tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: PROJ3.0-runcell01\n", "\n", "!pip install torchmetrics\n"]}, {"cell_type": "code", "execution_count": null, "id": "9fc5f50c", "metadata": {"id": "9fc5f50c", "tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: PROJ3.0-runcell02\n", "\n", "import numpy as np\n", "from numpy.random import rand\n", "import matplotlib.pyplot as plt\n", "from scipy.sparse import spdiags,linalg,eye\n", "from tqdm import tqdm\n", "import imageio\n", "import torch\n", "import torch.nn as nn\n", "import torch.nn.functional as F\n", "from torch.utils.data import Sampler, BatchSampler, Dataset, DataLoader, Subset, SubsetRandomSampler, random_split\n", "from torchmetrics import Accuracy"]}, {"cell_type": "markdown", "id": "3d85ffe0", "metadata": {"tags": ["learner", "md"]}, "source": ["<h3>Setting Default Figure Parameters</h3>\n", "\n", "The following code cell sets default values for figure parameters."]}, {"cell_type": "code", "execution_count": null, "id": "0d4468d4", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: PROJ3.0-runcell03\n", "\n", "#set plot resolution\n", "%config InlineBackend.figure_format = 'retina'\n", "\n", "#set default figure parameters\n", "plt.rcParams['figure.figsize'] = (6,6)\n", "\n", "medium_size = 12\n", "large_size = 15\n", "\n", "plt.rc('font', size=medium_size)          # default text sizes\n", "plt.rc('xtick', labelsize=medium_size)    # xtick labels\n", "plt.rc('ytick', labelsize=medium_size)    # ytick labels\n", "plt.rc('legend', fontsize=medium_size)    # legend\n", "plt.rc('axes', titlesize=large_size)      # axes title\n", "plt.rc('axes', labelsize=large_size)      # x and y labels\n", "plt.rc('figure', titlesize=large_size)    # figure title\n"]}, {"cell_type": "markdown", "id": "d469c142", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_3_1'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">PROJ3.1 The Lattice Ising Model</h2>    \n", "\n", "| [Top](#section_3_0) | [Previous Section](#section_3_0) | [Checkpoints](#problems_3_1) | [Next Section](#section_3_2) |\n"]}, {"cell_type": "markdown", "id": "1bba0684", "metadata": {"id": "1bba0684", "tags": ["learner", "md", "catsoop_01"]}, "source": ["<h3>Overview</h3>\n", "\n", "No numerical physics class would be complete without exploring the Ising model, a mathematical model used to describe the behavior of a collection of interacting magnetic moments such as atoms in a solid or spins in a lattice. It is named after Ernst Ising, a physicist who first proposed it in 1925.\n", "\n", "However, because we want use state of the art techniques for this, we are going to study the Ising model using Deep learning. The first part of this project will largely follow work done in <a href=\"https://arxiv.org/abs/1605.01735\" target=\"_blank\">this</a> nature paper:\n", "\n", ">source: https://arxiv.org/abs/1605.01735 <br>\n", ">attribution: Juan Carrasquilla, Roger G. Melko (2016), arXiv:1605.01735 [cond-mat.str-el]\n", "\n", "This article captures much of the core ideas that we will use for building simulators, and also highlights the basic scheme relevant to the Ising model.\n", "\n", "Our first step is to setup the Ising model.\n"]}, {"cell_type": "markdown", "id": "4b59c913", "metadata": {"id": "1bba0684", "tags": ["learner", "md", "catsoop_01"]}, "source": ["<h3>Setting up Model</h3>\n", "\n", "In the Ising model, each magnetic moment is represented by a spin variable $\\sigma$, which can take on values of $\\pm 1$. The model assumes that these spins interact only with their nearest neighbors in a lattice, and also with an external magnetic field if one is present.\n", "\n", "The Hamiltonian of the Ising model describing the energy of a system of spins $\\sigma_{i}$ is given by:\n", "\n", "$$\n", "H = -J \\sum_{i,j} \\sigma_{i} \\sigma_{j} - \\mu_{b} \\sum_{j} B_{j} \\sigma_{j}\n", "$$\n", "\n", "where $J$ is the exchange interaction strength between neighboring spins, $\\mu_{b}$ is the magnetic moment of the objects, and $B_{j}$ is the strength of the external magnetic field at the location of particle $j$. The second sum is taken over all spins in the system, while the first one includes only $(i,j)$ pairs which are nearest neighbors on the lattice.\n", "\n", "The Ising model exhibits a phase transition, which is a sudden change in the behavior of the system as a parameter is varied. In the absence of an external magnetic field ($B=0$), the model exhibits a phase transition at a critical temperature known as the Curie temperature ($T_C$). Below the critical temperature, the system exhibits long-range ordered spins, with all spins aligning in the same direction, resulting in a net magnetization. Above the critical temperature, the system becomes disordered, with spins pointing in random directions, and the net magnetization vanishes.\n", "\n", "\n", "The critical behavior of the Ising model at the phase transition is described by universal scaling laws, which are independent of the microscopic details of the system. These scaling laws have been used to study a wide range of physical systems, including magnets, fluids, and even social networks.\n", "\n", "\n", "As an example of how we will setup the Ising model, see the `initialize` code below, which represents the state of spins on a 2D lattice. Here, we will start with a random initialization. \n", "\n"]}, {"cell_type": "code", "execution_count": null, "id": "5ef24c1d", "metadata": {"id": "5ef24c1d", "tags": ["learner", "py", "learner_chopped", "catsoop_01"]}, "outputs": [], "source": ["#>>>RUN: PROJ3.1-runcell01\n", "\n", "def initialize(N):   \n", "    state = 2*np.random.randint(2, size=(N,N))-1\n", "    return state\n", "\n", "np.random.seed(20)\n", "N=4\n", "test=initialize(N)\n", "print(test)"]}, {"cell_type": "markdown", "id": "2f413bd5", "metadata": {"id": "2f413bd5", "tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='problems_3_1'></a>     \n", "\n", "| [Top](#section_3_0) | [Restart Section](#section_3_1) | [Next Section](#section_3_2) |"]}, {"cell_type": "markdown", "id": "17ef971b", "metadata": {"id": "2f413bd5", "tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Checkpoint 3.1.1</span>\n", "\n", "Now that we have a $4\\times4$ lattice of random spins, let's define a Hamiltonian that will output the energy of this system in absence of any external magnetic field.\n", "\n", "$$\n", "H = -J \\sum_{i,j} \\sigma_{i} \\sigma_{j}\n", "$$\n", "\n", "To make the units simple, set $J=1$.\n", "\n", "For this grid, we will use wrap-around (i.e., video-game) coordinates whereby, e.g., the spin at $x=0,\\, y=2$ in a $4\\times4$ lattice can contribute to the $x=3,\\, y=2$ neighbor spin. A mathematical way to summarize this is, for the coordinate $j+1$, $\\forall j \\geq N ,\\, j+1\\rightarrow j \\mod N$. In this way, a relatively small lattice can effectively simulate what would happen in a much larger system.\n", "\n", "Let's give a bit more detail. The function `hamiltonian` will take a lattice of spins as input. The energy of each  spin in the lattice will have contributions from $4$ neighbors. For example, the spin at position `(i,j)` will have one contribution from the spin at poisition `(i, (j+1)%N)`, where the `%N` notation takes care of the wrap-around boundary conditions. Of course, the interaction energy for the other 3 neighbors should be added for the spin at this position. Be sure not to double count!\n", "\n", "Complete the code, which should give a value of $4$ for the random seed defined by `np.random.seed(20)` in `PROJ3.1-runcell01` and $\\pm8$ for the other two cases listed.\n"]}, {"cell_type": "code", "execution_count": null, "id": "95f3cf9b", "metadata": {"tags": ["draft", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>PROBLEM: PROJ3.1.1\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "def hamiltonian(iArr,N):\n", "    energy = None #YOUR CODE HERE\n", "    return energy\n", "\n", "\n", "#TESTS\n", "#-----\n", "N=4\n", "\n", "np.random.seed(20)\n", "test1=initialize(N)\n", "print('Test 1')\n", "print(test1)\n", "print('test value =',hamiltonian(test1,N))\n", "print('should be  = 4.0')\n", "print()\n", "\n", "\n", "np.random.seed(42)\n", "test2=initialize(N)\n", "print('Test 2')\n", "print(test2)\n", "print('test value =',hamiltonian(test2,N))\n", "print('should be  = -8.0')\n", "print()\n", "\n", "np.random.seed(4)\n", "test3=initialize(N)\n", "print('Test 3')\n", "print(test3)\n", "print('test value =',hamiltonian(test3,N))\n", "print('should be  = 8.0')\n", "print()"]}, {"cell_type": "markdown", "id": "e21aced3", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Checkpoint 3.1.2</span>\n", "\n", "Now, we would like to come up with a strategy to evolve the spin configurations of the Ising model. To do this we are going to follow a Markov Chain Monte-Carlo Proposal strategy, where we flip the spin at a given lattice site and decide whether to accept or reject the flip based on the change in energy and a temperature parameter.\n", "\n", "For this, write a Metropolis algorithm for the function `flip` that does the following:\n", "\n", "* Takes indices `[i,j]`, the array of spins `iArr`, the array size `N`, and the parameter `Beta` as inputs. Note, the indices that are given can also be numpy arrays, not just singular values.\n", "* Considers the spin state (or states) of the `[i,j]`-th element(s) of the grid `iArr`.\n", "* Computes the change in energy for a particular element if it were flipped, i.e.: $\\Delta H=E_{\\rm after}-E_{\\rm before}$\n", "* Updates the spin state with acceptance probability $p < e^{\\large{-\\frac{\\Delta H}{k_{b} T} }}$, based on these criteria:\n", "\n", "    * If the energy change is negative or zero (the flip would decrease the energy or leave it unchanged), $p=1$.\n", "    * If the energy change is positive (the flip would increase the energy), $p=\\exp\u2061{\u2212\\Delta H \\beta}$.\n", "    * For $p<1$, take a random number from a uniform distribution. Update the spin flip if the random number is less than the acceptance probability. Otherwise, do not update the spin flip.\n", "\n", "\n", "Note that we often define temperature in the Ising model using the parameter $\\beta={1}/{k_{b}T}$. Additionally, to make our units extra simple, we will set the Boltzman Constant $k_{b}=1$.\n", "\n", "Finally, you will see in the tests below, we will want flip to not just work on single `[i,j]`, but we will want it to work on an array of `[i,j]`. Do all of this in parallel on the array using numpy tools.\n", "\n", "We provide several cases that you can use to test your function against expected values. In the solution, we provide a function that prints additional information, to make the actions of this algorithm more apparent."]}, {"cell_type": "code", "execution_count": null, "id": "3392f106", "metadata": {"tags": ["draft", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>PROBLEM: PROJ3.1.2\n", "\n", "def flip(i,j,iArr,N,Beta):\n", "    #YOUR CODE HERE\n", "    return\n", "\n", "#THE CODE BELOW SHOULD PRODUCE THE OUTCOMES\n", "#THAT ARE INDICATED IN EACH CASE\n", "N=4\n", "\n", "#TRIAL 1: FLIP\n", "######\n", "np.random.seed(20)\n", "test1=initialize(N)\n", "TM1 = 0.01\n", "print('TRIAL 1: TM1 =', TM1)\n", "print('Array')\n", "print(test1)\n", "print(\"Spin State Before Flip [0,0]:\",test1[0,0])\n", "flip(0,0,test1,N,TM1)\n", "print(\"Spin State After Flip [0,0]:\",test1[0,0])\n", "print(\"Summary: This flips automatically because the change in energy is negative.\")\n", "print()\n", "\n", "\n", "#TRIAL 2: FLIP\n", "######\n", "np.random.seed(20)\n", "test2=initialize(N)\n", "TM1 = 0.01\n", "print('TRIAL 2: TM1 =', TM1)\n", "print('Array')\n", "print(test2)\n", "print(\"Spin State Before Flip [2,1]:\",test2[2,1])\n", "flip(2,1,test2,N,TM1)\n", "print(\"Spin State After Flip [2,1]:\",test2[2,1])\n", "print(\"Summary: This flips automatically because the change in energy is zero.\")\n", "print()\n", "\n", "\n", "#TRIAL 3: FLIP\n", "######\n", "np.random.seed(20)\n", "test3=initialize(N)\n", "TM1 = 0.01\n", "print('TRIAL 3: TM1 =', TM1)\n", "print('Array')\n", "print(test3)\n", "print(\"Spin State Before Flip [3,1]:\",test3[3,1])\n", "flip(3,1,test3,N,TM1)\n", "print(\"Spin State After Flip [3,1]:\",test3[3,1])\n", "print(\"Summary: This flips because the flip probability was higher than the randomly drawn number.\\nHigh temperature makes this more likely.\")\n", "print()\n", "\n", "\n", "#TRIAL 4: FLIP\n", "######\n", "np.random.seed(20)\n", "test4=initialize(N)\n", "TM1 = 1.0\n", "print('TRIAL 4: TM1 =', TM1)\n", "print('Array')\n", "print(test4)\n", "print(\"Spin State Before Flip [3,1]:\",test4[3,1])\n", "flip(3,1,test4,N,TM1)\n", "print(\"Spin State After Flip [3,1]:\",test4[3,1])\n", "print(\"Summary: This DOES NOT FLIP because the flip probability was lower than the randomly drawn number.\\nWe looked at the same spin as Trial 3, but lower temperature (thus lower flip probability).\")\n", "print()\n", "\n", "\n", "#ADDITIONAL TESTS\n", "\n", "#TRIAL 5: Two Flips\n", "######\n", "np.random.seed(20)\n", "test5=initialize(N)\n", "TM1 = 0.1\n", "print('TRIAL 5: TM1 =', TM1)\n", "print('Array')\n", "print(test5)\n", "print(\"Spin States Before Flip [3,1], [1,1] (should be -1 -1):\",test5[3,1],test5[1,1])\n", "iarr=np.array([3,1]) #spin i-indices\n", "jarr=np.array([1,1]) #spin j-indices\n", "flip(iarr,jarr,test5,N,0.1)\n", "print(\"Spin States After Flip [3,1], [1,1] (should be -1 1):\",test5[3,1],test5[1,1])\n", "print()\n", "\n", "\n", "#TRIAL 6: Two Flips\n", "######\n", "np.random.seed(20)\n", "test6=initialize(N)\n", "TM1 = 0.1\n", "print('TRIAL 6: TM1 =', TM1)\n", "print('Array')\n", "print(test6)\n", "print(\"Spin States Before Flip [1,2], [1,1] (should be 1 -1):\",test6[1,2],test6[1,1])\n", "iarr=np.array([1,2]) #spin i-indices\n", "jarr=np.array([1,1]) #spin j-indices\n", "flip(iarr,jarr,test6,N,0.1)\n", "print(\"Spin States After Flip [3,1], [1,1] (should be 1 1):\",test6[1,2],test6[1,1])\n"]}, {"cell_type": "markdown", "id": "43730cae", "metadata": {"tags": ["learner", "md", "learner_chopped", "catsoop_01"]}, "source": ["<h3>Updating Spins with the Checkerboard Pattern</h3>\n", "\n", "It's straightforward to decide whether or not to flip a single spin, but how do we update a whole 2D array? One approach would be to flip the spins one-by-one, which is just far too time-consuming. If taking this approach (which you could try), you have to be mindful of randomly choosing spins, in order to avoid any bias.\n", "\n", "If we consider updating multiple spins at once, we must also avoid updating adjacent points at the same time, as this would lead to a somewhat inconsistent Hamiltonian update because the Hamiltonian of a single point is dependent on the neighbors. Now, it turns out that random, Poisson updates of multiple spins can produce the right phase transition, but we will take a more effective approach.\n", "\n", "**Ultimately, the most robust method is to apply updates in a checkerboard pattern.** A checkerboard pattern aims to update nodes that are NOT adjacent to one another. In this way, we can update the maximum amount of nodes in a single update. See this <a href=\"https://medium.com/@kherzieandal/the-checkerboard-metropolis-algorithm-explained-1ecdd301d17d\" target=\"_blank\">article</a> for more information."]}, {"cell_type": "markdown", "id": "038a88f7", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Checkpoint 3.1.3</span>\n", "\n", "Complete the `update_rand` code below to do the following:\n", "\n", "1. **Determine Update Subset**: Set `update` to either 0 or 1 depending on whether the current `index` is even or odd. This is used to determine whether to update the \"white\" or \"black\" squares of the checkerboard pattern.<br><br>\n", "\n", "2. **Create Index Array `ir`**: Create an array `ir` that holds the indices of either the white or black cells in the flattened version of the grid (i.e., treating the `N x N` array as a 1D array).<br><br>\n", "\n", "3. **Adjust `ir` for Checkerboard Pattern**: Use a loop to adjust the indices to account for the alternating pattern of rows in a true 2D checkerboard. For each row, ensure that the correct alternating pattern of updates (black or white squares) is applied. The final `ir` array should hold the 1D indices of the cells to be updated.<br><br>\n", "\n", "4. **Convert 1D Indices to 2D Coordinates**: Convert the 1D indices in `ir` to the X (row) coordinates and Y (column) coordinates. [Hint: You may find the Python arithmetic operators `%` (discussed previously) and `//` helpful.]<br><br>\n", "\n", "5. **Flip the Lattice Sites**: Call the function `flip` is to actually update the lattice at the specified X and Y coordinates.\n"]}, {"cell_type": "code", "execution_count": null, "id": "79465679", "metadata": {"tags": ["draft", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>PROBLEM: PROJ3.1.3\n", "\n", "\n", "def update_rand(iArr,N,TM1,index):\n", "    #determine the update subset (white or black)\n", "    update = index % 2\n", "    \n", "    #create index array \n", "    ir = np.arange(0,N*N//2)*2 + update\n", "    \n", "    #define checkerboard in ir\n", "    for row in range(N):\n", "        #YOUR CODE HERE\n", "        \n", "    #convert 1D indices to 2D coordinates\n", "    checkerboardsX = #YOUR CODE HERE\n", "    checkerboardsY = #YOUR CODE HERE\n", "    \n", "    #flip the lattice sites\n", "    flip(checkerboardsX,checkerboardsY,iArr,N,TM1)\n", "    return\n", "\n", "\n", "#THE CODE BELOW SHOULD PRODUCE THE INDICATED OUTCOME\n", "N=4\n", "TM1=1\n", "\n", "np.random.seed(20)\n", "test0=initialize(N)\n", "test1=initialize(N)\n", "test2=initialize(N)\n", "\n", "###Part 1\n", "update_rand(test1,N,TM1,0)\n", "print('Test 1')\n", "print(\"Diff After Rand Flip [YOUR CODE]:\", test1.flatten() - test0.flatten())\n", "print(\"Diff After Rand Flip [SHOULD BE]:\", '[  0  0 -2  0  0  0 -2  2  0  0 -2  2  2  0  2  0]' )\n", "print()\n", "\n", "\n", "###Part 2\n", "update_rand(test2,N,TM1,1)\n", "print('Test 2')\n", "print(\"Diff After Rand Flip [YOUR CODE]:\", test2.flatten() - test0.flatten())\n", "print(\"Diff After Rand Flip [SHOULD BE]:\", '[ -2  2  0 -2  2  2  0  0  0  2  0  0  0  0  2 -2 ]' )\n", "print()\n", "\n", "###Part 3, combined\n", "update_rand(test1,N,TM1,1)\n", "print('Test 3')\n", "print(\"Diff After Rand Flip [YOUR CODE]:\", test1.flatten() - test0.flatten())\n", "print(\"Diff After Rand Flip [SHOULD BE]:\", '[  0  0 -2  0  0  0 -2  2  0  0 -2  2  2  0  2  0] ' )\n", "print()"]}, {"cell_type": "markdown", "id": "c168cbec", "metadata": {"tags": ["learner", "md", "catsoop_01"]}, "source": ["<h3>Visualizing the Simulation</h3>\n", "\n", "Finally, we can put it all together by adding a plotting function that allows us to visualize the evolution of spins according to the Ising model. We will make use of the energy and magnetization in the next section.\n", "\n", "First, we define the `mapPlot` function, which plots the grid and saves it as images that we can then turn into an animated gif.\n", "\n", "Next, we include this plotting functionality into a simulation which does the following:  \n", "  * initializes a random array of spins, then updates the spin states for a number of steps `eqSteps`, which effectively evolves a random configuration to a stable state. This is the usual equilibration stage, we often seen in the markov chain process.  \n", "  * Runs a Markov Chain Monte-Carlo simulation after the equilibration step, which similarly randomly flips spins and accumulates the sum of the energy and magnetization of each state\n", "  * Plots the spin state every 5 steps\n", "  \n", "**Run the code below to define these functions.**\n", "\n", "\n", "In the questions below, we will set the grid size to $32\\times 32$ and explore what the visualization has to offer by varying the tempature from `5` to `0.05`. Consider how the Ising model behaves at different temperatures. Does the visualization show any evidence for a phase transition?"]}, {"cell_type": "code", "execution_count": null, "id": "b26133bb", "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 843}, "id": "5ebb68c1", "outputId": "21c3a317-2dbe-4c69-df80-f98a8554e802", "tags": ["py", "learner", "learner_chopped", "catsoop_01"]}, "outputs": [], "source": ["#>>>RUN: PROJ3.1-runcell02\n", "\n", "from IPython.display import Image\n", "\n", "def mapPlot(ax,fig, iArr, i, N, images):\n", "    plt.cla()\n", "    X, Y = np.meshgrid(range(N), range(N))\n", "    ax.pcolormesh(X, Y, iArr, cmap=plt.cm.RdBu);\n", "    ax.text(0.6, 0.3,'Time=%d'%i,fontdict={'size': 24, 'color':  'red'})#; plt.axis('tight')    \n", "    fig.canvas.draw()       # draw the canvas, cache the renderer\n", "    image  = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n", "    image  = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n", "    images.append(image)\n", "\n", "def runTemp_fig(iT,iN,images,fig,ax,eqSteps=500,mcSteps=100):\n", "    pArr = initialize(iN)         # initialise\n", "    beta=1.0/iT \n", "    for i in range(eqSteps):         # equilibrate\n", "        update_rand(pArr, iN, beta,i) \n", "    \n", "    for i in range(mcSteps):\n", "        update_rand(pArr, iN, beta,i)           \n", "        if i % 5 == 0: \n", "            mapPlot(ax,fig,pArr,i,iN,images)\n", "            "]}, {"cell_type": "markdown", "id": "4c3d7c89", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Checkpoint 3.1.4</span>\n", "\n", "In the cell below, define the simulation temperature to be `Temp=5` (this is the default setting). Run the simulation and examine the output (where red and blue rectangles indicate the two spin states). What behavior do you observe? **Try running several times to see a variety of possible outcomes.**\n", "\n", "Choose from the following potential observations (select ALL that apply):\n", "\n", "A) The system can have a striated pattern, where boundaries form between spins states.\n", "\n", "B) The system remains in a single state over time (i.e., all spin up or down).\n", "\n", "C) The system is nearly all in the same state, with small local fluctuations.\n", "\n", "D) The overall spin state of the system fluctuates between almost all up and almost all down.\n", "\n", "E) The spin state appears mostly randomized, but some structure exists.\n", "\n", "F) The spin state is always completely randomized and there is no order.\n"]}, {"cell_type": "code", "execution_count": null, "id": "96b73014", "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 843}, "id": "5ebb68c1", "outputId": "21c3a317-2dbe-4c69-df80-f98a8554e802", "tags": ["py", "learner_chopped", "draft"]}, "outputs": [], "source": ["#>>>PROBLEM: PROJ3.1.4\n", "            \n", "images=[]\n", "fig, ax = plt.subplots(figsize=(12,7))\n", "\n", "# Modify this line to study different temperatures\n", "Temp=5.\n", "\n", "runTemp_fig(Temp,32,images,fig,ax)\n", "imageio.mimsave('./test.gif', images, fps=10, loop=0)\n", "Image(open('test.gif','rb').read())\n", "#Double-click on the gif file in Colab to open"]}, {"cell_type": "markdown", "id": "b07a6f01", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Checkpoint 3.1.5</span>\n", "\n", "Define the simulation temperature to be `Temp=2.5`, then run the simulation and examine the output. **Try running several times to see a variety of possible outcomes.**\n", "\n", "Choose from the following potential observations (select ALL that apply):\n", "\n", "A) The system can have a striated pattern, where boundaries form between spins states.\n", "\n", "B) The system remains in a single state over time (i.e., all spin up or down).\n", "\n", "C) The system is nearly all in the same state, with small local fluctuations.\n", "\n", "D) The overall spin state of the system fluctuates between almost all up and almost all down.\n", "\n", "E) The spin state appears mostly randomized, but some structure exists.\n", "\n", "F) The spin state is always completely randomized and there is no order.\n"]}, {"cell_type": "markdown", "id": "41737bda", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Checkpoint 3.1.6</span>\n", "\n", "Define the simulation temperature to be `Temp=1.25`, then run the simulation and examine the output. **Try running several times to see a variety of possible outcomes.**\n", "\n", "A) The system can have a striated pattern, where boundaries form between spins states.\n", "\n", "B) The system remains in a single state over time (i.e., all spin up or down).\n", "\n", "C) The system is nearly all in the same state, with small local fluctuations.\n", "\n", "D) The overall spin state of the system fluctuates between almost all up and almost all down.\n", "\n", "E) The spin state appears mostly randomized, but some structure exists.\n", "\n", "F) The spin state is always completely randomized and there is no order.\n"]}, {"cell_type": "markdown", "id": "506ad92d", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Checkpoint 3.1.7</span>\n", "\n", "Define the simulation temperature to be `Temp=0.5`, then run the simulation and examine the output. **Try running several times to see a variety of possible outcomes.**\n", "\n", "A) The system can have a striated pattern, where boundaries form between spins states.\n", "\n", "B) The system remains in a single state over time (i.e., all spin up or down).\n", "\n", "C) The system is nearly all in the same state, with small local fluctuations.\n", "\n", "D) The overall spin state of the system fluctuates between almost all up and almost all down.\n", "\n", "E) The spin state appears mostly randomized, but some structure exists.\n", "\n", "F) The spin state is always completely randomized and there is no order.\n"]}, {"cell_type": "markdown", "id": "fcd65797", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Checkpoint 3.1.8</span>\n", "\n", "Define the simulation temperature to be `Temp=0.05`, then run the simulation and examine the output. **Try running several times to see a variety of possible outcomes.**\n", "\n", "A) The system can have a striated pattern, where boundaries form between spins states.\n", "\n", "B) The system remains in a single state over time (i.e., all spin up or down).\n", "\n", "C) The system is nearly all in the same state, with small local fluctuations.\n", "\n", "D) The overall spin state of the system fluctuates between almost all up and almost all down.\n", "\n", "E) The spin state appears mostly randomized, but some structure exists.\n", "\n", "F) The spin state is always completely randomized and there is no order.\n"]}, {"cell_type": "markdown", "id": "fec85a8a", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_3_2'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">PROJ3.2 Modeling the Phase transition</h2>    \n", "\n", "| [Top](#section_3_0) | [Previous Section](#section_3_1) | [Checkpoints](#problems_3_2) | [Next Section](#section_3_3) |\n", "\n"]}, {"cell_type": "markdown", "id": "24a09f2f", "metadata": {"tags": ["learner", "md", "catsoop_02"]}, "source": ["<h3>Overview</h3>\n", "\n", "With everything that we have developed, we can compute some quantities that characterize the properties of the system. In particular, we would like to compute the following quantities (per spin), where the brackets $\\langle \\rangle$ represent averages taken over the number of steps in the simulation:\n", "\n", " * Average Energy $\\langle E \\rangle$\n", " * Average Magnetization $\\langle M \\rangle$ (ultimately, we will want to plot $|\\langle M \\rangle|$)\n", " * Specific Heat $C=\\frac{\\langle E^{2}\\rangle - \\langle E\\rangle^{2}}{T^{2}}$ where $\\langle E\\rangle$ and $\\langle E^2\\rangle$ are the energy and energy squared, respectively\n", " * Magnetic Susceptibility $\\chi=\\frac{\\langle M^{2}\\rangle - \\langle M\\rangle^{2}}{T}$ where $\\langle M\\rangle$ and $\\langle M^2\\rangle$ are the magnetization and magnetization squared, respectively\n", " \n", "We can look for sharp changes in the behavior of these quantities as we scan the temperature. Such jumps are indicative of the system going through a phase transition. The specific heat, in particular, has should exhibit a discontinuity right at a phase trasition."]}, {"cell_type": "markdown", "id": "b5fcfa26", "metadata": {"id": "2f413bd5", "tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='problems_3_2'></a>     \n", "\n", "| [Top](#section_3_0) | [Restart Section](#section_3_2) | [Next Section](#section_3_3) |"]}, {"cell_type": "markdown", "id": "81b283f3", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Checkpoint 3.1.3</span>\n", "\n", "First let's define a quantity we haven't used yet, the total magnetization of the system. This is just the sum over *all* of the magnetizations due to the spins in the array:\n", "\n", "$$\n", "M=\\sum_{i\\in {\\rm Lattice}} \\sigma_{i},\n", "$$\n", "\n", "Write a function to do this. We have written some checks that calculate the magnetization after applying the `flip` function to different spins, at various temperatures. Your value should match the expected values in these cases."]}, {"cell_type": "code", "execution_count": null, "id": "b9ae0af6", "metadata": {"tags": ["draft", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>PROBLEM: PROJ3.2.1\n", "\n", "def mag(iArr):\n", "    return \n", "\n", "\n", "#THE CODE BELOW SHOULD PRODUCE THE OUTCOMES\n", "#THAT ARE INDICATED IN EACH CASE\n", "N=4\n", "\n", "#TRIAL 1\n", "######\n", "np.random.seed(20)\n", "test1=initialize(N)\n", "\n", "print('TRIAL 1')\n", "flip(0,0,test1,N,0.01)\n", "print(\"magnetization:\",mag(test1))\n", "print('Should be -4 if you flipped 0,0 correctly')\n", "print()\n", "\n", "\n", "#TRIAL 2\n", "######\n", "np.random.seed(20)\n", "test2=initialize(N)\n", "\n", "print('TRIAL 2')\n", "flip(2,1,test2,N,0.01)\n", "print(\"magnetization:\",mag(test2))\n", "print('Should be 0 if you flipped 2,1 correctly')\n", "print()\n", "\n", "#TRIAL 3\n", "######\n", "np.random.seed(20)\n", "test3=initialize(N)\n", "\n", "print('TRIAL 3')\n", "flip(3,1,test3,N,0.01)\n", "print(\"magnetization:\",mag(test3))\n", "print('Should be 0 if you flipped 3,1 correctly')\n", "print()\n", "\n", "\n", "#TRIAL 4\n", "######\n", "np.random.seed(20)\n", "test4=initialize(N)\n", "\n", "print('TRIAL 4')\n", "flip(3,1,test4,N,1.0)\n", "print(\"magnetization:\",mag(test4))\n", "print('Should be -2 if you flipped 3,1 correctly')"]}, {"cell_type": "markdown", "id": "0fbdcb52", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Checkpoint 3.2.2</span>\n", "\n", "Now modify the function `runTemp` to expicitly output the quatities outlined above: average energy, average magnetization, specific heat, and magnetic susceptibility (where the average is taken over the steps performed in `mcSteps`). Note that these quantities should be normalized by the total number of spins.\n"]}, {"cell_type": "code", "execution_count": null, "id": "b3ff314c", "metadata": {"tags": ["draft", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>PROBLEM: PROJ3.2.2\n", "\n", "def runTemp(iT,iN,eqSteps=500,mcSteps=100):\n", "    pArr = initialize(iN)         # initialise\n", "    E1 = M1 = E2 = M2 = 0 #initial values\n", "    beta=1.0/iT \n", "    for i in range(eqSteps):         # equilibrate\n", "        update_rand(pArr, iN, beta,i) \n", "    \n", "    for i in range(mcSteps):\n", "        update_rand(pArr, iN, beta,i)        \n", "        Ene = hamiltonian(pArr, iN)     # calculate the energy\n", "        Mag = mag(pArr)       # calculate the magnetisation\n", "        \n", "        #summing the quantities over all simulation steps\n", "        E1 = E1 + Ene\n", "        M1 = M1 + Mag\n", "        M2 = M2 + Mag*Mag \n", "        E2 = E2 + Ene*Ene\n", "        \n", "    #compute the values for E,M,C,X here\n", "    E = #average energy per spin\n", "    M = #average magnetization per spin\n", "    C = #heat capacity per spin\n", "    X = #magnetic susceptibility per spin\n", "    \n", "    return E,M,C,X\n", "\n", "\n", "#CHECK ON INITIAL ARRAY\n", "np.random.seed(0)\n", "E,M,C,X = runTemp(1.,32)\n", "#below should print: [-1.8433, -0.2179, 0.0976, 12.5131]\n", "print(list(np.round(np.array([E,M,C,X]),4)))\n", "print()\n", "\n", "np.random.seed(20)\n", "E,M,C,X = runTemp(1.,32)\n", "#below should print: [-1.9973, 0.9993, 0.024, 0.0015]\n", "print(list(np.round(np.array([E,M,C,X]),4)))\n", "print()\n", "\n", "np.random.seed(20)\n", "E,M,C,X = runTemp(0.01,32)\n", "#below should print: [-2.0, 1.0, 0.0, 0.0]\n", "print(list(np.round(np.array([E,M,C,X]),4)))\n", "print()"]}, {"cell_type": "markdown", "id": "3bbe3ded", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Checkpoint 3.2.3</span>\n", "\n", "Now, find the values of these quantities as a function of temperature to see if any discontinuous behavior is observed. Complete the code below to make a scan of temperature from about $T = 1.5$ to $3.5$ (units of $J/k_{b}$), then plot the results. The quantity `tqdm` is used to indicate the progress of the computation.\n", "\n", "**Note: Averaging over several runs will make things clearer.** Try setting `num_simulations=1` to start, then increase depending on your patience.\n", "\n", "Looking at the plots of $E$, $|M|$, $C$, and $\\chi$, do you observe any behavior that might be indicative of a phase transition? **What is the critical temperature at which a phase transition occurs?** Enter your answer as a number indicating the approximate temperature where a phase transition occurs, in units of $J/k_{b}$. Use precision `0.5`.\n", "\n", "After you have submitted a correct answer, be sure to us the `Show Answer` option. The explanation provides further insight into these topics. There is also plenty of literature about the approximate theoretical value that you should find."]}, {"cell_type": "code", "execution_count": null, "id": "8816d9ed", "metadata": {"tags": ["draft", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>PROBLEM: PROJ3.2.3\n", "\n", "N = #something (your choice, choose wisely)\n", "nt = #number of temperature points\n", "num_simulations = #number of simulations to average over\n", "T  = #np.linspace(1.5-ish,3.5-ish,nt) #again choose wisely\n", "\n", "E,M,C,X = np.zeros(nt), np.zeros(nt), np.zeros(nt), np.zeros(nt)\n", "\n", "for temp in tqdm(range(nt), desc=\"Loading...\"):\n", "    E_temp, M_temp, C_temp, X_temp = 0, 0, 0, 0  # Initialize accumulators for averaging\n", "\n", "    for _ in range(num_simulations):\n", "        e, m, c, x = runTemp(T[temp], N, eqSteps=1000, mcSteps=1000) #<-change eqSteps and mcSteps if desired\n", "        E_temp += e\n", "        M_temp += np.abs(m) #store the absolute value of the magnetization for each run\n", "        C_temp += c\n", "        X_temp += x\n", "\n", "    # Compute the average values and store them\n", "    E[temp] = E_temp / num_simulations\n", "    M[temp] = M_temp / num_simulations\n", "    C[temp] = C_temp / num_simulations\n", "    X[temp] = X_temp / num_simulations\n", "    \n", "f = plt.figure(figsize=(18, 10)); #  \n", "\n", "sp =  f.add_subplot(2, 2, 1 );\n", "plt.scatter(T, E, s=50, marker='o', color='red')\n", "plt.xlabel(\"Temperature (T)\", fontsize=20);\n", "plt.ylabel(\"Energy \", fontsize=20);\n", "plt.axis('tight');\n", "\n", "\n", "sp =  f.add_subplot(2, 2, 2 );\n", "#Plot magnetization (absolute value)\n", "\n", "sp =  f.add_subplot(2, 2, 3 );\n", "#Plot specific heat\n", "\n", "sp =  f.add_subplot(2, 2, 4 );\n", "#Plot magnetic susceptibility"]}, {"cell_type": "markdown", "id": "5dace6c5", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_3_3'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">PROJ3.3 Constructing Ising Model Simulation</h2>    \n", "\n", "| [Top](#section_3_0) | [Previous Section](#section_3_2) | [Checkpoints](#problems_3_3) | [Next Section](#section_3_4) |"]}, {"cell_type": "markdown", "id": "ecbc7b55", "metadata": {"tags": ["learner", "md", "catsoop_03"]}, "source": ["<h3>Training an NN</h3>\n", "\n", "Now that we have generated an Ising model, we want to build an optimized scheme to run the Ising model many times so that we can train a neural network to understand the critical temperature for the lattice we are working with.\n", "\n", "For this part of the project, we would like to generate Ising Monte Carlo Simulations where we randomly sample many configurations, and we the evolve the configuration at a specific temperature and then save it. Practically, this means we need to make simulated events where in each event we do the following:\n", "\n", "- Randomly sample a configutaion<br>\n", "- Evolve that config N steps<br>\n", "- Save the evolved configuration, magnetization, and temperature<br>\n", "- Repeat the above `nsim` times and write this all to disk\n", "\n", "Once, we have done that then we can use the datasets have generated to make a neural network that takes as input the random configuration and outputs the temperature."]}, {"cell_type": "markdown", "id": "f8dfa7fc", "metadata": {"id": "2f413bd5", "tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='problems_3_3'></a>     \n", "\n", "| [Top](#section_3_0) | [Restart Section](#section_3_3) | [Next Section](#section_3_4) |"]}, {"cell_type": "markdown", "id": "fcfd3cdd", "metadata": {"tags": ["learner", "md", "catsoop_03"]}, "source": ["<h3>Generating Ising Configurations</h3>\n", "\n", "We will start by making a class that generates Ising configurations. We can use some of the previous functions and what we learned above. **We will provide some unfinished code below and then ask some questions about it.** Let's start with an overview of what it does.\n", "\n", "<h3>Overview</h3>\n", "\n", "**Initialization (`__init__`)**: `iN` is the size of the 2D lattice (NxN), `Temp` is the temperature of the system, and the lattice (`self.arr`) is initialized with random spins. The arrays to store energy (`E`), magnetization (`M`), specific heat (`C`), and susceptibility (`X`) are initialized.\n", "\n", "**`initialize()`**: Generates a random NxN array of spins, with values of either `-1` or `1`, as defined previously in this notebook.\n", "\n", "**`simulate()`**: Runs the simulation for a defined number of steps (`self.steps`). In each step, the lattice is updated using the `update_rand` function, which applies the Metropolis-Hastings algorithm to flip spins. The energy and magnetization are calculated at each step, and the specific heat (`C`) and susceptibility (`X`) are also calculated.\n", "\n", "**`simulate_save()`**: Runs multiple simulations (`self.nsim` times) and saves the final spin configurations and magnetization to an HDF5 file. The simulation results are stored in datasets within the file, labeled by temperature.\n", "\n", "**`lastAvg()`**: Computes the average energy, magnetization, specific heat, and susceptibility over the last 500 steps of the simulation.\n", "\n", "**`plotEvol()`**: Plots the evolution of energy, magnetization, specific heat, and susceptibility over the simulation steps."]}, {"cell_type": "code", "execution_count": null, "id": "6ab0957d", "metadata": {"tags": ["draft", "py", "learner_chopped", "catsoop_03"]}, "outputs": [], "source": ["#>>>PROBLEM: PROJ3.3.1 - PROJ3.3.3\n", "\n", "#UNFINISHED CODE FOR CHECKPOINTS 3.3.1 - 3.3.3\n", "import h5py \n", "\n", "class Ising():\n", "    \n", "    def __init__(self, iN, Temp, steps=300):\n", "        self.N   = iN\n", "        self.T   = Temp\n", "        self.arr = self.initialize()\n", "        self.steps = steps\n", "        #History over simulatinp\n", "        self.E   = np.array([])\n", "        self.M   = np.array([])\n", "        self.C   = np.array([])\n", "        self.X   = np.array([])\n", "        self.nsim = 1000\n", "        \n", "    def initialize(self):   \n", "        state = 2*np.random.randint(2, size=(self.N,self.N))-1\n", "        return state\n", "    \n", "            \n", "    def simulate(self):\n", "        self.images=[]\n", "        N2M1 = 1./self.N/self.N\n", "        TM1  = 1./self.T\n", "        for i in range(self.steps):\n", "            update_rand(self.arr, self.N, TM1,i)           \n", "            Ene = hamiltonian(self.arr, N)\n", "            Mag = mag(self.arr)\n", "            \n", "            #Now save energy and magnetization\n", "            self.E   = np.append(self.E,Ene*N2M1)\n", "            self.M   = np.append(self.M,Mag*N2M1)\n", "\n", "            #Now COMPUTE specific Heat and Magnetic suscpetilibity\n", "            #HINT, consider what the meaning of RMS of Energy and Magnetization are\n", "            #Perhaps consider a sliding window over the last hundred steps\n", "            pC  = #code here\n", "            pX  = #code here\n", "            self.C   = np.append(self.C,pC)\n", "            self.X   = np.append(self.X,pX)\n", "            \n", "\n", "    def simulate_save(self,pre=''):\n", "        h5f  = h5py.File((pre)+'data_'+str(self.T)+'.h5', 'a')\n", "        data = np.array([])#np.empty((1,self.N,self.N), int)\n", "        mags = np.array([])\n", "        TM1  = 1./self.T\n", "        for n in range(self.nsim):\n", "            if n % 25 == 0:\n", "                print(\"sim\",n)\n", "            self.initialize()\n", "            ## Add code to run simulate the ising model nsteps\n", "            ## update self.arr  \n", "\n", "            #for each simulation we want to save the magnetization and the array      \n", "            pMag = mag(self.arr)\n", "            data = np.append(self.arr,data)\n", "            mags  = np.append(pMag,mags)\n", "        #now we write the output array into a dataset\n", "        data = np.reshape(data,(self.nsim,self.N,self.N))\n", "        h5f.create_dataset('data', data=data)\n", "        h5f.create_dataset('mag' , data=mags)\n", "        h5f.close()\n", "                    \n", "    def lastAvg(self):\n", "        avgE = np.mean(self.E[500:-1])\n", "        avgM = np.mean(self.M[500:-1])\n", "        avgC = np.std(self.E[500:-1])\n", "        avgX = np.std(self.M[500:-1])\n", "        return avgE,avgM,avgC,avgX\n", "        \n", "    def plotEvol(self):\n", "        ts = range(len(self.E))\n", "        f = plt.figure(figsize=(18, 10)); #  \n", "        sp =  f.add_subplot(2, 2, 1 );\n", "        plt.scatter(ts, self.E, s=50, marker='o', color='red')\n", "        plt.xlabel(\"step\", fontsize=20);\n", "        plt.ylabel(\"Energy \", fontsize=20);         plt.axis('tight');\n", "\n", "        #PLOT THE ENERGY, MAGNETIZATION (ABSOLUTE VALUE), SPECIFIC HEAT, AND SUSCEPTIBILITY\n", "        \n", "\n", "np.random.seed(20)\n", "nsim=10\n", "test = Ising(64,3.4,nsim)\n", "test.simulate()\n", "\n", "#PRINT VALUES\n", "print(\"Energy:\",test.E[-1],\"Magnetization:\",test.M[-1],\"Specific Heat:\",test.C[-1],\"Susceptibility:\",test.X[-1])\n", "#test.plotEvol()"]}, {"cell_type": "markdown", "id": "23c4c270", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Checkpoint 3.3.1</span>\n", "\n", "In the `simulate()` function above, which of the following options should be used to append the specific heat (`C`) and susceptibility (`X`) at each time step?\n", "\n", "A) `pC = np.std(self.E)` and `pX = np.std(self.M)`\n", "\n", "B) `pC = np.var(self.E)` and `pX = np.var(self.M)`\n", "\n", "C) `pC = np.std(self.E)*TM1**2.`and `pX = np.std(self.M)*TM1`\n", "\n", "D) `pC = np.var(self.E)*TM1**2.` and `pX = np.var(self.M)*TM1`\n", "\n", "E) `pC = np.std(self.E[-100:])` and `pX = np.std(self.M[-100:])`\n", "\n", "F) `pC = np.var(self.E[-100:])` and `pX = np.var(self.M[-100:])`\n", "\n", "G) `pC = np.std(self.E[-100:])*TM1**2.` and `pX = np.std(self.M[-100:])*TM1`\n", "\n", "H) `pC = np.var(self.E[-100:])*TM1**2.` and `pX = np.var(self.M[-100:])*TM1`\n", "\n"]}, {"cell_type": "markdown", "id": "830221cd", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Checkpoint 3.3.2</span>\n", "\n", "In the `simulate_save()` function, which of the following options should be used to simulate the Ising model steps?\n", "\n", "\n", "A) `for i in range(self.steps): update_rand(self.arr, self.N, TM1, i)`\n", "\n", "B) `for i in range(self.N): update_rand(self.arr, self.steps, TM1, i) ` \n", "\n", "C) `for step in range(self.steps): update_rand(self.arr, self.N, TM1, i)` \n", "\n", "D) `for step in range(self.N): update_rand(self.arr, self.N, TM1, i)` \n", "\n"]}, {"cell_type": "markdown", "id": "dc6ca69e", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Checkpoint 3.3.3</span>\n", "\n", "Fill in the code above based on your answers to the previous questions, then run the simulation with 10 steps and a fixed seed for N=64, at a temp of 3.4. Print the last value of `E`, `M`, `C`, and `X` (print statement already provided in code). Report the quantities with precision 1e-6.\n", "\n", "Note that there is a variability above about which checkerboard pattern to start with. We always start with the top left corner being flipped.  \n"]}, {"cell_type": "markdown", "id": "ab4592d5", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Checkpoint 3.3.4</span>\n", "\n", "Now complete the `plotEvol()` function in the class `Ising` to plot the energy, magnetization, specific heat, and susceptibility over time. Run the code cell below to generate 100 simulations with `N=64` and `T=3.4`. What features do you observe from the plots? Select ALL that apply:\n", "\n", "A) All the plots look completely noisy, with no clear trend.\\\n", "B) The effect of equilibration can be seen in some plots, and the quantities begin to settle afterwards.\\\n", "C) By the end of the simulation, the quantities no longer fluctuate at all.\n"]}, {"cell_type": "code", "execution_count": null, "id": "8c1b100f", "metadata": {"tags": ["py", "learner", "learner_chopped", "catsoop_03"]}, "outputs": [], "source": ["#>>>PROBLEM: PROJ3.3.4\n", "\n", "np.random.seed(20)\n", "test = Ising(64,3.4)\n", "test.nsim=100\n", "test.simulate()\n", "test.plotEvol()"]}, {"cell_type": "markdown", "id": "c289740b", "metadata": {"tags": ["learner", "md", "learner_chopped", "catsoop_03"]}, "source": ["<h3>Saving Simulation Data</h3>\n", "\n", "Let's save the data from above, where we ran 100 simulations with `N=64` and `T=3.4`. In the code below, we use `simulate_save` so save the data, then open the file and print some features. \n"]}, {"cell_type": "code", "execution_count": null, "id": "7be5c25c", "metadata": {"tags": ["py", "learner", "learner_chopped", "catsoop_03"]}, "outputs": [], "source": ["#>>>RUN: PROJ3.3-runcell01\n", "\n", "import os\n", "\n", "np.random.seed(20)\n", "test = Ising(64,3.4)\n", "test.nsim=100\n", "\n", "#write to disk\n", "#os.remove('data_3.4.h5') #first remove file if you need to run again\n", "test.simulate_save()\n", "!ls\n", "print(\"Lets Look at model\")\n", "f = h5py.File('data_3.4.h5', 'r')\n", "print(list(f.keys()))\n", "print(f['data'].shape)"]}, {"cell_type": "markdown", "id": "534c156e", "metadata": {"id": "534c156e", "tags": ["learner", "md", "catsoop_03"]}, "source": ["<h3>Setting Up Torch Dataset</h3>\n", "\n", "Now that we have a class to run our Ising model and save things to disk, we can go ahead and generate some samples following the code below. Let's first generate a test sample so that we understand how to train the neural network. For this, we will generate 10 test samples for each point, this shouldn't take too long, and will allow us to setup the neural network. Also, to make our Ising model manageable, lets use a `32x32` grid. \n", "\n", "Before we build the Neural Network, we are going to use Torch Dataset to process and format the data. Setting this up is a little annoying so we will just write the code for this down here, and we will provide a little example of how to read a Torch DataLoaer. \n"]}, {"cell_type": "code", "execution_count": null, "id": "e17fd1d0", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "e17fd1d0", "outputId": "a437e96d-d4b6-4d7b-ffaa-568a9d09e79c", "tags": ["learner", "learner_chopped", "catsoop_03", "py"]}, "outputs": [], "source": ["#>>>RUN: PROJ3.3-runcell02\n", "\n", "import os\n", "nt=20\n", "T       = np.round(np.linspace(1.53, 3.28, nt),2)\n", "print(T)\n", "for temp in tqdm (range (nt), desc=\"Loading...\"):\n", "    #Some hacky code to clean up things\n", "    filename='data_'+str(T[temp])+'.h5'\n", "    try:\n", "        os.remove(filename)\n", "    except OSError:\n", "        pass\n", "    test = Ising(32,T[temp])\n", "    test.nsim=500\n", "    test.simulate_save()\n", "    \n", "f = h5py.File('data_1.53.h5', 'r') \n", "list(f.keys())\n", "f['data'].shape\n", "!ls"]}, {"cell_type": "markdown", "id": "2af9ca2a", "metadata": {"id": "cb03b058", "tags": ["learner", "md", "catsoop_03"]}, "source": ["<h3>Develop a Neural Network: Part 1</h3>\n", "\n", "Now we would like to develop a neural network that will take in this dataset and train for whether the sample has undergone a phase transition (i.e., \"learn\" the phase transition). To do this, we are going to use binary cross entropy to learn the phase transition with a discrimination below and above the critical time $T_{C}$.\n", "\n", "Here is some unfinished code to accomplish the task, and we will ask some questions about it next."]}, {"cell_type": "code", "execution_count": null, "id": "20936cb5", "metadata": {"tags": ["draft", "py", "learner_chopped", "catsoop_03"]}, "outputs": [], "source": ["#>>>PROBLEM: PROJ3.3.5 - PROJ3.3.7\n", "\n", "class DataSet(Dataset):\n", "    def __init__(self, samples, labels, temps):\n", "        super(DataSet, self).__init__()\n", "        self.labels  = labels\n", "        self.samples = samples\n", "        self.temps   = temps\n", "        if len(samples) != len(labels):\n", "            raise ValueError(\n", "                f\"should have the same number of samples({len(samples)}) as there are labels({len(labels)})\")\n", "            \n", "    def __len__(self):\n", "        return len(self.labels)\n", "\n", "    def __getitem__(self, index):\n", "        y = self.labels[index]\n", "        x = self.samples[index]\n", "        t = self.temps[index]\n", "        return x, y, t\n", "\n", "\n", "#Here is some code to read all the different files and make a dataset\n", "all_data  = None\n", "all_temps = None\n", "for temp in tqdm (range (nt), desc=\"Loading...\"):\n", "    f = h5py.File('data_'+str(T[temp])+'.h5', 'r')\n", "    if temp == 0:\n", "        all_data  = f['data']\n", "        all_temps = np.ones(all_data.shape[0])*temp\n", "    else:\n", "        all_data  = np.append(all_data, f['data'],axis=0)\n", "        all_temps = np.append(all_temps,np.ones(f['data'].shape[0])*temp)\n", "    \n", "nones = #your code here\n", "all_data    = np.reshape(all_data,(all_data.shape[0],all_data.shape[1]*all_data.shape[2]))\n", "all_labels  = #build a numpy array that has labels 1 for below phase transition and 0 for above transition\n", "all_dataset = DataSet(samples=all_data.astype(\"float32\"),labels=all_labels,temps=all_temps)\n", "\n", "#Finally, we will split the dataset randomly\n", "data_train, data_test = #code to randomly split test and training\n", "\n", "#And a loader\n", "batch=10\n", "train_loader = #add the pytorch data loader\n", "\n", "#here is an example how it works\n", "for count, (x, y, t) in enumerate(train_loader):\n", "    print(count,\"x value:\",x,x.shape,\"\\n Label:\",y,y.shape,\"\\n Temp:\",t,t.shape)\n", "    if count > 2:\n", "        break\n", "        \n", "print(\"Total Length:\",len(data_train),all_data.shape,len(train_loader))"]}, {"cell_type": "markdown", "id": "5b426fb1", "metadata": {"id": "cb03b058", "tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Checkpoint 3.3.5</span>\n", "\n", "Lets first define the right labels. How do we define a cross entropy label for our dataset if we load our simulated samples and stack them all in temperature order from small to large? Which of the following options should we use to define `all_labels` (and optionally `nones`)? Note, you will have to cast this to a `float32` by using the function `.astype(\"float32\") `\n", "\n", "A) `all_labels = np.where(T[temp] < TC, 0, 1).astype(\"float32\")`\n", "\n", "B) `nones = len(all_temps[all_temps < TC])` and `all_labels = np.append(np.ones(nones),np.zeros(all_data.shape[0]-nones)).astype(\"float32\")`\n", "\n", "C) `all_labels = np.where(all_temps[temp] < 2.25, 0, 1).astype(\"float32\")\n", "`\n", "D) `all_labels = np.random.choice([0, 1], size=(all_data.shape[0],)).astype(\"float32\")`\n", "\n", "E) `nones = len(all_temps[all_temps < TC])` and `all_labels = np.append(np.ones(all_data.shape[0]-nones),np.zeros(nones)).astype(\"float32\")`\n"]}, {"cell_type": "markdown", "id": "0cde1661", "metadata": {"id": "cb03b058", "tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Checkpoint 3.3.6</span>\n", "\n", "Now let's split our data  into training and testing. Use the `random_split` function from `pytorch` and split it by 80% for training and 20% for testing. Which of the following options will accomplish this?\n", "\n", "A) `data_train, data_test = random_split(all_dataset, 0.8, 0.2)`\n", "  \n", "B) `data_train, data_test = random_split(all_dataset, 0.2, 0.8)`\n", "\n", "C) `data_train, data_test = random_split(all_dataset, [int(0.2 * all_data.shape[0]), len(all_dataset) - int(0.2 * all_data.shape[0])])`\n", "\n", "D) `data_train, data_test = random_split(all_dataset, [int(0.8 * all_data.shape[0]), len(all_dataset) - int(0.8 * all_data.shape[0])])`"]}, {"cell_type": "markdown", "id": "18e0cbe2", "metadata": {"id": "cb03b058", "tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Checkpoint 3.3.7</span>\n", "\n", "Ok now let's add a data loader that batches and shuffles the data, for batch of 10. What code should we use? Select the correct option below. Note, view the solution to this problem to see the complete code that combines all answers from the previous few problems.\n", "\n", "A) `train_loader=DataLoader(data_train, batch_size=10,shuffle=True)`\n", "\n", "B) `train_loader=DataLoader(data_train, batch_size=10)`\n", "\n", "C) `train_loader=DataLoader(data_train)`\n", "\n", "D) `train_loader=DataLoader(batch_size=10,shuffle=True,data_train)`\n", "\n", "E) `train_loader=DataLoader(10,True,data_train)`"]}, {"cell_type": "markdown", "id": "b09fef75", "metadata": {"id": "b09fef75", "tags": ["learner", "md", "learner_chopped", "catsoop_03"]}, "source": ["<h3>Develop a Neural Network: Part 2</h3>\n", "\n", "**First, complete and run the code cell above, related to checkpoints `3.3.5` through `3.3.7`. If needed, you can check our full version of this code in the solution to Checkpoint `3.3.7`.**\n", "\n", "Now finally, let's set up a neural network that reads in the inputs, and then trains to find the label. We will create a neural network that takes the input as a vector or image. After you follow the exercises below, you could return and create your own NN here, for instance a Dense network or a CNN. You should try different things!\n", "\n", "**As before, we will provide some incomplete code, then help you fill it in with the questions below.**"]}, {"cell_type": "code", "execution_count": null, "id": "8068dd28", "metadata": {"tags": ["draft", "py", "learner_chopped", "catsoop_03"]}, "outputs": [], "source": ["#>>>PROBLEM: PROJ3.3.8 - PROJ3.3.9\n", "\n", "class simple_MLP_4layer(torch.nn.Module):\n", "    def __init__(self,input_size,out_channels=1,nhidden=64):\n", "        super().__init__()\n", "        self.model = nn.Sequential(\n", "            #Design your own neural network\n", "        )\n", "        self.output  = torch.nn.Sigmoid()\n", "\n", "    def forward(self, x):\n", "        x = self.model(x)\n", "        x = self.output(x)\n", "        return x\n", "\n", "\n", "def train(model,n_epochs=20):\n", "    opt       = torch.optim.Adam(model.parameters(),lr=#YOUR CODE HERE)\n", "    criterion = #### come up with a loss function that is appropriate\n", "    for epoch in range(n_epochs):\n", "        model.train(True)\n", "        running_loss = 0.0; updates=0\n", "        for x, y, t in train_loader:\n", "            opt.zero_grad()\n", "            y_hat = model(x)\n", "            loss  = criterion(y_hat.flatten(),y)\n", "            loss.backward()\n", "            opt.step()\n", "            running_loss += loss\n", "            updates +=1\n", "            del x,y\n", "        print('Epoch: {} LOSS train: {} '.format(epoch,running_loss/(updates*batch)))\n", "\n", "model     = simple_MLP_4layer(all_data.shape[1],out_channels=1,act_out=True)\n", "train(model,n_epochs=10)"]}, {"cell_type": "markdown", "id": "b2e32c0a", "metadata": {"id": "b09fef75", "tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Checkpoint 3.3.8</span>\n", "\n", "As a baseline to get you started, define a 4 layer MLP (modify the code above to include that in the `simple_MLP_4layer` class). Which one of the choices of code gives you one layer that can be used to build a 4 layer MLP?\n", "\n", "A) `nn.Linear(nhidden, nhidden)` then `nn.ReLU()`\n", "     \n", "B) `nn.Linear(nhidden, nhidden)`\n", "\n", "C) `nn.ReLU()`\n", "\n", "D) `nn.Sigmoid`\n"]}, {"cell_type": "markdown", "id": "90130e6c", "metadata": {"id": "b09fef75", "tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Checkpoint 3.3.9</span>\n", "\n", "Now lets add a loss to the `train` function, that classifies the outputs as being above or below a certain temperature. What criterion should we apply? Select from the options below.\n", "\n", "**After completing this part, add you answers to the code cell above and run a training for 10 epochs, with a learning rate `lr < 0.01`. The solution to this problem will contain the full code that we used.**\n", "\n", "\n", "A) `criterion = nn.MSELoss()`\n", "\n", "B) `criterion = nn.CrossEntropyLoss()`\n", "\n", "C) `criterion = nn.BCELoss()`\n", "\n", "D) `criterion = nn.SmoothL1Loss()`\n"]}, {"cell_type": "markdown", "id": "848ad5c5", "metadata": {"id": "848ad5c5", "tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Checkpoint 3.3.10</span>\n", "\n", "Finally, run the validation below and report the temperature prediction of the neural network! Try running for more epochs if necessary to improve the prediction. What is the value of the predicted critical temperaure, with precision 1e-2?\n"]}, {"cell_type": "code", "execution_count": null, "id": "1afee1f8", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "3a21b382", "outputId": "63922958-83b2-4ed7-e359-55369563a530", "tags": ["py", "learner", "learner_chopped", "catsoop_03"]}, "outputs": [], "source": ["#>>>RUN: PROJ3.1-runcell03\n", "\n", "model.train(False)\n", "test_accuracy = Accuracy(task=\"binary\", num_classes=2)\n", "tplot  = np.array([])\n", "yplot  = np.zeros(len(T))\n", "ytrue  = np.zeros(len(T))\n", "ycount = np.zeros(len(T))\n", "ypred  = np.array([])\n", "yact   = np.array([])\n", "for x, y, t in train_loader:\n", "    with torch.no_grad():\n", "        y_hat = model(x)\n", "        ypred = np.append(ypred,y_hat)\n", "        yact = np.append(yact,y)\n", "        #tplot = np.append(tplot,t)\n", "        for pT,py_hat,py in zip(t.detach().numpy(),y_hat.detach().numpy(),y.detach().numpy()):\n", "            pT_index = np.where(T==pT)[0][0]\n", "            yplot[pT_index]  += py_hat[0]\n", "            ytrue[pT_index]  += py\n", "            ycount[pT_index] += 1\n", "            \n", "target = torch.tensor(ypred)\n", "preds  = torch.tensor(yact)\n", "print(\"Accuracy:\",test_accuracy(target,preds))\n", "yplot/=ycount\n", "ytrue/=ycount\n", "f = plt.figure(figsize=(9, 5));\n", "f.add_axes([0,0,1,1])#matplotlib.pyplot.figure()\n", "plt.plot(T,yplot, marker='o')\n", "plt.plot(T,ytrue, marker='o')\n", "plt.ylabel('Prediction')\n", "plt.xlabel('Tempareature(T)')\n", "plt.show()"]}, {"cell_type": "markdown", "id": "c0dab0bc", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_3_4'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">PROJ3.4 NN Application on Triangle Ising Model</h2>    \n", "\n", "| [Top](#section_3_0) | [Previous Section](#section_3_3) | [Checkpoints](#problems_3_4) | [Next Section](#section_3_5) |\n"]}, {"cell_type": "markdown", "id": "6f8671cb", "metadata": {"tags": ["learner", "md"]}, "source": ["<h3>Overview</h3>\n", "\n", "Once our validation is looking good, we want to show that our neural network has actually learned something non-trivial. For that we want to make a different magnetic field configuration with a different, but similar, Hamiltonian, and see if we can use our neural network to predict the temuprature change. **In particular, we are going to investigate the Triangular Ising Model.**\n", "\n", "We can define the Triangular Ising model as a triangular array, as opposed to a square array, like in the picture below: \n", "\n", "<p align=\"center\">\n", "<img alt=\"triangular lattice\" src=\"https://upload.wikimedia.org/wikipedia/commons/1/15/Tiling_3_simple.svg\" width=\"300\"/>\n", "</p>\n", "\n", ">source: https://upload.wikimedia.org/wikipedia/commons/1/15/Tiling_3_simple.svg\n", ">attribution: WatchduckYou can name the author as \"T. Piesk\", \"Tilman Piesk\" or \"Watchduck\"., CC BY 4.0 <https://creativecommons.org/licenses/by/4.0>, via Wikimedia Commons\n", "\n", "\n", "The Hamiltonian is again the Ising Hamiltonian, but now each site has 6 nearest neighbors, so we must sum over all 6 elements $i,j$ connected to a point: \n", "\n", "$$\n", "H = -\\frac{1}{2}\\sum_{i,j\\in{adjacent to i}} \\sigma_{i}\\sigma_{j} - h \\sum_{i} \\sigma_{i}\n", "$$\n", "\n", "This model for this Hamiltonian was presented in the paper below:\n", "\n", ">attribution: Badiev, M.K., Murtazaev, A.K., Ramazanov, M.K. et al. Ground-State Structures of the Ising Model on a Layered Triangular Lattice in a Magnetic Field. J. Exp. Theor. Phys. 134, 644\u2013649 (2022). https://doi.org/10.1134/S1063776122050016\n", "\n", "The first term is our usual interaction term, and the second term is the modification of the magnetization in the presence of an external magnetic field $h$. In this case we will set $h$ to zero and solve it when there is no external field. So our Hamiltonian will look like the one below. Note that all this term does is yield a global offset, it can be factorized from the problem. \n", "\n", "$$\n", "H = -\\frac{1}{2}\\sum_{i,j\\in{adjacent to i}} \\sigma_{i}\\sigma_{j}\n", "$$"]}, {"cell_type": "markdown", "id": "66087091", "metadata": {"id": "2f413bd5", "tags": ["learner", "md", "learner_chopped"]}, "source": ["<h3>Objective</h3>\n", "\n", "Using the Project 3 notebook, apply the neural network that you developed to this new Ising model and determine the phase transition temperature. Additionally, you may extend your investigation to explore other lattice geometries or an external magnetic field ($h\\neq0$). Is the NN flexible to a range of possibilities?\n"]}, {"cell_type": "markdown", "id": "60165529", "metadata": {"id": "2f413bd5", "tags": ["learner", "md", "learner_chopped"]}, "source": ["<h3>Expectations and Grading</h3>\n", "\n", "For this open-ended task, you will be expected to develop some procedure, analyze your results, and present your findings. Specifically, you will do the following:\n", "       \n", "1. Submit a pdf of your work on MITx, to be graded by your peers based on the criteria outlined below.\n", "2. Grade the work of others based on the same criteria.\n", "\n", "For full credit on this peer-reviewed checkpoint, we specifically expect you to complete these three tasks (and support your work with thorough explanation:\n", "\n", "- Section 1: Define and run a simulation and show that you can predict the transition tempearture. \n", "- Section 2: Explain your procedure.\n", "- Section 3: Describe your results, characterize the significance, and discuss (i.e., how sure are you that the NN found the right temperature, and what ways can you support your claims?)."]}, {"cell_type": "markdown", "id": "6cb0d0a0", "metadata": {"id": "2f413bd5", "tags": ["learner", "md", "learner_chopped"]}, "source": ["<h3>Peer-Evaluation Rubric</h3>\n", "\n", "Submit a pdf of your notebook below to MITx Online. Afterwards, you must peer-grade 3 submissions based on the criteria below (your submission will also be graded on these criteria):\n", "\n", "<p align=\"center\">\n", "<img alt=\"project 3 grading rubric\" src=\"https://raw.githubusercontent.com/mitx-8s50/images/main/PROJ3/rubric.png\" width=\"800\"/>\n", "</p>"]}, {"cell_type": "markdown", "id": "62c1b725", "metadata": {"id": "2f413bd5", "tags": ["learner", "md", "learner_chopped"]}, "source": ["<h3>Section 1: Define and Run the Simulation</h3>\n", "\n", "In this section you should do the following steps (and perhaps more that are not explicitly mentioned):\n", "\n", "- define a Hamiltonian\n", "- apply a MCMC for performing spin-flips (can you demonstrate that works as expected?)\n", "- run the NN on a dataset for Triangular Ising models\n", "- show that you can predict the correct tempearture (what is it?)\n", "\n", "**Begin your work below. You could use the starting code, if you wish.**"]}, {"cell_type": "code", "execution_count": null, "id": "00ff96dc", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "fc55fb75", "outputId": "e741a856-d9e4-49e3-9d94-75c0a841e6e6", "tags": ["py", "draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>PROBLEM: PROJ3.4.1\n", "\n", "#Now lets define the triangular ising model\n", "def hamiltonian(iArr,N):\n", "    #Compute the hamiltonian (note if you use this function you don't need to redeclare the above class)\n", "    #YOUR CODE HERE\n", "    return energy\n", "\n", "def flip(i,j,iArr,N,beta):\n", "    #run the Markov Chain process that computes delta energy, and based on the Markov decision flips the spins.\n", "    #YOUR CODE HERE\n", "    \n", "#Run some checks"]}, {"cell_type": "code", "execution_count": null, "id": "2b986708", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "fc55fb75", "outputId": "e741a856-d9e4-49e3-9d94-75c0a841e6e6", "tags": ["py", "draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>PROBLEM: PROJ3.4.2\n", "\n", "#write code to run some simulations and save neural network output."]}, {"cell_type": "code", "execution_count": null, "id": "40f968c3", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "fc55fb75", "outputId": "e741a856-d9e4-49e3-9d94-75c0a841e6e6", "tags": ["py", "draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>PROBLEM: PROJ3.4.3\n", "\n", "#read the data and output a dataset\n", "def load():\n", "    #YOUR CODE HERE\n", "    return data_tri_train, data_tri_test\n", "\n", "data_tri_train, data_tri_test = load()\n", "batch=1000\n", "test_tri_loader = DataLoader(data_tri_test, batch_size=batch,shuffle=True)\n", "\n", "#again following above, plot the temp applying your prevoiusly trained NN to the triagle boltzman\n", "model.train(False)\n", "for x, y, t in test_tri_loader:\n", "    with torch.no_grad():\n", "\n", "#What is accuracy?\n", "#plot Score vs Temp where is the phase transition, is it consistent with truth? (see arxiv paper)"]}, {"cell_type": "markdown", "id": "7d0704d0", "metadata": {"id": "2f413bd5", "tags": ["learner", "md", "learner_chopped"]}, "source": ["<h3>Section 2: Explanation of Procedure</h3>\n", "\n", "**Explain your code here:**\n", "\n"]}, {"cell_type": "markdown", "id": "24347bbd", "metadata": {"id": "2f413bd5", "tags": ["learner", "md", "learner_chopped"]}, "source": ["<h3>Section 3: Explanation of Results and Discussion</h3>\n", "\n", "**Describe your results here:**\n", "\n", "\n", "\n", "**Elaborate on some of the additional discussion points below:**\n", "\n", " * Do you see a phase transition?  \n", " * Does this agree with the paper? \n", " * What can you do to make this more accurate?\n", " \n", "Now there are many follow ups to this study. However, we would like to highlight that he big gains that come from this are not the network itself, its more that the NN has been able to do a visual inspection of a material and make conclusions that are not necessarily obvious. Using this can lead to better analysis of data. Moreover, we can ask ourselves this question: if we can accurately predict properties of materials, can we use this to advance our understanding? "]}], "metadata": {"celltoolbar": "Tags", "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}